{
    "dataset_reader": {
        "type": "boolean_qa_reader",
        "context_key": "passage",
        "is_training": true,
        "save_tokenizer": true,
        "tokenizer_wrapper": {
            "call_kwargs": {
                "truncation": "only_first"
            },
            "pretrained_model": "roberta-large"
        },
        "with_context": true
    },
    "model": {
        "type": "hf_classifier",
        "initializer": {
            "regexes": [
                [
                    ".*",
                    {
                        "parameter_name_overrides": {},
                        "type": "pretrained",
                        "weights_file_path": "experiments/for_STAR_1_twentyquestions_0/model.tar.gz"
                    }
                ]
            ]
        },
        "num_labels": 2,
        "pretrained_model": "roberta-large",
        "tokenizer_wrapper": {
            "call_kwargs": {
                "truncation": "only_first"
            },
            "pretrained_model": "roberta-large"
        }
    },
    "train_data_path": "data/boolq/train.jsonl",
    "validation_data_path": "data/boolq/dev.jsonl",
    "trainer": {
        "checkpointer": {
            "num_serialized_models_to_keep": -1
        },
        "cuda_device": 0,
        "learning_rate_scheduler": {
            "type": "slanted_triangular",
            "cut_frac": 0.06
        },
        "num_epochs": 10,
        "num_gradient_accumulation_steps": 16,
        "optimizer": {
            "type": "huggingface_adamw",
            "betas": [
                0.9,
                0.98
            ],
            "eps": 1e-06,
            "lr": 1e-05,
            "weight_decay": 0.1
        },
        "validation_metric": "+accuracy"
    },
    "data_loader": {
        "batch_sampler": {
            "type": "bucket",
            "batch_size": 2
        }
    },
    "numpy_seed": 42,
    "pytorch_seed": 42,
    "random_seed": 42,
    "validation_dataset_reader": {
        "type": "boolean_qa_reader",
        "context_key": "passage",
        "is_training": false,
        "save_tokenizer": false,
        "tokenizer_wrapper": {
            "call_kwargs": {
                "truncation": "only_first"
            },
            "pretrained_model": "roberta-large"
        },
        "with_context": true
    }
}