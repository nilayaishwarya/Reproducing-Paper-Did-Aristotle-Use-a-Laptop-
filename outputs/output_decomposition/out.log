2022-03-31 10:10:10,632 - INFO - allennlp.common.params - random_seed = 42
2022-03-31 10:10:10,633 - INFO - allennlp.common.params - numpy_seed = 42
2022-03-31 10:10:10,633 - INFO - allennlp.common.params - pytorch_seed = 42
2022-03-31 10:10:11,310 - INFO - allennlp.common.checks - Pytorch version: 1.7.1
2022-03-31 10:10:11,310 - INFO - allennlp.common.params - type = default
2022-03-31 10:10:11,311 - INFO - allennlp.common.params - dataset_reader.type = strategy_decomposition_reader
2022-03-31 10:10:11,311 - INFO - allennlp.common.params - dataset_reader.lazy = False
2022-03-31 10:10:11,311 - INFO - allennlp.common.params - dataset_reader.cache_directory = None
2022-03-31 10:10:11,311 - INFO - allennlp.common.params - dataset_reader.max_instances = None
2022-03-31 10:10:11,311 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False
2022-03-31 10:10:11,311 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False
2022-03-31 10:10:11,312 - INFO - allennlp.common.params - dataset_reader.tokenizer_wrapper.type = default
2022-03-31 10:10:11,312 - INFO - allennlp.common.params - dataset_reader.tokenizer_wrapper.pretrained_model = facebook/bart-large
2022-03-31 10:10:11,312 - INFO - allennlp.common.params - dataset_reader.tokenizer_wrapper.init_kwargs.add_prefix_space = True
2022-03-31 10:10:12,536 - INFO - allennlp.common.params - dataset_reader.save_tokenizer = True
2022-03-31 10:10:12,536 - INFO - allennlp.common.params - dataset_reader.is_training = True
2022-03-31 10:10:12,536 - INFO - allennlp.common.params - dataset_reader.pickle.action = None
2022-03-31 10:10:12,975 - INFO - allennlp.common.params - train_data_path = data/strategyqa/train.json
2022-03-31 10:10:12,976 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7ff3a6648cd0>
2022-03-31 10:10:12,976 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2022-03-31 10:10:12,976 - INFO - allennlp.common.params - validation_dataset_reader.type = strategy_decomposition_reader
2022-03-31 10:10:12,976 - INFO - allennlp.common.params - validation_dataset_reader.lazy = False
2022-03-31 10:10:12,976 - INFO - allennlp.common.params - validation_dataset_reader.cache_directory = None
2022-03-31 10:10:12,976 - INFO - allennlp.common.params - validation_dataset_reader.max_instances = None
2022-03-31 10:10:12,976 - INFO - allennlp.common.params - validation_dataset_reader.manual_distributed_sharding = False
2022-03-31 10:10:12,976 - INFO - allennlp.common.params - validation_dataset_reader.manual_multi_process_sharding = False
2022-03-31 10:10:12,977 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer_wrapper.type = default
2022-03-31 10:10:12,977 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer_wrapper.pretrained_model = facebook/bart-large
2022-03-31 10:10:12,977 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer_wrapper.init_kwargs.add_prefix_space = True
2022-03-31 10:10:14,423 - INFO - allennlp.common.params - validation_dataset_reader.save_tokenizer = False
2022-03-31 10:10:14,423 - INFO - allennlp.common.params - validation_dataset_reader.is_training = False
2022-03-31 10:10:14,423 - INFO - allennlp.common.params - validation_dataset_reader.pickle.action = None
2022-03-31 10:10:14,423 - INFO - allennlp.common.params - validation_data_path = data/strategyqa/dev.json
2022-03-31 10:10:14,423 - INFO - allennlp.common.params - validation_data_loader = None
2022-03-31 10:10:14,423 - INFO - allennlp.common.params - test_data_path = None
2022-03-31 10:10:14,423 - INFO - allennlp.common.params - evaluate_on_test = False
2022-03-31 10:10:14,423 - INFO - allennlp.common.params - batch_weight_key = 
2022-03-31 10:10:14,424 - INFO - allennlp.training.util - Reading training data from data/strategyqa/train.json
2022-03-31 10:10:14,424 - INFO - tqdm - reading instances: 0it [00:00, ?it/s]
2022-03-31 10:10:14,424 - INFO - src.data.dataset_readers.base.base_dataset_reader - Reading the dataset from scratch
2022-03-31 10:10:14,424 - INFO - src.data.dataset_readers.strategy_decomposition_reader - Reading the dataset:
2022-03-31 10:10:14,424 - INFO - src.data.dataset_readers.strategy_decomposition_reader - Reading file at data/strategyqa/train.json
2022-03-31 10:10:15,829 - INFO - allennlp.training.util - Reading validation data from data/strategyqa/dev.json
2022-03-31 10:10:15,829 - INFO - tqdm - reading instances: 0it [00:00, ?it/s]
2022-03-31 10:10:15,829 - INFO - src.data.dataset_readers.base.base_dataset_reader - Reading the dataset from scratch
2022-03-31 10:10:15,829 - INFO - src.data.dataset_readers.strategy_decomposition_reader - Reading the dataset:
2022-03-31 10:10:15,829 - INFO - src.data.dataset_readers.strategy_decomposition_reader - Reading file at data/strategyqa/dev.json
2022-03-31 10:10:15,987 - INFO - allennlp.common.params - type = from_instances
2022-03-31 10:10:15,988 - INFO - allennlp.common.params - min_count = None
2022-03-31 10:10:15,988 - INFO - allennlp.common.params - max_vocab_size = None
2022-03-31 10:10:15,988 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2022-03-31 10:10:15,988 - INFO - allennlp.common.params - pretrained_files = None
2022-03-31 10:10:15,988 - INFO - allennlp.common.params - only_include_pretrained_words = False
2022-03-31 10:10:15,988 - INFO - allennlp.common.params - tokens_to_add = None
2022-03-31 10:10:15,989 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2022-03-31 10:10:15,989 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2022-03-31 10:10:15,989 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2022-03-31 10:10:15,989 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2022-03-31 10:10:15,989 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2022-03-31 10:10:15,994 - INFO - allennlp.common.params - model.type = gen
2022-03-31 10:10:15,994 - INFO - allennlp.common.params - model.regularizer = None
2022-03-31 10:10:15,994 - INFO - allennlp.common.params - model.pretrained_model = facebook/bart-large
2022-03-31 10:10:15,994 - INFO - allennlp.common.params - model.tokenizer_wrapper.type = default
2022-03-31 10:10:15,995 - INFO - allennlp.common.params - model.tokenizer_wrapper.pretrained_model = facebook/bart-large
2022-03-31 10:10:15,995 - INFO - allennlp.common.params - model.tokenizer_wrapper.init_kwargs.add_prefix_space = True
2022-03-31 10:10:17,171 - INFO - allennlp.common.params - model.generate_while_training = False
2022-03-31 10:10:17,171 - INFO - allennlp.common.params - model.repetition_penalty = 2.5
2022-03-31 10:10:17,171 - INFO - allennlp.common.params - model.metrics.bleu.type = bleu
2022-03-31 10:10:17,171 - INFO - allennlp.common.params - model.metrics.bleu.ngram_weights = (0.25, 0.25, 0.25, 0.25)
2022-03-31 10:10:17,172 - INFO - allennlp.common.params - model.metrics.bleu.exclude_indices = None
2022-03-31 10:10:17,172 - INFO - allennlp.common.params - model.metrics.rouge.type = rouge
2022-03-31 10:10:17,172 - INFO - allennlp.common.params - model.metrics.rouge.ngram_size = 2
2022-03-31 10:10:17,172 - INFO - allennlp.common.params - model.metrics.rouge.exclude_indices = None
2022-03-31 10:10:17,172 - INFO - allennlp.common.params - model.metrics.sari.type = sari
2022-03-31 10:10:17,172 - INFO - allennlp.common.params - model.metrics.sari.is_main = True
2022-03-31 10:10:17,172 - INFO - allennlp.common.params - model.is_dummy = False
2022-03-31 10:10:17,172 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7ff39ba0a0d0>
2022-03-31 10:10:33,190 - INFO - allennlp.nn.initializers - Initializing parameters
2022-03-31 10:10:33,192 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-03-31 10:10:33,193 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.embed_positions.weight
2022-03-31 10:10:33,193 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layernorm_embedding.bias
2022-03-31 10:10:33,193 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layernorm_embedding.weight
2022-03-31 10:10:33,193 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.k_proj.bias
2022-03-31 10:10:33,193 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.k_proj.weight
2022-03-31 10:10:33,193 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.out_proj.bias
2022-03-31 10:10:33,193 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.out_proj.weight
2022-03-31 10:10:33,193 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.q_proj.bias
2022-03-31 10:10:33,193 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.q_proj.weight
2022-03-31 10:10:33,193 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.v_proj.bias
2022-03-31 10:10:33,193 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.v_proj.weight
2022-03-31 10:10:33,193 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn_layer_norm.bias
2022-03-31 10:10:33,193 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn_layer_norm.weight
2022-03-31 10:10:33,194 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.fc1.bias
2022-03-31 10:10:33,194 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.fc1.weight
2022-03-31 10:10:33,194 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.fc2.bias
2022-03-31 10:10:33,194 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.fc2.weight
2022-03-31 10:10:33,194 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.final_layer_norm.bias
2022-03-31 10:10:33,194 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.final_layer_norm.weight
2022-03-31 10:10:33,194 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.k_proj.bias
2022-03-31 10:10:33,194 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.k_proj.weight
2022-03-31 10:10:33,194 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.out_proj.bias
2022-03-31 10:10:33,194 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.out_proj.weight
2022-03-31 10:10:33,194 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.q_proj.bias
2022-03-31 10:10:33,194 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.q_proj.weight
2022-03-31 10:10:33,194 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.v_proj.bias
2022-03-31 10:10:33,194 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.v_proj.weight
2022-03-31 10:10:33,194 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn_layer_norm.bias
2022-03-31 10:10:33,195 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn_layer_norm.weight
2022-03-31 10:10:33,195 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.k_proj.bias
2022-03-31 10:10:33,195 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.k_proj.weight
2022-03-31 10:10:33,195 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.out_proj.bias
2022-03-31 10:10:33,195 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.out_proj.weight
2022-03-31 10:10:33,195 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.q_proj.bias
2022-03-31 10:10:33,195 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.q_proj.weight
2022-03-31 10:10:33,195 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.v_proj.bias
2022-03-31 10:10:33,195 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.v_proj.weight
2022-03-31 10:10:33,195 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn_layer_norm.bias
2022-03-31 10:10:33,195 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn_layer_norm.weight
2022-03-31 10:10:33,195 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.fc1.bias
2022-03-31 10:10:33,195 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.fc1.weight
2022-03-31 10:10:33,195 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.fc2.bias
2022-03-31 10:10:33,196 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.fc2.weight
2022-03-31 10:10:33,196 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.final_layer_norm.bias
2022-03-31 10:10:33,196 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.final_layer_norm.weight
2022-03-31 10:10:33,196 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.k_proj.bias
2022-03-31 10:10:33,196 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.k_proj.weight
2022-03-31 10:10:33,196 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.out_proj.bias
2022-03-31 10:10:33,196 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.out_proj.weight
2022-03-31 10:10:33,196 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.q_proj.bias
2022-03-31 10:10:33,196 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.q_proj.weight
2022-03-31 10:10:33,196 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.v_proj.bias
2022-03-31 10:10:33,196 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.v_proj.weight
2022-03-31 10:10:33,196 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn_layer_norm.bias
2022-03-31 10:10:33,196 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn_layer_norm.weight
2022-03-31 10:10:33,196 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.k_proj.bias
2022-03-31 10:10:33,196 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.k_proj.weight
2022-03-31 10:10:33,197 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.out_proj.bias
2022-03-31 10:10:33,197 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.out_proj.weight
2022-03-31 10:10:33,197 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.q_proj.bias
2022-03-31 10:10:33,197 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.q_proj.weight
2022-03-31 10:10:33,197 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.v_proj.bias
2022-03-31 10:10:33,197 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.v_proj.weight
2022-03-31 10:10:33,197 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn_layer_norm.bias
2022-03-31 10:10:33,197 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn_layer_norm.weight
2022-03-31 10:10:33,197 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.fc1.bias
2022-03-31 10:10:33,197 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.fc1.weight
2022-03-31 10:10:33,197 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.fc2.bias
2022-03-31 10:10:33,197 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.fc2.weight
2022-03-31 10:10:33,197 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.final_layer_norm.bias
2022-03-31 10:10:33,197 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.final_layer_norm.weight
2022-03-31 10:10:33,197 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.k_proj.bias
2022-03-31 10:10:33,198 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.k_proj.weight
2022-03-31 10:10:33,198 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.out_proj.bias
2022-03-31 10:10:33,198 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.out_proj.weight
2022-03-31 10:10:33,198 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.q_proj.bias
2022-03-31 10:10:33,198 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.q_proj.weight
2022-03-31 10:10:33,198 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.v_proj.bias
2022-03-31 10:10:33,198 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.v_proj.weight
2022-03-31 10:10:33,198 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn_layer_norm.bias
2022-03-31 10:10:33,198 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn_layer_norm.weight
2022-03-31 10:10:33,198 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.k_proj.bias
2022-03-31 10:10:33,198 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.k_proj.weight
2022-03-31 10:10:33,198 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.out_proj.bias
2022-03-31 10:10:33,198 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.out_proj.weight
2022-03-31 10:10:33,198 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.q_proj.bias
2022-03-31 10:10:33,198 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.q_proj.weight
2022-03-31 10:10:33,199 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.v_proj.bias
2022-03-31 10:10:33,199 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.v_proj.weight
2022-03-31 10:10:33,199 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn_layer_norm.bias
2022-03-31 10:10:33,199 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn_layer_norm.weight
2022-03-31 10:10:33,199 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.fc1.bias
2022-03-31 10:10:33,199 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.fc1.weight
2022-03-31 10:10:33,199 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.fc2.bias
2022-03-31 10:10:33,199 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.fc2.weight
2022-03-31 10:10:33,199 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.final_layer_norm.bias
2022-03-31 10:10:33,199 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.final_layer_norm.weight
2022-03-31 10:10:33,199 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.k_proj.bias
2022-03-31 10:10:33,199 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.k_proj.weight
2022-03-31 10:10:33,199 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.out_proj.bias
2022-03-31 10:10:33,199 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.out_proj.weight
2022-03-31 10:10:33,199 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.q_proj.bias
2022-03-31 10:10:33,200 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.q_proj.weight
2022-03-31 10:10:33,200 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.v_proj.bias
2022-03-31 10:10:33,200 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.v_proj.weight
2022-03-31 10:10:33,200 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn_layer_norm.bias
2022-03-31 10:10:33,200 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn_layer_norm.weight
2022-03-31 10:10:33,200 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.k_proj.bias
2022-03-31 10:10:33,200 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.k_proj.weight
2022-03-31 10:10:33,200 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.out_proj.bias
2022-03-31 10:10:33,200 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.out_proj.weight
2022-03-31 10:10:33,200 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.q_proj.bias
2022-03-31 10:10:33,200 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.q_proj.weight
2022-03-31 10:10:33,200 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.v_proj.bias
2022-03-31 10:10:33,200 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.v_proj.weight
2022-03-31 10:10:33,200 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn_layer_norm.bias
2022-03-31 10:10:33,200 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn_layer_norm.weight
2022-03-31 10:10:33,200 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.fc1.bias
2022-03-31 10:10:33,201 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.fc1.weight
2022-03-31 10:10:33,201 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.fc2.bias
2022-03-31 10:10:33,201 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.fc2.weight
2022-03-31 10:10:33,201 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.final_layer_norm.bias
2022-03-31 10:10:33,201 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.final_layer_norm.weight
2022-03-31 10:10:33,201 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.k_proj.bias
2022-03-31 10:10:33,201 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.k_proj.weight
2022-03-31 10:10:33,201 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.out_proj.bias
2022-03-31 10:10:33,201 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.out_proj.weight
2022-03-31 10:10:33,201 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.q_proj.bias
2022-03-31 10:10:33,201 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.q_proj.weight
2022-03-31 10:10:33,201 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.v_proj.bias
2022-03-31 10:10:33,201 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.v_proj.weight
2022-03-31 10:10:33,201 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn_layer_norm.bias
2022-03-31 10:10:33,201 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn_layer_norm.weight
2022-03-31 10:10:33,202 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.k_proj.bias
2022-03-31 10:10:33,202 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.k_proj.weight
2022-03-31 10:10:33,202 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.out_proj.bias
2022-03-31 10:10:33,202 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.out_proj.weight
2022-03-31 10:10:33,202 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.q_proj.bias
2022-03-31 10:10:33,202 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.q_proj.weight
2022-03-31 10:10:33,202 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.v_proj.bias
2022-03-31 10:10:33,202 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.v_proj.weight
2022-03-31 10:10:33,202 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn_layer_norm.bias
2022-03-31 10:10:33,202 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn_layer_norm.weight
2022-03-31 10:10:33,202 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.fc1.bias
2022-03-31 10:10:33,202 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.fc1.weight
2022-03-31 10:10:33,202 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.fc2.bias
2022-03-31 10:10:33,202 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.fc2.weight
2022-03-31 10:10:33,203 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.final_layer_norm.bias
2022-03-31 10:10:33,203 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.final_layer_norm.weight
2022-03-31 10:10:33,203 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.k_proj.bias
2022-03-31 10:10:33,203 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.k_proj.weight
2022-03-31 10:10:33,203 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.out_proj.bias
2022-03-31 10:10:33,203 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.out_proj.weight
2022-03-31 10:10:33,203 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.q_proj.bias
2022-03-31 10:10:33,203 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.q_proj.weight
2022-03-31 10:10:33,203 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.v_proj.bias
2022-03-31 10:10:33,203 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.v_proj.weight
2022-03-31 10:10:33,203 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn_layer_norm.bias
2022-03-31 10:10:33,203 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn_layer_norm.weight
2022-03-31 10:10:33,203 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.k_proj.bias
2022-03-31 10:10:33,203 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.k_proj.weight
2022-03-31 10:10:33,203 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.out_proj.bias
2022-03-31 10:10:33,204 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.out_proj.weight
2022-03-31 10:10:33,204 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.q_proj.bias
2022-03-31 10:10:33,204 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.q_proj.weight
2022-03-31 10:10:33,204 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.v_proj.bias
2022-03-31 10:10:33,204 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.v_proj.weight
2022-03-31 10:10:33,204 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn_layer_norm.bias
2022-03-31 10:10:33,204 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn_layer_norm.weight
2022-03-31 10:10:33,204 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.fc1.bias
2022-03-31 10:10:33,204 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.fc1.weight
2022-03-31 10:10:33,204 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.fc2.bias
2022-03-31 10:10:33,204 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.fc2.weight
2022-03-31 10:10:33,204 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.final_layer_norm.bias
2022-03-31 10:10:33,204 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.final_layer_norm.weight
2022-03-31 10:10:33,204 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.k_proj.bias
2022-03-31 10:10:33,205 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.k_proj.weight
2022-03-31 10:10:33,205 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.out_proj.bias
2022-03-31 10:10:33,205 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.out_proj.weight
2022-03-31 10:10:33,205 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.q_proj.bias
2022-03-31 10:10:33,205 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.q_proj.weight
2022-03-31 10:10:33,205 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.v_proj.bias
2022-03-31 10:10:33,205 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.v_proj.weight
2022-03-31 10:10:33,205 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn_layer_norm.bias
2022-03-31 10:10:33,205 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn_layer_norm.weight
2022-03-31 10:10:33,205 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.k_proj.bias
2022-03-31 10:10:33,205 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.k_proj.weight
2022-03-31 10:10:33,205 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.out_proj.bias
2022-03-31 10:10:33,205 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.out_proj.weight
2022-03-31 10:10:33,205 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.q_proj.bias
2022-03-31 10:10:33,205 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.q_proj.weight
2022-03-31 10:10:33,205 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.v_proj.bias
2022-03-31 10:10:33,206 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.v_proj.weight
2022-03-31 10:10:33,206 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn_layer_norm.bias
2022-03-31 10:10:33,206 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn_layer_norm.weight
2022-03-31 10:10:33,206 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.fc1.bias
2022-03-31 10:10:33,206 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.fc1.weight
2022-03-31 10:10:33,206 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.fc2.bias
2022-03-31 10:10:33,206 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.fc2.weight
2022-03-31 10:10:33,206 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.final_layer_norm.bias
2022-03-31 10:10:33,206 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.final_layer_norm.weight
2022-03-31 10:10:33,206 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.k_proj.bias
2022-03-31 10:10:33,206 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.k_proj.weight
2022-03-31 10:10:33,206 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.out_proj.bias
2022-03-31 10:10:33,206 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.out_proj.weight
2022-03-31 10:10:33,206 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.q_proj.bias
2022-03-31 10:10:33,207 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.q_proj.weight
2022-03-31 10:10:33,207 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.v_proj.bias
2022-03-31 10:10:33,207 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.v_proj.weight
2022-03-31 10:10:33,207 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn_layer_norm.bias
2022-03-31 10:10:33,207 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn_layer_norm.weight
2022-03-31 10:10:33,207 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.k_proj.bias
2022-03-31 10:10:33,207 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.k_proj.weight
2022-03-31 10:10:33,207 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.out_proj.bias
2022-03-31 10:10:33,207 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.out_proj.weight
2022-03-31 10:10:33,207 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.q_proj.bias
2022-03-31 10:10:33,207 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.q_proj.weight
2022-03-31 10:10:33,207 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.v_proj.bias
2022-03-31 10:10:33,207 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.v_proj.weight
2022-03-31 10:10:33,208 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn_layer_norm.bias
2022-03-31 10:10:33,208 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn_layer_norm.weight
2022-03-31 10:10:33,208 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.fc1.bias
2022-03-31 10:10:33,208 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.fc1.weight
2022-03-31 10:10:33,208 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.fc2.bias
2022-03-31 10:10:33,208 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.fc2.weight
2022-03-31 10:10:33,208 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.final_layer_norm.bias
2022-03-31 10:10:33,208 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.final_layer_norm.weight
2022-03-31 10:10:33,208 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.k_proj.bias
2022-03-31 10:10:33,208 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.k_proj.weight
2022-03-31 10:10:33,208 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.out_proj.bias
2022-03-31 10:10:33,208 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.out_proj.weight
2022-03-31 10:10:33,209 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.q_proj.bias
2022-03-31 10:10:33,209 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.q_proj.weight
2022-03-31 10:10:33,209 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.v_proj.bias
2022-03-31 10:10:33,209 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.v_proj.weight
2022-03-31 10:10:33,209 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn_layer_norm.bias
2022-03-31 10:10:33,209 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn_layer_norm.weight
2022-03-31 10:10:33,209 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.k_proj.bias
2022-03-31 10:10:33,209 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.k_proj.weight
2022-03-31 10:10:33,209 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.out_proj.bias
2022-03-31 10:10:33,209 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.out_proj.weight
2022-03-31 10:10:33,209 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.q_proj.bias
2022-03-31 10:10:33,209 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.q_proj.weight
2022-03-31 10:10:33,209 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.v_proj.bias
2022-03-31 10:10:33,210 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.v_proj.weight
2022-03-31 10:10:33,210 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn_layer_norm.bias
2022-03-31 10:10:33,210 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn_layer_norm.weight
2022-03-31 10:10:33,210 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.fc1.bias
2022-03-31 10:10:33,210 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.fc1.weight
2022-03-31 10:10:33,210 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.fc2.bias
2022-03-31 10:10:33,210 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.fc2.weight
2022-03-31 10:10:33,210 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.final_layer_norm.bias
2022-03-31 10:10:33,210 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.final_layer_norm.weight
2022-03-31 10:10:33,210 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.k_proj.bias
2022-03-31 10:10:33,210 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.k_proj.weight
2022-03-31 10:10:33,210 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.out_proj.bias
2022-03-31 10:10:33,210 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.out_proj.weight
2022-03-31 10:10:33,210 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.q_proj.bias
2022-03-31 10:10:33,210 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.q_proj.weight
2022-03-31 10:10:33,211 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.v_proj.bias
2022-03-31 10:10:33,211 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.v_proj.weight
2022-03-31 10:10:33,211 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn_layer_norm.bias
2022-03-31 10:10:33,211 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn_layer_norm.weight
2022-03-31 10:10:33,211 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.k_proj.bias
2022-03-31 10:10:33,211 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.k_proj.weight
2022-03-31 10:10:33,211 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.out_proj.bias
2022-03-31 10:10:33,211 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.out_proj.weight
2022-03-31 10:10:33,211 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.q_proj.bias
2022-03-31 10:10:33,211 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.q_proj.weight
2022-03-31 10:10:33,211 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.v_proj.bias
2022-03-31 10:10:33,211 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.v_proj.weight
2022-03-31 10:10:33,211 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn_layer_norm.bias
2022-03-31 10:10:33,212 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn_layer_norm.weight
2022-03-31 10:10:33,212 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.fc1.bias
2022-03-31 10:10:33,212 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.fc1.weight
2022-03-31 10:10:33,212 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.fc2.bias
2022-03-31 10:10:33,212 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.fc2.weight
2022-03-31 10:10:33,212 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.final_layer_norm.bias
2022-03-31 10:10:33,212 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.final_layer_norm.weight
2022-03-31 10:10:33,212 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.k_proj.bias
2022-03-31 10:10:33,212 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.k_proj.weight
2022-03-31 10:10:33,212 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.out_proj.bias
2022-03-31 10:10:33,212 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.out_proj.weight
2022-03-31 10:10:33,212 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.q_proj.bias
2022-03-31 10:10:33,212 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.q_proj.weight
2022-03-31 10:10:33,212 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.v_proj.bias
2022-03-31 10:10:33,213 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.v_proj.weight
2022-03-31 10:10:33,213 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn_layer_norm.bias
2022-03-31 10:10:33,213 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn_layer_norm.weight
2022-03-31 10:10:33,213 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.k_proj.bias
2022-03-31 10:10:33,213 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.k_proj.weight
2022-03-31 10:10:33,213 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.out_proj.bias
2022-03-31 10:10:33,213 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.out_proj.weight
2022-03-31 10:10:33,213 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.q_proj.bias
2022-03-31 10:10:33,213 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.q_proj.weight
2022-03-31 10:10:33,213 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.v_proj.bias
2022-03-31 10:10:33,213 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.v_proj.weight
2022-03-31 10:10:33,213 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn_layer_norm.bias
2022-03-31 10:10:33,213 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn_layer_norm.weight
2022-03-31 10:10:33,213 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.fc1.bias
2022-03-31 10:10:33,213 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.fc1.weight
2022-03-31 10:10:33,214 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.fc2.bias
2022-03-31 10:10:33,214 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.fc2.weight
2022-03-31 10:10:33,214 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.final_layer_norm.bias
2022-03-31 10:10:33,214 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.final_layer_norm.weight
2022-03-31 10:10:33,214 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.k_proj.bias
2022-03-31 10:10:33,214 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.k_proj.weight
2022-03-31 10:10:33,214 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.out_proj.bias
2022-03-31 10:10:33,214 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.out_proj.weight
2022-03-31 10:10:33,214 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.q_proj.bias
2022-03-31 10:10:33,214 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.q_proj.weight
2022-03-31 10:10:33,214 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.v_proj.bias
2022-03-31 10:10:33,214 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.v_proj.weight
2022-03-31 10:10:33,214 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn_layer_norm.bias
2022-03-31 10:10:33,214 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn_layer_norm.weight
2022-03-31 10:10:33,215 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.embed_positions.weight
2022-03-31 10:10:33,215 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layernorm_embedding.bias
2022-03-31 10:10:33,215 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layernorm_embedding.weight
2022-03-31 10:10:33,215 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.fc1.bias
2022-03-31 10:10:33,215 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.fc1.weight
2022-03-31 10:10:33,215 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.fc2.bias
2022-03-31 10:10:33,215 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.fc2.weight
2022-03-31 10:10:33,215 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.final_layer_norm.bias
2022-03-31 10:10:33,215 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.final_layer_norm.weight
2022-03-31 10:10:33,215 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.k_proj.bias
2022-03-31 10:10:33,215 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.k_proj.weight
2022-03-31 10:10:33,215 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.out_proj.bias
2022-03-31 10:10:33,215 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.out_proj.weight
2022-03-31 10:10:33,215 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.q_proj.bias
2022-03-31 10:10:33,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.q_proj.weight
2022-03-31 10:10:33,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.v_proj.bias
2022-03-31 10:10:33,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.v_proj.weight
2022-03-31 10:10:33,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn_layer_norm.bias
2022-03-31 10:10:33,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn_layer_norm.weight
2022-03-31 10:10:33,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.fc1.bias
2022-03-31 10:10:33,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.fc1.weight
2022-03-31 10:10:33,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.fc2.bias
2022-03-31 10:10:33,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.fc2.weight
2022-03-31 10:10:33,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.final_layer_norm.bias
2022-03-31 10:10:33,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.final_layer_norm.weight
2022-03-31 10:10:33,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.k_proj.bias
2022-03-31 10:10:33,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.k_proj.weight
2022-03-31 10:10:33,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.out_proj.bias
2022-03-31 10:10:33,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.out_proj.weight
2022-03-31 10:10:33,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.q_proj.bias
2022-03-31 10:10:33,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.q_proj.weight
2022-03-31 10:10:33,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.v_proj.bias
2022-03-31 10:10:33,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.v_proj.weight
2022-03-31 10:10:33,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn_layer_norm.bias
2022-03-31 10:10:33,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn_layer_norm.weight
2022-03-31 10:10:33,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.fc1.bias
2022-03-31 10:10:33,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.fc1.weight
2022-03-31 10:10:33,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.fc2.bias
2022-03-31 10:10:33,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.fc2.weight
2022-03-31 10:10:33,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.final_layer_norm.bias
2022-03-31 10:10:33,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.final_layer_norm.weight
2022-03-31 10:10:33,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.k_proj.bias
2022-03-31 10:10:33,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.k_proj.weight
2022-03-31 10:10:33,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.out_proj.bias
2022-03-31 10:10:33,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.out_proj.weight
2022-03-31 10:10:33,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.q_proj.bias
2022-03-31 10:10:33,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.q_proj.weight
2022-03-31 10:10:33,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.v_proj.bias
2022-03-31 10:10:33,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.v_proj.weight
2022-03-31 10:10:33,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn_layer_norm.bias
2022-03-31 10:10:33,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn_layer_norm.weight
2022-03-31 10:10:33,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.fc1.bias
2022-03-31 10:10:33,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.fc1.weight
2022-03-31 10:10:33,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.fc2.bias
2022-03-31 10:10:33,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.fc2.weight
2022-03-31 10:10:33,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.final_layer_norm.bias
2022-03-31 10:10:33,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.final_layer_norm.weight
2022-03-31 10:10:33,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.k_proj.bias
2022-03-31 10:10:33,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.k_proj.weight
2022-03-31 10:10:33,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.out_proj.bias
2022-03-31 10:10:33,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.out_proj.weight
2022-03-31 10:10:33,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.q_proj.bias
2022-03-31 10:10:33,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.q_proj.weight
2022-03-31 10:10:33,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.v_proj.bias
2022-03-31 10:10:33,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.v_proj.weight
2022-03-31 10:10:33,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn_layer_norm.bias
2022-03-31 10:10:33,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn_layer_norm.weight
2022-03-31 10:10:33,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.fc1.bias
2022-03-31 10:10:33,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.fc1.weight
2022-03-31 10:10:33,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.fc2.bias
2022-03-31 10:10:33,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.fc2.weight
2022-03-31 10:10:33,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.final_layer_norm.bias
2022-03-31 10:10:33,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.final_layer_norm.weight
2022-03-31 10:10:33,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.k_proj.bias
2022-03-31 10:10:33,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.k_proj.weight
2022-03-31 10:10:33,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.out_proj.bias
2022-03-31 10:10:33,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.out_proj.weight
2022-03-31 10:10:33,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.q_proj.bias
2022-03-31 10:10:33,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.q_proj.weight
2022-03-31 10:10:33,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.v_proj.bias
2022-03-31 10:10:33,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.v_proj.weight
2022-03-31 10:10:33,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn_layer_norm.bias
2022-03-31 10:10:33,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn_layer_norm.weight
2022-03-31 10:10:33,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.fc1.bias
2022-03-31 10:10:33,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.fc1.weight
2022-03-31 10:10:33,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.fc2.bias
2022-03-31 10:10:33,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.fc2.weight
2022-03-31 10:10:33,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.final_layer_norm.bias
2022-03-31 10:10:33,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.final_layer_norm.weight
2022-03-31 10:10:33,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.k_proj.bias
2022-03-31 10:10:33,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.k_proj.weight
2022-03-31 10:10:33,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.out_proj.bias
2022-03-31 10:10:33,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.out_proj.weight
2022-03-31 10:10:33,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.q_proj.bias
2022-03-31 10:10:33,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.q_proj.weight
2022-03-31 10:10:33,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.v_proj.bias
2022-03-31 10:10:33,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.v_proj.weight
2022-03-31 10:10:33,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn_layer_norm.bias
2022-03-31 10:10:33,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn_layer_norm.weight
2022-03-31 10:10:33,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.fc1.bias
2022-03-31 10:10:33,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.fc1.weight
2022-03-31 10:10:33,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.fc2.bias
2022-03-31 10:10:33,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.fc2.weight
2022-03-31 10:10:33,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.final_layer_norm.bias
2022-03-31 10:10:33,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.final_layer_norm.weight
2022-03-31 10:10:33,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.k_proj.bias
2022-03-31 10:10:33,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.k_proj.weight
2022-03-31 10:10:33,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.out_proj.bias
2022-03-31 10:10:33,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.out_proj.weight
2022-03-31 10:10:33,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.q_proj.bias
2022-03-31 10:10:33,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.q_proj.weight
2022-03-31 10:10:33,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.v_proj.bias
2022-03-31 10:10:33,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.v_proj.weight
2022-03-31 10:10:33,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn_layer_norm.bias
2022-03-31 10:10:33,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn_layer_norm.weight
2022-03-31 10:10:33,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.fc1.bias
2022-03-31 10:10:33,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.fc1.weight
2022-03-31 10:10:33,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.fc2.bias
2022-03-31 10:10:33,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.fc2.weight
2022-03-31 10:10:33,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.final_layer_norm.bias
2022-03-31 10:10:33,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.final_layer_norm.weight
2022-03-31 10:10:33,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.k_proj.bias
2022-03-31 10:10:33,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.k_proj.weight
2022-03-31 10:10:33,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.out_proj.bias
2022-03-31 10:10:33,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.out_proj.weight
2022-03-31 10:10:33,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.q_proj.bias
2022-03-31 10:10:33,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.q_proj.weight
2022-03-31 10:10:33,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.v_proj.bias
2022-03-31 10:10:33,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.v_proj.weight
2022-03-31 10:10:33,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn_layer_norm.bias
2022-03-31 10:10:33,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn_layer_norm.weight
2022-03-31 10:10:33,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.fc1.bias
2022-03-31 10:10:33,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.fc1.weight
2022-03-31 10:10:33,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.fc2.bias
2022-03-31 10:10:33,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.fc2.weight
2022-03-31 10:10:33,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.final_layer_norm.bias
2022-03-31 10:10:33,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.final_layer_norm.weight
2022-03-31 10:10:33,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.k_proj.bias
2022-03-31 10:10:33,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.k_proj.weight
2022-03-31 10:10:33,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.out_proj.bias
2022-03-31 10:10:33,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.out_proj.weight
2022-03-31 10:10:33,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.q_proj.bias
2022-03-31 10:10:33,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.q_proj.weight
2022-03-31 10:10:33,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.v_proj.bias
2022-03-31 10:10:33,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.v_proj.weight
2022-03-31 10:10:33,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn_layer_norm.bias
2022-03-31 10:10:33,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn_layer_norm.weight
2022-03-31 10:10:33,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.fc1.bias
2022-03-31 10:10:33,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.fc1.weight
2022-03-31 10:10:33,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.fc2.bias
2022-03-31 10:10:33,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.fc2.weight
2022-03-31 10:10:33,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.final_layer_norm.bias
2022-03-31 10:10:33,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.final_layer_norm.weight
2022-03-31 10:10:33,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.k_proj.bias
2022-03-31 10:10:33,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.k_proj.weight
2022-03-31 10:10:33,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.out_proj.bias
2022-03-31 10:10:33,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.out_proj.weight
2022-03-31 10:10:33,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.q_proj.bias
2022-03-31 10:10:33,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.q_proj.weight
2022-03-31 10:10:33,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.v_proj.bias
2022-03-31 10:10:33,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.v_proj.weight
2022-03-31 10:10:33,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn_layer_norm.bias
2022-03-31 10:10:33,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn_layer_norm.weight
2022-03-31 10:10:33,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.fc1.bias
2022-03-31 10:10:33,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.fc1.weight
2022-03-31 10:10:33,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.fc2.bias
2022-03-31 10:10:33,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.fc2.weight
2022-03-31 10:10:33,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.final_layer_norm.bias
2022-03-31 10:10:33,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.final_layer_norm.weight
2022-03-31 10:10:33,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.k_proj.bias
2022-03-31 10:10:33,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.k_proj.weight
2022-03-31 10:10:33,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.out_proj.bias
2022-03-31 10:10:33,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.out_proj.weight
2022-03-31 10:10:33,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.q_proj.bias
2022-03-31 10:10:33,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.q_proj.weight
2022-03-31 10:10:33,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.v_proj.bias
2022-03-31 10:10:33,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.v_proj.weight
2022-03-31 10:10:33,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn_layer_norm.bias
2022-03-31 10:10:33,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn_layer_norm.weight
2022-03-31 10:10:33,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.fc1.bias
2022-03-31 10:10:33,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.fc1.weight
2022-03-31 10:10:33,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.fc2.bias
2022-03-31 10:10:33,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.fc2.weight
2022-03-31 10:10:33,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.final_layer_norm.bias
2022-03-31 10:10:33,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.final_layer_norm.weight
2022-03-31 10:10:33,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.k_proj.bias
2022-03-31 10:10:33,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.k_proj.weight
2022-03-31 10:10:33,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.out_proj.bias
2022-03-31 10:10:33,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.out_proj.weight
2022-03-31 10:10:33,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.q_proj.bias
2022-03-31 10:10:33,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.q_proj.weight
2022-03-31 10:10:33,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.v_proj.bias
2022-03-31 10:10:33,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.v_proj.weight
2022-03-31 10:10:33,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn_layer_norm.bias
2022-03-31 10:10:33,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn_layer_norm.weight
2022-03-31 10:10:33,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.shared.weight
2022-03-31 10:10:34,078 - INFO - filelock - Lock 140684443755024 acquired on ./output_decomposition/vocabulary/.lock
2022-03-31 10:10:34,079 - INFO - filelock - Lock 140684443755024 released on ./output_decomposition/vocabulary/.lock
2022-03-31 10:10:34,079 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader
2022-03-31 10:10:34,079 - INFO - allennlp.common.params - data_loader.batch_size = 1
2022-03-31 10:10:34,079 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-31 10:10:34,079 - INFO - allennlp.common.params - data_loader.sampler = None
2022-03-31 10:10:34,080 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-31 10:10:34,080 - INFO - allennlp.common.params - data_loader.pin_memory = False
2022-03-31 10:10:34,080 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-31 10:10:34,080 - INFO - allennlp.common.params - data_loader.timeout = 0
2022-03-31 10:10:34,080 - INFO - allennlp.common.params - data_loader.worker_init_fn = None
2022-03-31 10:10:34,080 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None
2022-03-31 10:10:34,080 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-31 10:10:34,080 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-31 10:10:34,081 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 2
2022-03-31 10:10:34,081 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-31 10:10:34,081 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-31 10:10:34,081 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-31 10:10:34,085 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader
2022-03-31 10:10:34,085 - INFO - allennlp.common.params - data_loader.batch_size = 1
2022-03-31 10:10:34,085 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-31 10:10:34,085 - INFO - allennlp.common.params - data_loader.sampler = None
2022-03-31 10:10:34,086 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-31 10:10:34,086 - INFO - allennlp.common.params - data_loader.pin_memory = False
2022-03-31 10:10:34,086 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-31 10:10:34,086 - INFO - allennlp.common.params - data_loader.timeout = 0
2022-03-31 10:10:34,086 - INFO - allennlp.common.params - data_loader.worker_init_fn = None
2022-03-31 10:10:34,086 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None
2022-03-31 10:10:34,086 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-31 10:10:34,086 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-31 10:10:34,086 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 2
2022-03-31 10:10:34,087 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-31 10:10:34,087 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-31 10:10:34,087 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-31 10:10:34,087 - INFO - allennlp.common.params - trainer.type = gradient_descent
2022-03-31 10:10:34,087 - INFO - allennlp.common.params - trainer.patience = None
2022-03-31 10:10:34,088 - INFO - allennlp.common.params - trainer.validation_metric = +SARI
2022-03-31 10:10:34,088 - INFO - allennlp.common.params - trainer.num_epochs = 15
2022-03-31 10:10:34,088 - INFO - allennlp.common.params - trainer.cuda_device = 0
2022-03-31 10:10:34,088 - INFO - allennlp.common.params - trainer.grad_norm = None
2022-03-31 10:10:34,088 - INFO - allennlp.common.params - trainer.grad_clipping = None
2022-03-31 10:10:34,088 - INFO - allennlp.common.params - trainer.distributed = False
2022-03-31 10:10:34,088 - INFO - allennlp.common.params - trainer.world_size = 1
2022-03-31 10:10:34,088 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 16
2022-03-31 10:10:34,088 - INFO - allennlp.common.params - trainer.use_amp = False
2022-03-31 10:10:34,088 - INFO - allennlp.common.params - trainer.no_grad = None
2022-03-31 10:10:34,089 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2022-03-31 10:10:34,089 - INFO - allennlp.common.params - trainer.tensorboard_writer = <allennlp.common.lazy.Lazy object at 0x7ff39c1f9050>
2022-03-31 10:10:34,089 - INFO - allennlp.common.params - trainer.moving_average = None
2022-03-31 10:10:34,089 - INFO - allennlp.common.params - trainer.batch_callbacks = None
2022-03-31 10:10:34,089 - INFO - allennlp.common.params - trainer.epoch_callbacks = None
2022-03-31 10:10:34,089 - INFO - allennlp.common.params - trainer.end_callbacks = None
2022-03-31 10:10:34,089 - INFO - allennlp.common.params - trainer.trainer_callbacks = None
2022-03-31 10:10:38,491 - INFO - allennlp.common.params - trainer.optimizer.type = huggingface_adamw
2022-03-31 10:10:38,491 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups = None
2022-03-31 10:10:38,492 - INFO - allennlp.common.params - trainer.optimizer.lr = 3e-05
2022-03-31 10:10:38,492 - INFO - allennlp.common.params - trainer.optimizer.betas = [0.9, 0.999]
2022-03-31 10:10:38,492 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08
2022-03-31 10:10:38,492 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.0
2022-03-31 10:10:38,492 - INFO - allennlp.common.params - trainer.optimizer.correct_bias = True
2022-03-31 10:10:38,493 - INFO - allennlp.training.optimizers - Number of trainable parameters: 406291456
2022-03-31 10:10:38,496 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2022-03-31 10:10:38,499 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2022-03-31 10:10:38,499 - INFO - allennlp.common.util - _seq2seq.model.shared.weight
2022-03-31 10:10:38,499 - INFO - allennlp.common.util - _seq2seq.model.encoder.embed_positions.weight
2022-03-31 10:10:38,499 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.k_proj.weight
2022-03-31 10:10:38,499 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.k_proj.bias
2022-03-31 10:10:38,500 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.v_proj.weight
2022-03-31 10:10:38,500 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.v_proj.bias
2022-03-31 10:10:38,500 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.q_proj.weight
2022-03-31 10:10:38,500 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.q_proj.bias
2022-03-31 10:10:38,500 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.out_proj.weight
2022-03-31 10:10:38,500 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.out_proj.bias
2022-03-31 10:10:38,500 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn_layer_norm.weight
2022-03-31 10:10:38,500 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn_layer_norm.bias
2022-03-31 10:10:38,500 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.fc1.weight
2022-03-31 10:10:38,500 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.fc1.bias
2022-03-31 10:10:38,501 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.fc2.weight
2022-03-31 10:10:38,501 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.fc2.bias
2022-03-31 10:10:38,501 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.final_layer_norm.weight
2022-03-31 10:10:38,501 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.final_layer_norm.bias
2022-03-31 10:10:38,501 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.k_proj.weight
2022-03-31 10:10:38,501 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.k_proj.bias
2022-03-31 10:10:38,501 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.v_proj.weight
2022-03-31 10:10:38,501 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.v_proj.bias
2022-03-31 10:10:38,501 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.q_proj.weight
2022-03-31 10:10:38,501 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.q_proj.bias
2022-03-31 10:10:38,501 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.out_proj.weight
2022-03-31 10:10:38,502 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.out_proj.bias
2022-03-31 10:10:38,502 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn_layer_norm.weight
2022-03-31 10:10:38,502 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn_layer_norm.bias
2022-03-31 10:10:38,502 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.fc1.weight
2022-03-31 10:10:38,502 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.fc1.bias
2022-03-31 10:10:38,502 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.fc2.weight
2022-03-31 10:10:38,502 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.fc2.bias
2022-03-31 10:10:38,502 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.final_layer_norm.weight
2022-03-31 10:10:38,502 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.final_layer_norm.bias
2022-03-31 10:10:38,502 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.k_proj.weight
2022-03-31 10:10:38,502 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.k_proj.bias
2022-03-31 10:10:38,503 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.v_proj.weight
2022-03-31 10:10:38,503 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.v_proj.bias
2022-03-31 10:10:38,503 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.q_proj.weight
2022-03-31 10:10:38,503 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.q_proj.bias
2022-03-31 10:10:38,503 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.out_proj.weight
2022-03-31 10:10:38,503 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.out_proj.bias
2022-03-31 10:10:38,503 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn_layer_norm.weight
2022-03-31 10:10:38,503 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn_layer_norm.bias
2022-03-31 10:10:38,503 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.fc1.weight
2022-03-31 10:10:38,503 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.fc1.bias
2022-03-31 10:10:38,504 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.fc2.weight
2022-03-31 10:10:38,504 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.fc2.bias
2022-03-31 10:10:38,504 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.final_layer_norm.weight
2022-03-31 10:10:38,504 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.final_layer_norm.bias
2022-03-31 10:10:38,504 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.k_proj.weight
2022-03-31 10:10:38,504 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.k_proj.bias
2022-03-31 10:10:38,504 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.v_proj.weight
2022-03-31 10:10:38,504 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.v_proj.bias
2022-03-31 10:10:38,504 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.q_proj.weight
2022-03-31 10:10:38,504 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.q_proj.bias
2022-03-31 10:10:38,504 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.out_proj.weight
2022-03-31 10:10:38,504 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.out_proj.bias
2022-03-31 10:10:38,505 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn_layer_norm.weight
2022-03-31 10:10:38,505 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn_layer_norm.bias
2022-03-31 10:10:38,505 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.fc1.weight
2022-03-31 10:10:38,505 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.fc1.bias
2022-03-31 10:10:38,505 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.fc2.weight
2022-03-31 10:10:38,505 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.fc2.bias
2022-03-31 10:10:38,505 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.final_layer_norm.weight
2022-03-31 10:10:38,505 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.final_layer_norm.bias
2022-03-31 10:10:38,505 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.k_proj.weight
2022-03-31 10:10:38,505 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.k_proj.bias
2022-03-31 10:10:38,505 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.v_proj.weight
2022-03-31 10:10:38,505 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.v_proj.bias
2022-03-31 10:10:38,505 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.q_proj.weight
2022-03-31 10:10:38,505 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.q_proj.bias
2022-03-31 10:10:38,506 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.out_proj.weight
2022-03-31 10:10:38,506 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.out_proj.bias
2022-03-31 10:10:38,506 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn_layer_norm.weight
2022-03-31 10:10:38,506 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn_layer_norm.bias
2022-03-31 10:10:38,506 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.fc1.weight
2022-03-31 10:10:38,506 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.fc1.bias
2022-03-31 10:10:38,506 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.fc2.weight
2022-03-31 10:10:38,506 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.fc2.bias
2022-03-31 10:10:38,506 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.final_layer_norm.weight
2022-03-31 10:10:38,506 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.final_layer_norm.bias
2022-03-31 10:10:38,506 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.k_proj.weight
2022-03-31 10:10:38,506 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.k_proj.bias
2022-03-31 10:10:38,507 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.v_proj.weight
2022-03-31 10:10:38,507 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.v_proj.bias
2022-03-31 10:10:38,507 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.q_proj.weight
2022-03-31 10:10:38,507 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.q_proj.bias
2022-03-31 10:10:38,507 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.out_proj.weight
2022-03-31 10:10:38,507 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.out_proj.bias
2022-03-31 10:10:38,507 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn_layer_norm.weight
2022-03-31 10:10:38,507 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn_layer_norm.bias
2022-03-31 10:10:38,507 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.fc1.weight
2022-03-31 10:10:38,507 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.fc1.bias
2022-03-31 10:10:38,507 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.fc2.weight
2022-03-31 10:10:38,507 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.fc2.bias
2022-03-31 10:10:38,508 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.final_layer_norm.weight
2022-03-31 10:10:38,508 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.final_layer_norm.bias
2022-03-31 10:10:38,508 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.k_proj.weight
2022-03-31 10:10:38,508 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.k_proj.bias
2022-03-31 10:10:38,508 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.v_proj.weight
2022-03-31 10:10:38,508 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.v_proj.bias
2022-03-31 10:10:38,508 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.q_proj.weight
2022-03-31 10:10:38,508 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.q_proj.bias
2022-03-31 10:10:38,508 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.out_proj.weight
2022-03-31 10:10:38,508 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.out_proj.bias
2022-03-31 10:10:38,508 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn_layer_norm.weight
2022-03-31 10:10:38,509 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn_layer_norm.bias
2022-03-31 10:10:38,509 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.fc1.weight
2022-03-31 10:10:38,509 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.fc1.bias
2022-03-31 10:10:38,509 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.fc2.weight
2022-03-31 10:10:38,509 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.fc2.bias
2022-03-31 10:10:38,509 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.final_layer_norm.weight
2022-03-31 10:10:38,509 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.final_layer_norm.bias
2022-03-31 10:10:38,509 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.k_proj.weight
2022-03-31 10:10:38,509 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.k_proj.bias
2022-03-31 10:10:38,509 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.v_proj.weight
2022-03-31 10:10:38,509 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.v_proj.bias
2022-03-31 10:10:38,510 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.q_proj.weight
2022-03-31 10:10:38,510 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.q_proj.bias
2022-03-31 10:10:38,510 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.out_proj.weight
2022-03-31 10:10:38,510 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.out_proj.bias
2022-03-31 10:10:38,510 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn_layer_norm.weight
2022-03-31 10:10:38,510 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn_layer_norm.bias
2022-03-31 10:10:38,510 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.fc1.weight
2022-03-31 10:10:38,510 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.fc1.bias
2022-03-31 10:10:38,510 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.fc2.weight
2022-03-31 10:10:38,510 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.fc2.bias
2022-03-31 10:10:38,510 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.final_layer_norm.weight
2022-03-31 10:10:38,510 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.final_layer_norm.bias
2022-03-31 10:10:38,511 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.k_proj.weight
2022-03-31 10:10:38,511 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.k_proj.bias
2022-03-31 10:10:38,511 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.v_proj.weight
2022-03-31 10:10:38,511 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.v_proj.bias
2022-03-31 10:10:38,511 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.q_proj.weight
2022-03-31 10:10:38,511 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.q_proj.bias
2022-03-31 10:10:38,511 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.out_proj.weight
2022-03-31 10:10:38,511 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.out_proj.bias
2022-03-31 10:10:38,511 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn_layer_norm.weight
2022-03-31 10:10:38,511 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn_layer_norm.bias
2022-03-31 10:10:38,511 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.fc1.weight
2022-03-31 10:10:38,512 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.fc1.bias
2022-03-31 10:10:38,512 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.fc2.weight
2022-03-31 10:10:38,512 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.fc2.bias
2022-03-31 10:10:38,512 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.final_layer_norm.weight
2022-03-31 10:10:38,512 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.final_layer_norm.bias
2022-03-31 10:10:38,512 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.k_proj.weight
2022-03-31 10:10:38,512 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.k_proj.bias
2022-03-31 10:10:38,512 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.v_proj.weight
2022-03-31 10:10:38,512 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.v_proj.bias
2022-03-31 10:10:38,512 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.q_proj.weight
2022-03-31 10:10:38,512 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.q_proj.bias
2022-03-31 10:10:38,513 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.out_proj.weight
2022-03-31 10:10:38,513 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.out_proj.bias
2022-03-31 10:10:38,513 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn_layer_norm.weight
2022-03-31 10:10:38,513 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn_layer_norm.bias
2022-03-31 10:10:38,513 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.fc1.weight
2022-03-31 10:10:38,513 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.fc1.bias
2022-03-31 10:10:38,513 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.fc2.weight
2022-03-31 10:10:38,513 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.fc2.bias
2022-03-31 10:10:38,513 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.final_layer_norm.weight
2022-03-31 10:10:38,513 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.final_layer_norm.bias
2022-03-31 10:10:38,513 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.k_proj.weight
2022-03-31 10:10:38,513 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.k_proj.bias
2022-03-31 10:10:38,514 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.v_proj.weight
2022-03-31 10:10:38,514 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.v_proj.bias
2022-03-31 10:10:38,514 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.q_proj.weight
2022-03-31 10:10:38,514 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.q_proj.bias
2022-03-31 10:10:38,514 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.out_proj.weight
2022-03-31 10:10:38,514 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.out_proj.bias
2022-03-31 10:10:38,514 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn_layer_norm.weight
2022-03-31 10:10:38,514 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn_layer_norm.bias
2022-03-31 10:10:38,514 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.fc1.weight
2022-03-31 10:10:38,514 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.fc1.bias
2022-03-31 10:10:38,514 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.fc2.weight
2022-03-31 10:10:38,515 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.fc2.bias
2022-03-31 10:10:38,515 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.final_layer_norm.weight
2022-03-31 10:10:38,515 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.final_layer_norm.bias
2022-03-31 10:10:38,515 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.k_proj.weight
2022-03-31 10:10:38,515 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.k_proj.bias
2022-03-31 10:10:38,515 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.v_proj.weight
2022-03-31 10:10:38,515 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.v_proj.bias
2022-03-31 10:10:38,515 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.q_proj.weight
2022-03-31 10:10:38,515 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.q_proj.bias
2022-03-31 10:10:38,515 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.out_proj.weight
2022-03-31 10:10:38,515 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.out_proj.bias
2022-03-31 10:10:38,516 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn_layer_norm.weight
2022-03-31 10:10:38,516 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn_layer_norm.bias
2022-03-31 10:10:38,516 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.fc1.weight
2022-03-31 10:10:38,516 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.fc1.bias
2022-03-31 10:10:38,516 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.fc2.weight
2022-03-31 10:10:38,516 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.fc2.bias
2022-03-31 10:10:38,516 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.final_layer_norm.weight
2022-03-31 10:10:38,516 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.final_layer_norm.bias
2022-03-31 10:10:38,516 - INFO - allennlp.common.util - _seq2seq.model.encoder.layernorm_embedding.weight
2022-03-31 10:10:38,516 - INFO - allennlp.common.util - _seq2seq.model.encoder.layernorm_embedding.bias
2022-03-31 10:10:38,516 - INFO - allennlp.common.util - _seq2seq.model.decoder.embed_positions.weight
2022-03-31 10:10:38,517 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.k_proj.weight
2022-03-31 10:10:38,517 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.k_proj.bias
2022-03-31 10:10:38,517 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.v_proj.weight
2022-03-31 10:10:38,517 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.v_proj.bias
2022-03-31 10:10:38,517 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.q_proj.weight
2022-03-31 10:10:38,517 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.q_proj.bias
2022-03-31 10:10:38,517 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.out_proj.weight
2022-03-31 10:10:38,517 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.out_proj.bias
2022-03-31 10:10:38,517 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn_layer_norm.weight
2022-03-31 10:10:38,517 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn_layer_norm.bias
2022-03-31 10:10:38,517 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.k_proj.weight
2022-03-31 10:10:38,518 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.k_proj.bias
2022-03-31 10:10:38,518 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.v_proj.weight
2022-03-31 10:10:38,518 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.v_proj.bias
2022-03-31 10:10:38,518 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.q_proj.weight
2022-03-31 10:10:38,518 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.q_proj.bias
2022-03-31 10:10:38,518 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.out_proj.weight
2022-03-31 10:10:38,518 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.out_proj.bias
2022-03-31 10:10:38,518 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn_layer_norm.weight
2022-03-31 10:10:38,518 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn_layer_norm.bias
2022-03-31 10:10:38,518 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.fc1.weight
2022-03-31 10:10:38,518 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.fc1.bias
2022-03-31 10:10:38,518 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.fc2.weight
2022-03-31 10:10:38,519 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.fc2.bias
2022-03-31 10:10:38,519 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.final_layer_norm.weight
2022-03-31 10:10:38,519 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.final_layer_norm.bias
2022-03-31 10:10:38,519 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.k_proj.weight
2022-03-31 10:10:38,519 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.k_proj.bias
2022-03-31 10:10:38,519 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.v_proj.weight
2022-03-31 10:10:38,519 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.v_proj.bias
2022-03-31 10:10:38,519 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.q_proj.weight
2022-03-31 10:10:38,519 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.q_proj.bias
2022-03-31 10:10:38,519 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.out_proj.weight
2022-03-31 10:10:38,519 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.out_proj.bias
2022-03-31 10:10:38,520 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn_layer_norm.weight
2022-03-31 10:10:38,520 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn_layer_norm.bias
2022-03-31 10:10:38,520 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.k_proj.weight
2022-03-31 10:10:38,520 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.k_proj.bias
2022-03-31 10:10:38,520 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.v_proj.weight
2022-03-31 10:10:38,520 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.v_proj.bias
2022-03-31 10:10:38,520 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.q_proj.weight
2022-03-31 10:10:38,520 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.q_proj.bias
2022-03-31 10:10:38,520 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.out_proj.weight
2022-03-31 10:10:38,520 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.out_proj.bias
2022-03-31 10:10:38,520 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn_layer_norm.weight
2022-03-31 10:10:38,520 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn_layer_norm.bias
2022-03-31 10:10:38,521 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.fc1.weight
2022-03-31 10:10:38,521 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.fc1.bias
2022-03-31 10:10:38,521 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.fc2.weight
2022-03-31 10:10:38,521 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.fc2.bias
2022-03-31 10:10:38,521 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.final_layer_norm.weight
2022-03-31 10:10:38,521 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.final_layer_norm.bias
2022-03-31 10:10:38,521 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.k_proj.weight
2022-03-31 10:10:38,521 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.k_proj.bias
2022-03-31 10:10:38,521 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.v_proj.weight
2022-03-31 10:10:38,521 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.v_proj.bias
2022-03-31 10:10:38,521 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.q_proj.weight
2022-03-31 10:10:38,522 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.q_proj.bias
2022-03-31 10:10:38,522 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.out_proj.weight
2022-03-31 10:10:38,522 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.out_proj.bias
2022-03-31 10:10:38,522 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn_layer_norm.weight
2022-03-31 10:10:38,522 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn_layer_norm.bias
2022-03-31 10:10:38,522 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.k_proj.weight
2022-03-31 10:10:38,522 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.k_proj.bias
2022-03-31 10:10:38,522 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.v_proj.weight
2022-03-31 10:10:38,522 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.v_proj.bias
2022-03-31 10:10:38,522 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.q_proj.weight
2022-03-31 10:10:38,522 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.q_proj.bias
2022-03-31 10:10:38,523 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.out_proj.weight
2022-03-31 10:10:38,523 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.out_proj.bias
2022-03-31 10:10:38,523 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn_layer_norm.weight
2022-03-31 10:10:38,523 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn_layer_norm.bias
2022-03-31 10:10:38,523 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.fc1.weight
2022-03-31 10:10:38,523 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.fc1.bias
2022-03-31 10:10:38,523 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.fc2.weight
2022-03-31 10:10:38,523 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.fc2.bias
2022-03-31 10:10:38,523 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.final_layer_norm.weight
2022-03-31 10:10:38,523 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.final_layer_norm.bias
2022-03-31 10:10:38,523 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.k_proj.weight
2022-03-31 10:10:38,524 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.k_proj.bias
2022-03-31 10:10:38,524 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.v_proj.weight
2022-03-31 10:10:38,524 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.v_proj.bias
2022-03-31 10:10:38,524 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.q_proj.weight
2022-03-31 10:10:38,524 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.q_proj.bias
2022-03-31 10:10:38,524 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.out_proj.weight
2022-03-31 10:10:38,524 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.out_proj.bias
2022-03-31 10:10:38,524 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn_layer_norm.weight
2022-03-31 10:10:38,524 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn_layer_norm.bias
2022-03-31 10:10:38,524 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.k_proj.weight
2022-03-31 10:10:38,524 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.k_proj.bias
2022-03-31 10:10:38,525 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.v_proj.weight
2022-03-31 10:10:38,525 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.v_proj.bias
2022-03-31 10:10:38,525 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.q_proj.weight
2022-03-31 10:10:38,525 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.q_proj.bias
2022-03-31 10:10:38,525 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.out_proj.weight
2022-03-31 10:10:38,525 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.out_proj.bias
2022-03-31 10:10:38,525 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn_layer_norm.weight
2022-03-31 10:10:38,525 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn_layer_norm.bias
2022-03-31 10:10:38,525 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.fc1.weight
2022-03-31 10:10:38,525 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.fc1.bias
2022-03-31 10:10:38,525 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.fc2.weight
2022-03-31 10:10:38,526 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.fc2.bias
2022-03-31 10:10:38,526 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.final_layer_norm.weight
2022-03-31 10:10:38,526 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.final_layer_norm.bias
2022-03-31 10:10:38,526 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.k_proj.weight
2022-03-31 10:10:38,526 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.k_proj.bias
2022-03-31 10:10:38,526 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.v_proj.weight
2022-03-31 10:10:38,526 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.v_proj.bias
2022-03-31 10:10:38,526 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.q_proj.weight
2022-03-31 10:10:38,526 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.q_proj.bias
2022-03-31 10:10:38,526 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.out_proj.weight
2022-03-31 10:10:38,526 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.out_proj.bias
2022-03-31 10:10:38,527 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn_layer_norm.weight
2022-03-31 10:10:38,527 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn_layer_norm.bias
2022-03-31 10:10:38,527 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.k_proj.weight
2022-03-31 10:10:38,527 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.k_proj.bias
2022-03-31 10:10:38,527 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.v_proj.weight
2022-03-31 10:10:38,527 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.v_proj.bias
2022-03-31 10:10:38,527 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.q_proj.weight
2022-03-31 10:10:38,527 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.q_proj.bias
2022-03-31 10:10:38,527 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.out_proj.weight
2022-03-31 10:10:38,527 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.out_proj.bias
2022-03-31 10:10:38,527 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn_layer_norm.weight
2022-03-31 10:10:38,528 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn_layer_norm.bias
2022-03-31 10:10:38,528 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.fc1.weight
2022-03-31 10:10:38,528 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.fc1.bias
2022-03-31 10:10:38,528 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.fc2.weight
2022-03-31 10:10:38,528 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.fc2.bias
2022-03-31 10:10:38,528 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.final_layer_norm.weight
2022-03-31 10:10:38,528 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.final_layer_norm.bias
2022-03-31 10:10:38,528 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.k_proj.weight
2022-03-31 10:10:38,528 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.k_proj.bias
2022-03-31 10:10:38,528 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.v_proj.weight
2022-03-31 10:10:38,529 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.v_proj.bias
2022-03-31 10:10:38,529 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.q_proj.weight
2022-03-31 10:10:38,529 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.q_proj.bias
2022-03-31 10:10:38,529 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.out_proj.weight
2022-03-31 10:10:38,529 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.out_proj.bias
2022-03-31 10:10:38,529 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn_layer_norm.weight
2022-03-31 10:10:38,529 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn_layer_norm.bias
2022-03-31 10:10:38,529 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.k_proj.weight
2022-03-31 10:10:38,529 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.k_proj.bias
2022-03-31 10:10:38,529 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.v_proj.weight
2022-03-31 10:10:38,529 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.v_proj.bias
2022-03-31 10:10:38,530 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.q_proj.weight
2022-03-31 10:10:38,530 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.q_proj.bias
2022-03-31 10:10:38,530 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.out_proj.weight
2022-03-31 10:10:38,530 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.out_proj.bias
2022-03-31 10:10:38,530 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn_layer_norm.weight
2022-03-31 10:10:38,530 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn_layer_norm.bias
2022-03-31 10:10:38,530 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.fc1.weight
2022-03-31 10:10:38,530 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.fc1.bias
2022-03-31 10:10:38,530 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.fc2.weight
2022-03-31 10:10:38,530 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.fc2.bias
2022-03-31 10:10:38,530 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.final_layer_norm.weight
2022-03-31 10:10:38,531 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.final_layer_norm.bias
2022-03-31 10:10:38,531 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.k_proj.weight
2022-03-31 10:10:38,531 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.k_proj.bias
2022-03-31 10:10:38,531 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.v_proj.weight
2022-03-31 10:10:38,531 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.v_proj.bias
2022-03-31 10:10:38,531 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.q_proj.weight
2022-03-31 10:10:38,531 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.q_proj.bias
2022-03-31 10:10:38,531 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.out_proj.weight
2022-03-31 10:10:38,531 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.out_proj.bias
2022-03-31 10:10:38,531 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn_layer_norm.weight
2022-03-31 10:10:38,531 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn_layer_norm.bias
2022-03-31 10:10:38,532 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.k_proj.weight
2022-03-31 10:10:38,532 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.k_proj.bias
2022-03-31 10:10:38,532 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.v_proj.weight
2022-03-31 10:10:38,532 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.v_proj.bias
2022-03-31 10:10:38,532 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.q_proj.weight
2022-03-31 10:10:38,532 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.q_proj.bias
2022-03-31 10:10:38,532 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.out_proj.weight
2022-03-31 10:10:38,532 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.out_proj.bias
2022-03-31 10:10:38,532 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn_layer_norm.weight
2022-03-31 10:10:38,532 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn_layer_norm.bias
2022-03-31 10:10:38,532 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.fc1.weight
2022-03-31 10:10:38,533 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.fc1.bias
2022-03-31 10:10:38,533 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.fc2.weight
2022-03-31 10:10:38,533 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.fc2.bias
2022-03-31 10:10:38,533 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.final_layer_norm.weight
2022-03-31 10:10:38,533 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.final_layer_norm.bias
2022-03-31 10:10:38,533 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.k_proj.weight
2022-03-31 10:10:38,533 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.k_proj.bias
2022-03-31 10:10:38,533 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.v_proj.weight
2022-03-31 10:10:38,533 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.v_proj.bias
2022-03-31 10:10:38,533 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.q_proj.weight
2022-03-31 10:10:38,534 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.q_proj.bias
2022-03-31 10:10:38,534 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.out_proj.weight
2022-03-31 10:10:38,534 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.out_proj.bias
2022-03-31 10:10:38,534 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn_layer_norm.weight
2022-03-31 10:10:38,534 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn_layer_norm.bias
2022-03-31 10:10:38,534 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.k_proj.weight
2022-03-31 10:10:38,534 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.k_proj.bias
2022-03-31 10:10:38,534 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.v_proj.weight
2022-03-31 10:10:38,534 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.v_proj.bias
2022-03-31 10:10:38,534 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.q_proj.weight
2022-03-31 10:10:38,534 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.q_proj.bias
2022-03-31 10:10:38,535 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.out_proj.weight
2022-03-31 10:10:38,535 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.out_proj.bias
2022-03-31 10:10:38,535 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn_layer_norm.weight
2022-03-31 10:10:38,535 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn_layer_norm.bias
2022-03-31 10:10:38,535 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.fc1.weight
2022-03-31 10:10:38,535 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.fc1.bias
2022-03-31 10:10:38,535 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.fc2.weight
2022-03-31 10:10:38,535 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.fc2.bias
2022-03-31 10:10:38,535 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.final_layer_norm.weight
2022-03-31 10:10:38,535 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.final_layer_norm.bias
2022-03-31 10:10:38,536 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.k_proj.weight
2022-03-31 10:10:38,536 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.k_proj.bias
2022-03-31 10:10:38,536 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.v_proj.weight
2022-03-31 10:10:38,536 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.v_proj.bias
2022-03-31 10:10:38,536 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.q_proj.weight
2022-03-31 10:10:38,536 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.q_proj.bias
2022-03-31 10:10:38,536 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.out_proj.weight
2022-03-31 10:10:38,536 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.out_proj.bias
2022-03-31 10:10:38,536 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn_layer_norm.weight
2022-03-31 10:10:38,536 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn_layer_norm.bias
2022-03-31 10:10:38,536 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.k_proj.weight
2022-03-31 10:10:38,537 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.k_proj.bias
2022-03-31 10:10:38,537 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.v_proj.weight
2022-03-31 10:10:38,537 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.v_proj.bias
2022-03-31 10:10:38,537 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.q_proj.weight
2022-03-31 10:10:38,537 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.q_proj.bias
2022-03-31 10:10:38,537 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.out_proj.weight
2022-03-31 10:10:38,537 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.out_proj.bias
2022-03-31 10:10:38,537 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn_layer_norm.weight
2022-03-31 10:10:38,537 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn_layer_norm.bias
2022-03-31 10:10:38,537 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.fc1.weight
2022-03-31 10:10:38,537 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.fc1.bias
2022-03-31 10:10:38,537 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.fc2.weight
2022-03-31 10:10:38,537 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.fc2.bias
2022-03-31 10:10:38,538 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.final_layer_norm.weight
2022-03-31 10:10:38,538 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.final_layer_norm.bias
2022-03-31 10:10:38,538 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.k_proj.weight
2022-03-31 10:10:38,538 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.k_proj.bias
2022-03-31 10:10:38,538 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.v_proj.weight
2022-03-31 10:10:38,538 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.v_proj.bias
2022-03-31 10:10:38,538 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.q_proj.weight
2022-03-31 10:10:38,538 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.q_proj.bias
2022-03-31 10:10:38,538 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.out_proj.weight
2022-03-31 10:10:38,538 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.out_proj.bias
2022-03-31 10:10:38,538 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn_layer_norm.weight
2022-03-31 10:10:38,538 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn_layer_norm.bias
2022-03-31 10:10:38,539 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.k_proj.weight
2022-03-31 10:10:38,539 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.k_proj.bias
2022-03-31 10:10:38,539 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.v_proj.weight
2022-03-31 10:10:38,539 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.v_proj.bias
2022-03-31 10:10:38,539 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.q_proj.weight
2022-03-31 10:10:38,539 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.q_proj.bias
2022-03-31 10:10:38,539 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.out_proj.weight
2022-03-31 10:10:38,539 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.out_proj.bias
2022-03-31 10:10:38,539 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn_layer_norm.weight
2022-03-31 10:10:38,539 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn_layer_norm.bias
2022-03-31 10:10:38,540 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.fc1.weight
2022-03-31 10:10:38,540 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.fc1.bias
2022-03-31 10:10:38,540 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.fc2.weight
2022-03-31 10:10:38,540 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.fc2.bias
2022-03-31 10:10:38,540 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.final_layer_norm.weight
2022-03-31 10:10:38,540 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.final_layer_norm.bias
2022-03-31 10:10:38,540 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.k_proj.weight
2022-03-31 10:10:38,540 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.k_proj.bias
2022-03-31 10:10:38,540 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.v_proj.weight
2022-03-31 10:10:38,540 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.v_proj.bias
2022-03-31 10:10:38,540 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.q_proj.weight
2022-03-31 10:10:38,541 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.q_proj.bias
2022-03-31 10:10:38,541 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.out_proj.weight
2022-03-31 10:10:38,541 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.out_proj.bias
2022-03-31 10:10:38,541 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn_layer_norm.weight
2022-03-31 10:10:38,541 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn_layer_norm.bias
2022-03-31 10:10:38,541 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.k_proj.weight
2022-03-31 10:10:38,541 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.k_proj.bias
2022-03-31 10:10:38,541 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.v_proj.weight
2022-03-31 10:10:38,541 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.v_proj.bias
2022-03-31 10:10:38,541 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.q_proj.weight
2022-03-31 10:10:38,541 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.q_proj.bias
2022-03-31 10:10:38,542 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.out_proj.weight
2022-03-31 10:10:38,542 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.out_proj.bias
2022-03-31 10:10:38,542 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn_layer_norm.weight
2022-03-31 10:10:38,542 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn_layer_norm.bias
2022-03-31 10:10:38,542 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.fc1.weight
2022-03-31 10:10:38,542 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.fc1.bias
2022-03-31 10:10:38,542 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.fc2.weight
2022-03-31 10:10:38,542 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.fc2.bias
2022-03-31 10:10:38,542 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.final_layer_norm.weight
2022-03-31 10:10:38,542 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.final_layer_norm.bias
2022-03-31 10:10:38,542 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.k_proj.weight
2022-03-31 10:10:38,543 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.k_proj.bias
2022-03-31 10:10:38,543 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.v_proj.weight
2022-03-31 10:10:38,543 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.v_proj.bias
2022-03-31 10:10:38,543 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.q_proj.weight
2022-03-31 10:10:38,543 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.q_proj.bias
2022-03-31 10:10:38,543 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.out_proj.weight
2022-03-31 10:10:38,543 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.out_proj.bias
2022-03-31 10:10:38,543 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn_layer_norm.weight
2022-03-31 10:10:38,543 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn_layer_norm.bias
2022-03-31 10:10:38,543 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.k_proj.weight
2022-03-31 10:10:38,543 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.k_proj.bias
2022-03-31 10:10:38,544 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.v_proj.weight
2022-03-31 10:10:38,544 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.v_proj.bias
2022-03-31 10:10:38,544 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.q_proj.weight
2022-03-31 10:10:38,544 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.q_proj.bias
2022-03-31 10:10:38,544 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.out_proj.weight
2022-03-31 10:10:38,544 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.out_proj.bias
2022-03-31 10:10:38,544 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn_layer_norm.weight
2022-03-31 10:10:38,544 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn_layer_norm.bias
2022-03-31 10:10:38,544 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.fc1.weight
2022-03-31 10:10:38,544 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.fc1.bias
2022-03-31 10:10:38,544 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.fc2.weight
2022-03-31 10:10:38,545 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.fc2.bias
2022-03-31 10:10:38,545 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.final_layer_norm.weight
2022-03-31 10:10:38,545 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.final_layer_norm.bias
2022-03-31 10:10:38,545 - INFO - allennlp.common.util - _seq2seq.model.decoder.layernorm_embedding.weight
2022-03-31 10:10:38,545 - INFO - allennlp.common.util - _seq2seq.model.decoder.layernorm_embedding.bias
2022-03-31 10:10:38,545 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = polynomial_decay
2022-03-31 10:10:38,546 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.power = 1.0
2022-03-31 10:10:38,546 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.warmup_steps = 0
2022-03-31 10:10:38,546 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.end_learning_rate = 0.0
2022-03-31 10:10:38,546 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.last_epoch = -1
2022-03-31 10:10:38,546 - INFO - allennlp.common.params - trainer.checkpointer.type = default
2022-03-31 10:10:38,546 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None
2022-03-31 10:10:38,546 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = -1
2022-03-31 10:10:38,546 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None
2022-03-31 10:10:38,547 - INFO - allennlp.common.params - summary_interval = 100
2022-03-31 10:10:38,547 - INFO - allennlp.common.params - histogram_interval = None
2022-03-31 10:10:38,547 - INFO - allennlp.common.params - batch_size_interval = None
2022-03-31 10:10:38,547 - INFO - allennlp.common.params - should_log_parameter_statistics = True
2022-03-31 10:10:38,547 - INFO - allennlp.common.params - should_log_learning_rate = False
2022-03-31 10:10:38,547 - INFO - allennlp.common.params - get_batch_num_total = None
2022-03-31 10:10:38,550 - WARNING - allennlp.training.trainer - You provided a validation dataset but patience was set to None, meaning that early stopping is disabled
2022-03-31 10:10:38,568 - INFO - allennlp.training.trainer - Beginning training.
2022-03-31 10:10:38,568 - INFO - allennlp.training.trainer - Epoch 0/14
2022-03-31 10:10:38,568 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.1G
2022-03-31 10:10:38,569 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.5G
2022-03-31 10:10:38,570 - INFO - allennlp.training.trainer - Training
2022-03-31 10:10:38,570 - INFO - tqdm - 0%|          | 0/65 [00:00<?, ?it/s]
2022-03-31 10:10:38,570 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-31 10:10:38,570 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['target_ids'] as the sorting keys
2022-03-31 10:10:48,961 - INFO - tqdm - batch_loss: 4.6631, loss: 7.2512 ||:   9%|9         | 6/65 [00:10<01:42,  1.73s/it]
2022-03-31 10:10:59,176 - INFO - tqdm - batch_loss: 3.6637, loss: 5.6479 ||:  18%|#8        | 12/65 [00:20<01:30,  1.70s/it]
2022-03-31 10:11:09,442 - INFO - tqdm - batch_loss: 2.9293, loss: 4.8388 ||:  28%|##7       | 18/65 [00:30<01:20,  1.72s/it]
2022-03-31 10:11:19,711 - INFO - tqdm - batch_loss: 2.8196, loss: 4.3495 ||:  37%|###6      | 24/65 [00:41<01:09,  1.70s/it]
2022-03-31 10:11:30,001 - INFO - tqdm - batch_loss: 2.6158, loss: 4.0031 ||:  46%|####6     | 30/65 [00:51<01:00,  1.72s/it]
2022-03-31 10:11:40,281 - INFO - tqdm - batch_loss: 2.3476, loss: 3.7600 ||:  55%|#####5    | 36/65 [01:01<00:49,  1.71s/it]
2022-03-31 10:11:50,573 - INFO - tqdm - batch_loss: 2.3328, loss: 3.5554 ||:  65%|######4   | 42/65 [01:12<00:39,  1.71s/it]
2022-03-31 10:12:00,928 - INFO - tqdm - batch_loss: 2.0715, loss: 3.3845 ||:  74%|#######3  | 48/65 [01:22<00:28,  1.71s/it]
2022-03-31 10:12:11,609 - INFO - tqdm - batch_loss: 2.3682, loss: 3.2451 ||:  83%|########3 | 54/65 [01:33<00:19,  1.76s/it]
2022-03-31 10:12:22,038 - INFO - tqdm - batch_loss: 2.2010, loss: 3.1329 ||:  92%|#########2| 60/65 [01:43<00:08,  1.74s/it]
2022-03-31 10:12:29,939 - INFO - tqdm - batch_loss: 2.1960, loss: 3.0516 ||: 100%|##########| 65/65 [01:51<00:00,  1.49s/it]
2022-03-31 10:12:29,940 - INFO - tqdm - batch_loss: 2.1960, loss: 3.0516 ||: 100%|##########| 65/65 [01:51<00:00,  1.71s/it]
2022-03-31 10:12:33,082 - INFO - allennlp.training.trainer - Validating
2022-03-31 10:12:33,083 - INFO - tqdm - 0%|          | 0/115 [00:00<?, ?it/s]
2022-03-31 10:12:33,084 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-31 10:12:33,084 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['target_ids'] as the sorting keys
2022-03-31 10:12:43,253 - INFO - tqdm - bleu_BLEU: 0.1800, rouge_ROUGE-1_R: 0.4403, rouge_ROUGE-2_R: 0.2812, rouge_ROUGE-1_P: 0.7007, rouge_ROUGE-2_P: 0.4622, rouge_ROUGE-1_F1: 0.5315, rouge_ROUGE-2_F1: 0.3440, rouge_ROUGE-L: 0.4784, SARI: 0.5175, count: 22.0000, batch_loss: 1.4459, loss: 1.6388 ||:  10%|9         | 11/115 [00:10<01:38,  1.05it/s]
2022-03-31 10:12:53,653 - INFO - tqdm - bleu_BLEU: 0.1939, rouge_ROUGE-1_R: 0.4650, rouge_ROUGE-2_R: 0.2974, rouge_ROUGE-1_P: 0.6838, rouge_ROUGE-2_P: 0.4467, rouge_ROUGE-1_F1: 0.5442, rouge_ROUGE-2_F1: 0.3510, rouge_ROUGE-L: 0.4798, SARI: 0.5173, count: 44.0000, batch_loss: 1.5974, loss: 1.5615 ||:  19%|#9        | 22/115 [00:20<01:27,  1.06it/s]
2022-03-31 10:13:03,931 - INFO - tqdm - bleu_BLEU: 0.2070, rouge_ROUGE-1_R: 0.4876, rouge_ROUGE-2_R: 0.3103, rouge_ROUGE-1_P: 0.6880, rouge_ROUGE-2_P: 0.4489, rouge_ROUGE-1_F1: 0.5600, rouge_ROUGE-2_F1: 0.3598, rouge_ROUGE-L: 0.4931, SARI: 0.5204, count: 66.0000, batch_loss: 1.1521, loss: 1.5460 ||:  29%|##8       | 33/115 [00:30<01:17,  1.06it/s]
2022-03-31 10:13:14,840 - INFO - tqdm - bleu_BLEU: 0.2180, rouge_ROUGE-1_R: 0.4972, rouge_ROUGE-2_R: 0.3217, rouge_ROUGE-1_P: 0.6912, rouge_ROUGE-2_P: 0.4546, rouge_ROUGE-1_F1: 0.5668, rouge_ROUGE-2_F1: 0.3690, rouge_ROUGE-L: 0.4994, SARI: 0.5318, count: 88.0000, batch_loss: 2.1173, loss: 1.5976 ||:  38%|###8      | 44/115 [00:41<01:10,  1.00it/s]
2022-03-31 10:13:25,250 - INFO - tqdm - bleu_BLEU: 0.2101, rouge_ROUGE-1_R: 0.4915, rouge_ROUGE-2_R: 0.3186, rouge_ROUGE-1_P: 0.6891, rouge_ROUGE-2_P: 0.4534, rouge_ROUGE-1_F1: 0.5624, rouge_ROUGE-2_F1: 0.3665, rouge_ROUGE-L: 0.4944, SARI: 0.5275, count: 110.0000, batch_loss: 1.2593, loss: 1.5870 ||:  48%|####7     | 55/115 [00:52<00:55,  1.09it/s]
2022-03-31 10:13:35,657 - INFO - tqdm - bleu_BLEU: 0.2013, rouge_ROUGE-1_R: 0.4845, rouge_ROUGE-2_R: 0.3146, rouge_ROUGE-1_P: 0.6932, rouge_ROUGE-2_P: 0.4585, rouge_ROUGE-1_F1: 0.5578, rouge_ROUGE-2_F1: 0.3645, rouge_ROUGE-L: 0.4871, SARI: 0.5286, count: 132.0000, batch_loss: 1.2590, loss: 1.6133 ||:  57%|#####7    | 66/115 [01:02<00:48,  1.02it/s]
2022-03-31 10:13:45,771 - INFO - tqdm - bleu_BLEU: 0.1938, rouge_ROUGE-1_R: 0.4742, rouge_ROUGE-2_R: 0.3081, rouge_ROUGE-1_P: 0.6963, rouge_ROUGE-2_P: 0.4606, rouge_ROUGE-1_F1: 0.5520, rouge_ROUGE-2_F1: 0.3609, rouge_ROUGE-L: 0.4822, SARI: 0.5306, count: 153.0000, batch_loss: 2.4268, loss: 1.6458 ||:  67%|######6   | 77/115 [01:12<00:35,  1.08it/s]
2022-03-31 10:13:55,900 - INFO - tqdm - bleu_BLEU: 0.1964, rouge_ROUGE-1_R: 0.4763, rouge_ROUGE-2_R: 0.3090, rouge_ROUGE-1_P: 0.6964, rouge_ROUGE-2_P: 0.4609, rouge_ROUGE-1_F1: 0.5542, rouge_ROUGE-2_F1: 0.3621, rouge_ROUGE-L: 0.4840, SARI: 0.5250, count: 175.0000, batch_loss: 1.3887, loss: 1.6444 ||:  77%|#######6  | 88/115 [01:22<00:24,  1.09it/s]
2022-03-31 10:14:06,717 - INFO - tqdm - bleu_BLEU: 0.1909, rouge_ROUGE-1_R: 0.4710, rouge_ROUGE-2_R: 0.3044, rouge_ROUGE-1_P: 0.6959, rouge_ROUGE-2_P: 0.4584, rouge_ROUGE-1_F1: 0.5502, rouge_ROUGE-2_F1: 0.3579, rouge_ROUGE-L: 0.4798, SARI: 0.5206, count: 197.0000, batch_loss: 1.4708, loss: 1.6483 ||:  86%|########6 | 99/115 [01:33<00:16,  1.01s/it]
2022-03-31 10:14:17,249 - INFO - tqdm - bleu_BLEU: 0.1968, rouge_ROUGE-1_R: 0.4727, rouge_ROUGE-2_R: 0.3083, rouge_ROUGE-1_P: 0.6983, rouge_ROUGE-2_P: 0.4647, rouge_ROUGE-1_F1: 0.5528, rouge_ROUGE-2_F1: 0.3632, rouge_ROUGE-L: 0.4835, SARI: 0.5194, count: 219.0000, batch_loss: 1.3331, loss: 1.6380 ||:  96%|#########5| 110/115 [01:44<00:04,  1.06it/s]
2022-03-31 10:14:21,872 - INFO - tqdm - bleu_BLEU: 0.1983, rouge_ROUGE-1_R: 0.4733, rouge_ROUGE-2_R: 0.3091, rouge_ROUGE-1_P: 0.6984, rouge_ROUGE-2_P: 0.4655, rouge_ROUGE-1_F1: 0.5529, rouge_ROUGE-2_F1: 0.3637, rouge_ROUGE-L: 0.4853, SARI: 0.5213, count: 229.0000, batch_loss: 1.1232, loss: 1.6390 ||: 100%|##########| 115/115 [01:48<00:00,  1.07it/s]
2022-03-31 10:14:21,872 - INFO - tqdm - bleu_BLEU: 0.1983, rouge_ROUGE-1_R: 0.4733, rouge_ROUGE-2_R: 0.3091, rouge_ROUGE-1_P: 0.6984, rouge_ROUGE-2_P: 0.4655, rouge_ROUGE-1_F1: 0.5529, rouge_ROUGE-2_F1: 0.3637, rouge_ROUGE-L: 0.4853, SARI: 0.5213, count: 229.0000, batch_loss: 1.1232, loss: 1.6390 ||: 100%|##########| 115/115 [01:48<00:00,  1.06it/s]
2022-03-31 10:14:21,873 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2022-03-31 10:14:21,873 - INFO - allennlp.training.tensorboard_writer - SARI               |       N/A  |     0.521
2022-03-31 10:14:21,874 - INFO - allennlp.training.tensorboard_writer - bleu_BLEU          |       N/A  |     0.198
2022-03-31 10:14:21,876 - INFO - allennlp.training.tensorboard_writer - count              |       N/A  |   229.000
2022-03-31 10:14:21,877 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |  1550.071  |       N/A
2022-03-31 10:14:21,877 - INFO - allennlp.training.tensorboard_writer - loss               |     3.052  |     1.639
2022-03-31 10:14:21,878 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_F1   |       N/A  |     0.553
2022-03-31 10:14:21,878 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_P    |       N/A  |     0.698
2022-03-31 10:14:21,879 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_R    |       N/A  |     0.473
2022-03-31 10:14:21,879 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_F1   |       N/A  |     0.364
2022-03-31 10:14:21,880 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_P    |       N/A  |     0.466
2022-03-31 10:14:21,880 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_R    |       N/A  |     0.309
2022-03-31 10:14:21,881 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-L      |       N/A  |     0.485
2022-03-31 10:14:21,881 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5241.066  |       N/A
2022-03-31 10:14:28,142 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to './output_decomposition/best.th'.
2022-03-31 10:14:29,542 - INFO - allennlp.training.trainer - Epoch duration: 0:03:50.973571
2022-03-31 10:14:29,542 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:53:53
2022-03-31 10:14:29,542 - INFO - allennlp.training.trainer - Epoch 1/14
2022-03-31 10:14:29,543 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.1G
2022-03-31 10:14:29,543 - INFO - allennlp.training.trainer - GPU 0 memory usage: 6.7G
2022-03-31 10:14:29,544 - INFO - allennlp.training.trainer - Training
2022-03-31 10:14:29,544 - INFO - tqdm - 0%|          | 0/65 [00:00<?, ?it/s]
2022-03-31 10:14:40,125 - INFO - tqdm - batch_loss: 1.9200, loss: 2.0485 ||:   9%|9         | 6/65 [00:10<01:43,  1.76s/it]
2022-03-31 10:14:50,724 - INFO - tqdm - batch_loss: 2.0507, loss: 2.0562 ||:  18%|#8        | 12/65 [00:21<01:33,  1.77s/it]
2022-03-31 10:15:01,481 - INFO - tqdm - batch_loss: 2.2285, loss: 2.0008 ||:  28%|##7       | 18/65 [00:31<01:24,  1.79s/it]
2022-03-31 10:15:12,162 - INFO - tqdm - batch_loss: 1.8251, loss: 1.9640 ||:  37%|###6      | 24/65 [00:42<01:13,  1.78s/it]
2022-03-31 10:15:22,562 - INFO - tqdm - batch_loss: 1.8560, loss: 1.9269 ||:  46%|####6     | 30/65 [00:53<01:00,  1.74s/it]
2022-03-31 10:15:33,599 - INFO - tqdm - batch_loss: 1.7557, loss: 1.9000 ||:  55%|#####5    | 36/65 [01:04<00:53,  1.86s/it]
2022-03-31 10:15:44,114 - INFO - tqdm - batch_loss: 1.8106, loss: 1.8927 ||:  65%|######4   | 42/65 [01:14<00:40,  1.75s/it]
2022-03-31 10:15:54,626 - INFO - tqdm - batch_loss: 1.7460, loss: 1.8779 ||:  74%|#######3  | 48/65 [01:25<00:29,  1.75s/it]
2022-03-31 10:16:05,205 - INFO - tqdm - batch_loss: 1.8962, loss: 1.8653 ||:  83%|########3 | 54/65 [01:35<00:19,  1.76s/it]
2022-03-31 10:16:15,669 - INFO - tqdm - batch_loss: 1.7926, loss: 1.8552 ||:  92%|#########2| 60/65 [01:46<00:08,  1.74s/it]
2022-03-31 10:16:23,457 - INFO - tqdm - batch_loss: 1.6030, loss: 1.8503 ||: 100%|##########| 65/65 [01:53<00:00,  1.46s/it]
2022-03-31 10:16:23,457 - INFO - tqdm - batch_loss: 1.6030, loss: 1.8503 ||: 100%|##########| 65/65 [01:53<00:00,  1.75s/it]
2022-03-31 10:16:26,607 - INFO - allennlp.training.trainer - Validating
2022-03-31 10:16:26,608 - INFO - tqdm - 0%|          | 0/115 [00:00<?, ?it/s]
2022-03-31 10:16:36,877 - INFO - tqdm - bleu_BLEU: 0.1832, rouge_ROUGE-1_R: 0.4485, rouge_ROUGE-2_R: 0.2938, rouge_ROUGE-1_P: 0.6918, rouge_ROUGE-2_P: 0.4612, rouge_ROUGE-1_F1: 0.5382, rouge_ROUGE-2_F1: 0.3543, rouge_ROUGE-L: 0.4535, SARI: 0.5044, count: 22.0000, batch_loss: 1.6321, loss: 1.3397 ||:  10%|9         | 11/115 [00:10<01:33,  1.11it/s]
2022-03-31 10:16:47,844 - INFO - tqdm - bleu_BLEU: 0.2095, rouge_ROUGE-1_R: 0.4752, rouge_ROUGE-2_R: 0.3127, rouge_ROUGE-1_P: 0.7086, rouge_ROUGE-2_P: 0.4766, rouge_ROUGE-1_F1: 0.5608, rouge_ROUGE-2_F1: 0.3719, rouge_ROUGE-L: 0.4845, SARI: 0.5113, count: 46.0000, batch_loss: 1.3222, loss: 1.4715 ||:  20%|##        | 23/115 [00:21<01:29,  1.02it/s]
2022-03-31 10:16:58,696 - INFO - tqdm - bleu_BLEU: 0.2239, rouge_ROUGE-1_R: 0.4914, rouge_ROUGE-2_R: 0.3241, rouge_ROUGE-1_P: 0.6987, rouge_ROUGE-2_P: 0.4710, rouge_ROUGE-1_F1: 0.5687, rouge_ROUGE-2_F1: 0.3782, rouge_ROUGE-L: 0.4909, SARI: 0.5327, count: 69.0000, batch_loss: 1.5157, loss: 1.4034 ||:  30%|###       | 35/115 [00:32<01:13,  1.08it/s]
2022-03-31 10:17:09,612 - INFO - tqdm - bleu_BLEU: 0.2316, rouge_ROUGE-1_R: 0.4887, rouge_ROUGE-2_R: 0.3266, rouge_ROUGE-1_P: 0.7069, rouge_ROUGE-2_P: 0.4834, rouge_ROUGE-1_F1: 0.5696, rouge_ROUGE-2_F1: 0.3841, rouge_ROUGE-L: 0.4933, SARI: 0.5486, count: 93.0000, batch_loss: 1.6701, loss: 1.4133 ||:  41%|####      | 47/115 [00:43<01:03,  1.07it/s]
2022-03-31 10:17:20,152 - INFO - tqdm - bleu_BLEU: 0.2151, rouge_ROUGE-1_R: 0.4768, rouge_ROUGE-2_R: 0.3167, rouge_ROUGE-1_P: 0.7047, rouge_ROUGE-2_P: 0.4772, rouge_ROUGE-1_F1: 0.5602, rouge_ROUGE-2_F1: 0.3748, rouge_ROUGE-L: 0.4873, SARI: 0.5377, count: 117.0000, batch_loss: 0.7111, loss: 1.4177 ||:  51%|#####1    | 59/115 [00:53<00:47,  1.17it/s]
2022-03-31 10:17:30,451 - INFO - tqdm - bleu_BLEU: 0.2087, rouge_ROUGE-1_R: 0.4747, rouge_ROUGE-2_R: 0.3110, rouge_ROUGE-1_P: 0.6932, rouge_ROUGE-2_P: 0.4634, rouge_ROUGE-1_F1: 0.5542, rouge_ROUGE-2_F1: 0.3659, rouge_ROUGE-L: 0.4827, SARI: 0.5245, count: 139.0000, batch_loss: 2.2576, loss: 1.4794 ||:  61%|######    | 70/115 [01:03<00:42,  1.07it/s]
2022-03-31 10:17:41,015 - INFO - tqdm - bleu_BLEU: 0.2116, rouge_ROUGE-1_R: 0.4754, rouge_ROUGE-2_R: 0.3105, rouge_ROUGE-1_P: 0.6877, rouge_ROUGE-2_P: 0.4590, rouge_ROUGE-1_F1: 0.5533, rouge_ROUGE-2_F1: 0.3645, rouge_ROUGE-L: 0.4841, SARI: 0.5213, count: 163.0000, batch_loss: 1.1646, loss: 1.4939 ||:  71%|#######1  | 82/115 [01:14<00:28,  1.15it/s]
2022-03-31 10:17:51,176 - INFO - tqdm - bleu_BLEU: 0.2099, rouge_ROUGE-1_R: 0.4749, rouge_ROUGE-2_R: 0.3111, rouge_ROUGE-1_P: 0.6915, rouge_ROUGE-2_P: 0.4625, rouge_ROUGE-1_F1: 0.5540, rouge_ROUGE-2_F1: 0.3658, rouge_ROUGE-L: 0.4846, SARI: 0.5290, count: 185.0000, batch_loss: 1.2905, loss: 1.4758 ||:  81%|########  | 93/115 [01:24<00:19,  1.11it/s]
2022-03-31 10:18:01,865 - INFO - tqdm - bleu_BLEU: 0.2105, rouge_ROUGE-1_R: 0.4766, rouge_ROUGE-2_R: 0.3111, rouge_ROUGE-1_P: 0.6852, rouge_ROUGE-2_P: 0.4563, rouge_ROUGE-1_F1: 0.5525, rouge_ROUGE-2_F1: 0.3635, rouge_ROUGE-L: 0.4828, SARI: 0.5325, count: 207.0000, batch_loss: 1.2201, loss: 1.4792 ||:  90%|######### | 104/115 [01:35<00:10,  1.05it/s]
2022-03-31 10:18:11,681 - INFO - tqdm - bleu_BLEU: 0.2130, rouge_ROUGE-1_R: 0.4794, rouge_ROUGE-2_R: 0.3128, rouge_ROUGE-1_P: 0.6804, rouge_ROUGE-2_P: 0.4536, rouge_ROUGE-1_F1: 0.5518, rouge_ROUGE-2_F1: 0.3630, rouge_ROUGE-L: 0.4822, SARI: 0.5299, count: 229.0000, batch_loss: 1.4246, loss: 1.4993 ||: 100%|##########| 115/115 [01:45<00:00,  1.10it/s]
2022-03-31 10:18:11,681 - INFO - tqdm - bleu_BLEU: 0.2130, rouge_ROUGE-1_R: 0.4794, rouge_ROUGE-2_R: 0.3128, rouge_ROUGE-1_P: 0.6804, rouge_ROUGE-2_P: 0.4536, rouge_ROUGE-1_F1: 0.5518, rouge_ROUGE-2_F1: 0.3630, rouge_ROUGE-L: 0.4822, SARI: 0.5299, count: 229.0000, batch_loss: 1.4246, loss: 1.4993 ||: 100%|##########| 115/115 [01:45<00:00,  1.09it/s]
2022-03-31 10:18:11,682 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2022-03-31 10:18:11,682 - INFO - allennlp.training.tensorboard_writer - SARI               |       N/A  |     0.530
2022-03-31 10:18:11,683 - INFO - allennlp.training.tensorboard_writer - bleu_BLEU          |       N/A  |     0.213
2022-03-31 10:18:11,683 - INFO - allennlp.training.tensorboard_writer - count              |       N/A  |   229.000
2022-03-31 10:18:11,683 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |  6843.527  |       N/A
2022-03-31 10:18:11,684 - INFO - allennlp.training.tensorboard_writer - loss               |     1.850  |     1.499
2022-03-31 10:18:11,684 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_F1   |       N/A  |     0.552
2022-03-31 10:18:11,685 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_P    |       N/A  |     0.680
2022-03-31 10:18:11,685 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_R    |       N/A  |     0.479
2022-03-31 10:18:11,686 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_F1   |       N/A  |     0.363
2022-03-31 10:18:11,686 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_P    |       N/A  |     0.454
2022-03-31 10:18:11,686 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_R    |       N/A  |     0.313
2022-03-31 10:18:11,686 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-L      |       N/A  |     0.482
2022-03-31 10:18:11,687 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5241.066  |       N/A
2022-03-31 10:18:17,848 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to './output_decomposition/best.th'.
2022-03-31 10:18:37,665 - INFO - allennlp.training.trainer - Epoch duration: 0:04:08.122611
2022-03-31 10:18:37,665 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:51:54
2022-03-31 10:18:37,666 - INFO - allennlp.training.trainer - Epoch 2/14
2022-03-31 10:18:37,666 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.1G
2022-03-31 10:18:37,666 - INFO - allennlp.training.trainer - GPU 0 memory usage: 6.7G
2022-03-31 10:18:37,667 - INFO - allennlp.training.trainer - Training
2022-03-31 10:18:37,667 - INFO - tqdm - 0%|          | 0/65 [00:00<?, ?it/s]
2022-03-31 10:18:48,223 - INFO - tqdm - batch_loss: 1.9002, loss: 1.7205 ||:   9%|9         | 6/65 [00:10<01:44,  1.77s/it]
2022-03-31 10:18:58,742 - INFO - tqdm - batch_loss: 1.9163, loss: 1.7342 ||:  18%|#8        | 12/65 [00:21<01:32,  1.74s/it]
2022-03-31 10:19:09,294 - INFO - tqdm - batch_loss: 1.5042, loss: 1.6942 ||:  28%|##7       | 18/65 [00:31<01:22,  1.76s/it]
2022-03-31 10:19:19,721 - INFO - tqdm - batch_loss: 1.9024, loss: 1.7034 ||:  37%|###6      | 24/65 [00:42<01:11,  1.75s/it]
2022-03-31 10:19:30,240 - INFO - tqdm - batch_loss: 1.6983, loss: 1.6862 ||:  46%|####6     | 30/65 [00:52<01:01,  1.76s/it]
2022-03-31 10:19:40,629 - INFO - tqdm - batch_loss: 1.8627, loss: 1.6803 ||:  55%|#####5    | 36/65 [01:02<00:50,  1.73s/it]
2022-03-31 10:19:50,953 - INFO - tqdm - batch_loss: 1.6610, loss: 1.6612 ||:  65%|######4   | 42/65 [01:13<00:39,  1.73s/it]
2022-03-31 10:20:01,337 - INFO - tqdm - batch_loss: 1.6947, loss: 1.6717 ||:  74%|#######3  | 48/65 [01:23<00:29,  1.73s/it]
2022-03-31 10:20:11,727 - INFO - tqdm - batch_loss: 1.5728, loss: 1.6688 ||:  83%|########3 | 54/65 [01:34<00:18,  1.72s/it]
2022-03-31 10:20:22,086 - INFO - tqdm - batch_loss: 1.4335, loss: 1.6645 ||:  92%|#########2| 60/65 [01:44<00:08,  1.74s/it]
2022-03-31 10:20:29,740 - INFO - tqdm - batch_loss: 1.4376, loss: 1.6565 ||: 100%|##########| 65/65 [01:52<00:00,  1.44s/it]
2022-03-31 10:20:29,741 - INFO - tqdm - batch_loss: 1.4376, loss: 1.6565 ||: 100%|##########| 65/65 [01:52<00:00,  1.72s/it]
2022-03-31 10:20:32,946 - INFO - allennlp.training.trainer - Validating
2022-03-31 10:20:32,948 - INFO - tqdm - 0%|          | 0/115 [00:00<?, ?it/s]
2022-03-31 10:20:43,271 - INFO - tqdm - bleu_BLEU: 0.2465, rouge_ROUGE-1_R: 0.5061, rouge_ROUGE-2_R: 0.3404, rouge_ROUGE-1_P: 0.7032, rouge_ROUGE-2_P: 0.4910, rouge_ROUGE-1_F1: 0.5733, rouge_ROUGE-2_F1: 0.3909, rouge_ROUGE-L: 0.5157, SARI: 0.5453, count: 22.0000, batch_loss: 1.3336, loss: 1.4443 ||:  10%|9         | 11/115 [00:10<01:39,  1.05it/s]
2022-03-31 10:20:54,267 - INFO - tqdm - bleu_BLEU: 0.2137, rouge_ROUGE-1_R: 0.4810, rouge_ROUGE-2_R: 0.3184, rouge_ROUGE-1_P: 0.6917, rouge_ROUGE-2_P: 0.4712, rouge_ROUGE-1_F1: 0.5544, rouge_ROUGE-2_F1: 0.3707, rouge_ROUGE-L: 0.4777, SARI: 0.5518, count: 45.0000, batch_loss: 2.0519, loss: 1.5069 ||:  20%|##        | 23/115 [00:21<01:26,  1.07it/s]
2022-03-31 10:21:04,389 - INFO - tqdm - bleu_BLEU: 0.2181, rouge_ROUGE-1_R: 0.4836, rouge_ROUGE-2_R: 0.3215, rouge_ROUGE-1_P: 0.6886, rouge_ROUGE-2_P: 0.4688, rouge_ROUGE-1_F1: 0.5544, rouge_ROUGE-2_F1: 0.3716, rouge_ROUGE-L: 0.4756, SARI: 0.5600, count: 67.0000, batch_loss: 1.0694, loss: 1.4970 ||:  30%|##9       | 34/115 [00:31<01:16,  1.05it/s]
2022-03-31 10:21:15,023 - INFO - tqdm - bleu_BLEU: 0.2083, rouge_ROUGE-1_R: 0.4699, rouge_ROUGE-2_R: 0.3132, rouge_ROUGE-1_P: 0.6974, rouge_ROUGE-2_P: 0.4767, rouge_ROUGE-1_F1: 0.5492, rouge_ROUGE-2_F1: 0.3694, rouge_ROUGE-L: 0.4760, SARI: 0.5522, count: 91.0000, batch_loss: 1.0510, loss: 1.4540 ||:  40%|####      | 46/115 [00:42<01:01,  1.12it/s]
2022-03-31 10:21:25,738 - INFO - tqdm - bleu_BLEU: 0.2143, rouge_ROUGE-1_R: 0.4781, rouge_ROUGE-2_R: 0.3164, rouge_ROUGE-1_P: 0.6971, rouge_ROUGE-2_P: 0.4716, rouge_ROUGE-1_F1: 0.5566, rouge_ROUGE-2_F1: 0.3712, rouge_ROUGE-L: 0.4840, SARI: 0.5448, count: 115.0000, batch_loss: 1.4483, loss: 1.4554 ||:  50%|#####     | 58/115 [00:52<00:48,  1.18it/s]
2022-03-31 10:21:36,016 - INFO - tqdm - bleu_BLEU: 0.2137, rouge_ROUGE-1_R: 0.4775, rouge_ROUGE-2_R: 0.3163, rouge_ROUGE-1_P: 0.7000, rouge_ROUGE-2_P: 0.4744, rouge_ROUGE-1_F1: 0.5572, rouge_ROUGE-2_F1: 0.3720, rouge_ROUGE-L: 0.4866, SARI: 0.5467, count: 139.0000, batch_loss: 2.0996, loss: 1.4429 ||:  61%|######    | 70/115 [01:03<00:37,  1.19it/s]
2022-03-31 10:21:46,783 - INFO - tqdm - bleu_BLEU: 0.2098, rouge_ROUGE-1_R: 0.4746, rouge_ROUGE-2_R: 0.3118, rouge_ROUGE-1_P: 0.6898, rouge_ROUGE-2_P: 0.4638, rouge_ROUGE-1_F1: 0.5507, rouge_ROUGE-2_F1: 0.3648, rouge_ROUGE-L: 0.4817, SARI: 0.5393, count: 163.0000, batch_loss: 1.8275, loss: 1.4426 ||:  71%|#######1  | 82/115 [01:13<00:28,  1.14it/s]
2022-03-31 10:21:57,165 - INFO - tqdm - bleu_BLEU: 0.2147, rouge_ROUGE-1_R: 0.4778, rouge_ROUGE-2_R: 0.3167, rouge_ROUGE-1_P: 0.6946, rouge_ROUGE-2_P: 0.4704, rouge_ROUGE-1_F1: 0.5548, rouge_ROUGE-2_F1: 0.3705, rouge_ROUGE-L: 0.4882, SARI: 0.5446, count: 187.0000, batch_loss: 1.4733, loss: 1.4581 ||:  82%|########1 | 94/115 [01:24<00:19,  1.09it/s]
2022-03-31 10:22:07,855 - INFO - tqdm - bleu_BLEU: 0.2127, rouge_ROUGE-1_R: 0.4762, rouge_ROUGE-2_R: 0.3158, rouge_ROUGE-1_P: 0.6978, rouge_ROUGE-2_P: 0.4727, rouge_ROUGE-1_F1: 0.5551, rouge_ROUGE-2_F1: 0.3709, rouge_ROUGE-L: 0.4851, SARI: 0.5424, count: 211.0000, batch_loss: 1.5183, loss: 1.4487 ||:  92%|#########2| 106/115 [01:34<00:07,  1.18it/s]
2022-03-31 10:22:15,631 - INFO - tqdm - bleu_BLEU: 0.2108, rouge_ROUGE-1_R: 0.4765, rouge_ROUGE-2_R: 0.3167, rouge_ROUGE-1_P: 0.6989, rouge_ROUGE-2_P: 0.4734, rouge_ROUGE-1_F1: 0.5555, rouge_ROUGE-2_F1: 0.3716, rouge_ROUGE-L: 0.4856, SARI: 0.5408, count: 229.0000, batch_loss: 0.7039, loss: 1.4469 ||: 100%|##########| 115/115 [01:42<00:00,  1.20it/s]
2022-03-31 10:22:15,631 - INFO - tqdm - bleu_BLEU: 0.2108, rouge_ROUGE-1_R: 0.4765, rouge_ROUGE-2_R: 0.3167, rouge_ROUGE-1_P: 0.6989, rouge_ROUGE-2_P: 0.4734, rouge_ROUGE-1_F1: 0.5555, rouge_ROUGE-2_F1: 0.3716, rouge_ROUGE-L: 0.4856, SARI: 0.5408, count: 229.0000, batch_loss: 0.7039, loss: 1.4469 ||: 100%|##########| 115/115 [01:42<00:00,  1.12it/s]
2022-03-31 10:22:15,632 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2022-03-31 10:22:15,632 - INFO - allennlp.training.tensorboard_writer - SARI               |       N/A  |     0.541
2022-03-31 10:22:15,633 - INFO - allennlp.training.tensorboard_writer - bleu_BLEU          |       N/A  |     0.211
2022-03-31 10:22:15,634 - INFO - allennlp.training.tensorboard_writer - count              |       N/A  |   229.000
2022-03-31 10:22:15,634 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |  6843.718  |       N/A
2022-03-31 10:22:15,634 - INFO - allennlp.training.tensorboard_writer - loss               |     1.656  |     1.447
2022-03-31 10:22:15,635 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_F1   |       N/A  |     0.555
2022-03-31 10:22:15,636 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_P    |       N/A  |     0.699
2022-03-31 10:22:15,636 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_R    |       N/A  |     0.477
2022-03-31 10:22:15,636 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_F1   |       N/A  |     0.372
2022-03-31 10:22:15,637 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_P    |       N/A  |     0.473
2022-03-31 10:22:15,637 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_R    |       N/A  |     0.317
2022-03-31 10:22:15,638 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-L      |       N/A  |     0.486
2022-03-31 10:22:15,638 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5241.066  |       N/A
2022-03-31 10:22:21,816 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to './output_decomposition/best.th'.
2022-03-31 10:22:45,543 - INFO - allennlp.training.trainer - Epoch duration: 0:04:07.877719
2022-03-31 10:22:45,544 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:48:27
2022-03-31 10:22:45,544 - INFO - allennlp.training.trainer - Epoch 3/14
2022-03-31 10:22:45,544 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.1G
2022-03-31 10:22:45,544 - INFO - allennlp.training.trainer - GPU 0 memory usage: 6.7G
2022-03-31 10:22:45,545 - INFO - allennlp.training.trainer - Training
2022-03-31 10:22:45,546 - INFO - tqdm - 0%|          | 0/65 [00:00<?, ?it/s]
2022-03-31 10:22:56,564 - INFO - tqdm - batch_loss: 1.5820, loss: 1.5443 ||:   9%|9         | 6/65 [00:11<01:50,  1.87s/it]
2022-03-31 10:23:06,971 - INFO - tqdm - batch_loss: 1.5912, loss: 1.5450 ||:  18%|#8        | 12/65 [00:21<01:32,  1.74s/it]
2022-03-31 10:23:17,432 - INFO - tqdm - batch_loss: 1.3963, loss: 1.5257 ||:  28%|##7       | 18/65 [00:31<01:21,  1.74s/it]
2022-03-31 10:23:27,985 - INFO - tqdm - batch_loss: 1.3009, loss: 1.5288 ||:  37%|###6      | 24/65 [00:42<01:12,  1.76s/it]
2022-03-31 10:23:38,358 - INFO - tqdm - batch_loss: 1.5994, loss: 1.5303 ||:  46%|####6     | 30/65 [00:52<01:00,  1.73s/it]
2022-03-31 10:23:48,724 - INFO - tqdm - batch_loss: 1.5322, loss: 1.5304 ||:  55%|#####5    | 36/65 [01:03<00:50,  1.73s/it]
2022-03-31 10:23:58,907 - INFO - tqdm - batch_loss: 1.3181, loss: 1.5278 ||:  65%|######4   | 42/65 [01:13<00:39,  1.70s/it]
2022-03-31 10:24:09,520 - INFO - tqdm - batch_loss: 1.4810, loss: 1.5206 ||:  74%|#######3  | 48/65 [01:23<00:30,  1.77s/it]
2022-03-31 10:24:20,047 - INFO - tqdm - batch_loss: 1.3843, loss: 1.5192 ||:  83%|########3 | 54/65 [01:34<00:19,  1.75s/it]
2022-03-31 10:24:30,458 - INFO - tqdm - batch_loss: 1.6909, loss: 1.5273 ||:  92%|#########2| 60/65 [01:44<00:08,  1.73s/it]
2022-03-31 10:24:38,194 - INFO - tqdm - batch_loss: 1.6712, loss: 1.5271 ||: 100%|##########| 65/65 [01:52<00:00,  1.45s/it]
2022-03-31 10:24:38,194 - INFO - tqdm - batch_loss: 1.6712, loss: 1.5271 ||: 100%|##########| 65/65 [01:52<00:00,  1.73s/it]
2022-03-31 10:24:41,313 - INFO - allennlp.training.trainer - Validating
2022-03-31 10:24:41,314 - INFO - tqdm - 0%|          | 0/115 [00:00<?, ?it/s]
2022-03-31 10:24:51,792 - INFO - tqdm - bleu_BLEU: 0.2345, rouge_ROUGE-1_R: 0.5233, rouge_ROUGE-2_R: 0.3465, rouge_ROUGE-1_P: 0.6640, rouge_ROUGE-2_P: 0.4434, rouge_ROUGE-1_F1: 0.5676, rouge_ROUGE-2_F1: 0.3769, rouge_ROUGE-L: 0.5142, SARI: 0.5393, count: 22.0000, batch_loss: 0.8506, loss: 1.3736 ||:  10%|9         | 11/115 [00:10<01:38,  1.06it/s]
2022-03-31 10:25:02,131 - INFO - tqdm - bleu_BLEU: 0.2216, rouge_ROUGE-1_R: 0.5086, rouge_ROUGE-2_R: 0.3384, rouge_ROUGE-1_P: 0.6556, rouge_ROUGE-2_P: 0.4380, rouge_ROUGE-1_F1: 0.5599, rouge_ROUGE-2_F1: 0.3730, rouge_ROUGE-L: 0.4952, SARI: 0.5175, count: 44.0000, batch_loss: 1.3419, loss: 1.3637 ||:  19%|#9        | 22/115 [00:20<01:28,  1.05it/s]
2022-03-31 10:25:12,492 - INFO - tqdm - bleu_BLEU: 0.2206, rouge_ROUGE-1_R: 0.5037, rouge_ROUGE-2_R: 0.3285, rouge_ROUGE-1_P: 0.6489, rouge_ROUGE-2_P: 0.4297, rouge_ROUGE-1_F1: 0.5557, rouge_ROUGE-2_F1: 0.3645, rouge_ROUGE-L: 0.4891, SARI: 0.5381, count: 68.0000, batch_loss: 1.1058, loss: 1.4085 ||:  30%|##9       | 34/115 [00:31<01:08,  1.18it/s]
2022-03-31 10:25:22,723 - INFO - tqdm - bleu_BLEU: 0.2225, rouge_ROUGE-1_R: 0.5036, rouge_ROUGE-2_R: 0.3323, rouge_ROUGE-1_P: 0.6631, rouge_ROUGE-2_P: 0.4433, rouge_ROUGE-1_F1: 0.5612, rouge_ROUGE-2_F1: 0.3721, rouge_ROUGE-L: 0.4919, SARI: 0.5415, count: 88.0000, batch_loss: 1.0504, loss: 1.3774 ||:  38%|###8      | 44/115 [00:41<01:09,  1.02it/s]
2022-03-31 10:25:33,631 - INFO - tqdm - bleu_BLEU: 0.2278, rouge_ROUGE-1_R: 0.5070, rouge_ROUGE-2_R: 0.3397, rouge_ROUGE-1_P: 0.6789, rouge_ROUGE-2_P: 0.4588, rouge_ROUGE-1_F1: 0.5693, rouge_ROUGE-2_F1: 0.3827, rouge_ROUGE-L: 0.4980, SARI: 0.5528, count: 112.0000, batch_loss: 2.0421, loss: 1.3943 ||:  49%|####8     | 56/115 [00:52<00:53,  1.11it/s]
2022-03-31 10:25:44,010 - INFO - tqdm - bleu_BLEU: 0.2297, rouge_ROUGE-1_R: 0.5070, rouge_ROUGE-2_R: 0.3398, rouge_ROUGE-1_P: 0.6802, rouge_ROUGE-2_P: 0.4603, rouge_ROUGE-1_F1: 0.5695, rouge_ROUGE-2_F1: 0.3831, rouge_ROUGE-L: 0.4984, SARI: 0.5539, count: 134.0000, batch_loss: 1.1114, loss: 1.3920 ||:  58%|#####8    | 67/115 [01:02<00:45,  1.05it/s]
2022-03-31 10:25:54,261 - INFO - tqdm - bleu_BLEU: 0.2250, rouge_ROUGE-1_R: 0.5002, rouge_ROUGE-2_R: 0.3341, rouge_ROUGE-1_P: 0.6822, rouge_ROUGE-2_P: 0.4605, rouge_ROUGE-1_F1: 0.5662, rouge_ROUGE-2_F1: 0.3797, rouge_ROUGE-L: 0.4961, SARI: 0.5471, count: 156.0000, batch_loss: 1.0438, loss: 1.3928 ||:  68%|######7   | 78/115 [01:12<00:36,  1.01it/s]
2022-03-31 10:26:05,045 - INFO - tqdm - bleu_BLEU: 0.2214, rouge_ROUGE-1_R: 0.4952, rouge_ROUGE-2_R: 0.3314, rouge_ROUGE-1_P: 0.6871, rouge_ROUGE-2_P: 0.4667, rouge_ROUGE-1_F1: 0.5634, rouge_ROUGE-2_F1: 0.3790, rouge_ROUGE-L: 0.4925, SARI: 0.5464, count: 178.0000, batch_loss: 1.4311, loss: 1.3913 ||:  77%|#######7  | 89/115 [01:23<00:27,  1.07s/it]
2022-03-31 10:26:15,263 - INFO - tqdm - bleu_BLEU: 0.2201, rouge_ROUGE-1_R: 0.4915, rouge_ROUGE-2_R: 0.3287, rouge_ROUGE-1_P: 0.6866, rouge_ROUGE-2_P: 0.4655, rouge_ROUGE-1_F1: 0.5604, rouge_ROUGE-2_F1: 0.3764, rouge_ROUGE-L: 0.4905, SARI: 0.5522, count: 199.0000, batch_loss: 1.2097, loss: 1.3932 ||:  87%|########6 | 100/115 [01:33<00:14,  1.04it/s]
2022-03-31 10:26:25,445 - INFO - tqdm - bleu_BLEU: 0.2209, rouge_ROUGE-1_R: 0.4899, rouge_ROUGE-2_R: 0.3265, rouge_ROUGE-1_P: 0.6818, rouge_ROUGE-2_P: 0.4605, rouge_ROUGE-1_F1: 0.5584, rouge_ROUGE-2_F1: 0.3737, rouge_ROUGE-L: 0.4894, SARI: 0.5499, count: 221.0000, batch_loss: 1.9079, loss: 1.4258 ||:  97%|#########6| 111/115 [01:44<00:03,  1.09it/s]
2022-03-31 10:26:28,878 - INFO - tqdm - bleu_BLEU: 0.2184, rouge_ROUGE-1_R: 0.4871, rouge_ROUGE-2_R: 0.3241, rouge_ROUGE-1_P: 0.6816, rouge_ROUGE-2_P: 0.4595, rouge_ROUGE-1_F1: 0.5566, rouge_ROUGE-2_F1: 0.3719, rouge_ROUGE-L: 0.4882, SARI: 0.5507, count: 229.0000, batch_loss: 1.0021, loss: 1.4198 ||: 100%|##########| 115/115 [01:47<00:00,  1.14it/s]
2022-03-31 10:26:28,879 - INFO - tqdm - bleu_BLEU: 0.2184, rouge_ROUGE-1_R: 0.4871, rouge_ROUGE-2_R: 0.3241, rouge_ROUGE-1_P: 0.6816, rouge_ROUGE-2_P: 0.4595, rouge_ROUGE-1_F1: 0.5566, rouge_ROUGE-2_F1: 0.3719, rouge_ROUGE-L: 0.4882, SARI: 0.5507, count: 229.0000, batch_loss: 1.0021, loss: 1.4198 ||: 100%|##########| 115/115 [01:47<00:00,  1.07it/s]
2022-03-31 10:26:28,879 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2022-03-31 10:26:28,880 - INFO - allennlp.training.tensorboard_writer - SARI               |       N/A  |     0.551
2022-03-31 10:26:28,880 - INFO - allennlp.training.tensorboard_writer - bleu_BLEU          |       N/A  |     0.218
2022-03-31 10:26:28,881 - INFO - allennlp.training.tensorboard_writer - count              |       N/A  |   229.000
2022-03-31 10:26:28,881 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |  6843.718  |       N/A
2022-03-31 10:26:28,882 - INFO - allennlp.training.tensorboard_writer - loss               |     1.527  |     1.420
2022-03-31 10:26:28,883 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_F1   |       N/A  |     0.557
2022-03-31 10:26:28,883 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_P    |       N/A  |     0.682
2022-03-31 10:26:28,883 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_R    |       N/A  |     0.487
2022-03-31 10:26:28,884 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_F1   |       N/A  |     0.372
2022-03-31 10:26:28,884 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_P    |       N/A  |     0.460
2022-03-31 10:26:28,884 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_R    |       N/A  |     0.324
2022-03-31 10:26:28,885 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-L      |       N/A  |     0.488
2022-03-31 10:26:28,885 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5241.066  |       N/A
2022-03-31 10:26:35,066 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to './output_decomposition/best.th'.
2022-03-31 10:26:47,523 - INFO - allennlp.training.trainer - Epoch duration: 0:04:01.979241
2022-03-31 10:26:47,523 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:44:24
2022-03-31 10:26:47,523 - INFO - allennlp.training.trainer - Epoch 4/14
2022-03-31 10:26:47,524 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.1G
2022-03-31 10:26:47,524 - INFO - allennlp.training.trainer - GPU 0 memory usage: 6.7G
2022-03-31 10:26:47,525 - INFO - allennlp.training.trainer - Training
2022-03-31 10:26:47,525 - INFO - tqdm - 0%|          | 0/65 [00:00<?, ?it/s]
2022-03-31 10:26:57,888 - INFO - tqdm - batch_loss: 1.3768, loss: 1.4320 ||:   9%|9         | 6/65 [00:10<01:41,  1.72s/it]
2022-03-31 10:27:08,463 - INFO - tqdm - batch_loss: 1.3893, loss: 1.4603 ||:  18%|#8        | 12/65 [00:20<01:32,  1.75s/it]
2022-03-31 10:27:19,006 - INFO - tqdm - batch_loss: 1.3929, loss: 1.4257 ||:  28%|##7       | 18/65 [00:31<01:22,  1.75s/it]
2022-03-31 10:27:29,434 - INFO - tqdm - batch_loss: 1.3141, loss: 1.4347 ||:  37%|###6      | 24/65 [00:41<01:11,  1.74s/it]
2022-03-31 10:27:39,805 - INFO - tqdm - batch_loss: 1.4897, loss: 1.4274 ||:  46%|####6     | 30/65 [00:52<01:00,  1.74s/it]
2022-03-31 10:27:49,983 - INFO - tqdm - batch_loss: 1.4949, loss: 1.4275 ||:  55%|#####5    | 36/65 [01:02<00:49,  1.70s/it]
2022-03-31 10:28:00,882 - INFO - tqdm - batch_loss: 1.5479, loss: 1.4298 ||:  65%|######4   | 42/65 [01:13<00:41,  1.79s/it]
2022-03-31 10:28:11,399 - INFO - tqdm - batch_loss: 1.4538, loss: 1.4269 ||:  74%|#######3  | 48/65 [01:23<00:29,  1.74s/it]
2022-03-31 10:28:21,751 - INFO - tqdm - batch_loss: 1.4267, loss: 1.4327 ||:  83%|########3 | 54/65 [01:34<00:19,  1.74s/it]
2022-03-31 10:28:32,160 - INFO - tqdm - batch_loss: 1.5803, loss: 1.4378 ||:  92%|#########2| 60/65 [01:44<00:08,  1.75s/it]
2022-03-31 10:28:39,905 - INFO - tqdm - batch_loss: 1.1853, loss: 1.4330 ||: 100%|##########| 65/65 [01:52<00:00,  1.46s/it]
2022-03-31 10:28:39,905 - INFO - tqdm - batch_loss: 1.1853, loss: 1.4330 ||: 100%|##########| 65/65 [01:52<00:00,  1.73s/it]
2022-03-31 10:28:43,028 - INFO - allennlp.training.trainer - Validating
2022-03-31 10:28:43,030 - INFO - tqdm - 0%|          | 0/115 [00:00<?, ?it/s]
2022-03-31 10:28:53,118 - INFO - tqdm - bleu_BLEU: 0.2252, rouge_ROUGE-1_R: 0.5244, rouge_ROUGE-2_R: 0.3355, rouge_ROUGE-1_P: 0.6386, rouge_ROUGE-2_P: 0.4188, rouge_ROUGE-1_F1: 0.5577, rouge_ROUGE-2_F1: 0.3597, rouge_ROUGE-L: 0.4918, SARI: 0.5117, count: 21.0000, batch_loss: 1.4957, loss: 1.2821 ||:  10%|9         | 11/115 [00:10<01:28,  1.17it/s]
2022-03-31 10:29:03,941 - INFO - tqdm - bleu_BLEU: 0.2455, rouge_ROUGE-1_R: 0.5121, rouge_ROUGE-2_R: 0.3391, rouge_ROUGE-1_P: 0.6544, rouge_ROUGE-2_P: 0.4420, rouge_ROUGE-1_F1: 0.5631, rouge_ROUGE-2_F1: 0.3756, rouge_ROUGE-L: 0.4885, SARI: 0.5262, count: 43.0000, batch_loss: 1.3292, loss: 1.4110 ||:  19%|#9        | 22/115 [00:20<01:33,  1.01s/it]
2022-03-31 10:29:14,301 - INFO - tqdm - bleu_BLEU: 0.2352, rouge_ROUGE-1_R: 0.5057, rouge_ROUGE-2_R: 0.3331, rouge_ROUGE-1_P: 0.6572, rouge_ROUGE-2_P: 0.4412, rouge_ROUGE-1_F1: 0.5585, rouge_ROUGE-2_F1: 0.3704, rouge_ROUGE-L: 0.4817, SARI: 0.5343, count: 63.0000, batch_loss: 0.9251, loss: 1.3945 ||:  28%|##7       | 32/115 [00:31<01:25,  1.02s/it]
2022-03-31 10:29:24,903 - INFO - tqdm - bleu_BLEU: 0.2426, rouge_ROUGE-1_R: 0.5127, rouge_ROUGE-2_R: 0.3377, rouge_ROUGE-1_P: 0.6518, rouge_ROUGE-2_P: 0.4374, rouge_ROUGE-1_F1: 0.5614, rouge_ROUGE-2_F1: 0.3724, rouge_ROUGE-L: 0.4866, SARI: 0.5467, count: 83.0000, batch_loss: 1.0737, loss: 1.3809 ||:  37%|###6      | 42/115 [00:41<01:18,  1.08s/it]
2022-03-31 10:29:34,945 - INFO - tqdm - bleu_BLEU: 0.2429, rouge_ROUGE-1_R: 0.5141, rouge_ROUGE-2_R: 0.3394, rouge_ROUGE-1_P: 0.6522, rouge_ROUGE-2_P: 0.4374, rouge_ROUGE-1_F1: 0.5624, rouge_ROUGE-2_F1: 0.3735, rouge_ROUGE-L: 0.4864, SARI: 0.5523, count: 101.0000, batch_loss: 1.4942, loss: 1.4128 ||:  44%|####4     | 51/115 [00:51<01:12,  1.13s/it]
2022-03-31 10:29:45,842 - INFO - tqdm - bleu_BLEU: 0.2492, rouge_ROUGE-1_R: 0.5287, rouge_ROUGE-2_R: 0.3525, rouge_ROUGE-1_P: 0.6493, rouge_ROUGE-2_P: 0.4372, rouge_ROUGE-1_F1: 0.5692, rouge_ROUGE-2_F1: 0.3806, rouge_ROUGE-L: 0.4878, SARI: 0.5577, count: 123.0000, batch_loss: 1.7783, loss: 1.3817 ||:  54%|#####3    | 62/115 [01:02<00:52,  1.01it/s]
2022-03-31 10:29:56,037 - INFO - tqdm - bleu_BLEU: 0.2403, rouge_ROUGE-1_R: 0.5187, rouge_ROUGE-2_R: 0.3448, rouge_ROUGE-1_P: 0.6505, rouge_ROUGE-2_P: 0.4362, rouge_ROUGE-1_F1: 0.5640, rouge_ROUGE-2_F1: 0.3759, rouge_ROUGE-L: 0.4846, SARI: 0.5501, count: 145.0000, batch_loss: 1.2139, loss: 1.3836 ||:  63%|######3   | 73/115 [01:13<00:37,  1.11it/s]
2022-03-31 10:30:06,240 - INFO - tqdm - bleu_BLEU: 0.2429, rouge_ROUGE-1_R: 0.5184, rouge_ROUGE-2_R: 0.3438, rouge_ROUGE-1_P: 0.6454, rouge_ROUGE-2_P: 0.4326, rouge_ROUGE-1_F1: 0.5603, rouge_ROUGE-2_F1: 0.3730, rouge_ROUGE-L: 0.4818, SARI: 0.5545, count: 165.0000, batch_loss: 1.1770, loss: 1.3688 ||:  72%|#######2  | 83/115 [01:23<00:33,  1.05s/it]
2022-03-31 10:30:16,565 - INFO - tqdm - bleu_BLEU: 0.2401, rouge_ROUGE-1_R: 0.5191, rouge_ROUGE-2_R: 0.3440, rouge_ROUGE-1_P: 0.6508, rouge_ROUGE-2_P: 0.4357, rouge_ROUGE-1_F1: 0.5631, rouge_ROUGE-2_F1: 0.3745, rouge_ROUGE-L: 0.4826, SARI: 0.5527, count: 185.0000, batch_loss: 1.6241, loss: 1.3903 ||:  81%|########  | 93/115 [01:33<00:21,  1.02it/s]
2022-03-31 10:30:26,727 - INFO - tqdm - bleu_BLEU: 0.2405, rouge_ROUGE-1_R: 0.5159, rouge_ROUGE-2_R: 0.3431, rouge_ROUGE-1_P: 0.6507, rouge_ROUGE-2_P: 0.4370, rouge_ROUGE-1_F1: 0.5620, rouge_ROUGE-2_F1: 0.3751, rouge_ROUGE-L: 0.4843, SARI: 0.5553, count: 205.0000, batch_loss: 1.2979, loss: 1.3820 ||:  90%|########9 | 103/115 [01:43<00:11,  1.02it/s]
2022-03-31 10:30:36,826 - INFO - tqdm - bleu_BLEU: 0.2345, rouge_ROUGE-1_R: 0.5108, rouge_ROUGE-2_R: 0.3374, rouge_ROUGE-1_P: 0.6489, rouge_ROUGE-2_P: 0.4327, rouge_ROUGE-1_F1: 0.5583, rouge_ROUGE-2_F1: 0.3700, rouge_ROUGE-L: 0.4808, SARI: 0.5549, count: 225.0000, batch_loss: 0.6814, loss: 1.3899 ||:  98%|#########8| 113/115 [01:53<00:01,  1.05it/s]
2022-03-31 10:30:38,825 - INFO - tqdm - bleu_BLEU: 0.2328, rouge_ROUGE-1_R: 0.5093, rouge_ROUGE-2_R: 0.3356, rouge_ROUGE-1_P: 0.6463, rouge_ROUGE-2_P: 0.4299, rouge_ROUGE-1_F1: 0.5564, rouge_ROUGE-2_F1: 0.3679, rouge_ROUGE-L: 0.4782, SARI: 0.5557, count: 229.0000, batch_loss: 2.2001, loss: 1.3956 ||: 100%|##########| 115/115 [01:55<00:00,  1.03it/s]
2022-03-31 10:30:38,825 - INFO - tqdm - bleu_BLEU: 0.2328, rouge_ROUGE-1_R: 0.5093, rouge_ROUGE-2_R: 0.3356, rouge_ROUGE-1_P: 0.6463, rouge_ROUGE-2_P: 0.4299, rouge_ROUGE-1_F1: 0.5564, rouge_ROUGE-2_F1: 0.3679, rouge_ROUGE-L: 0.4782, SARI: 0.5557, count: 229.0000, batch_loss: 2.2001, loss: 1.3956 ||: 100%|##########| 115/115 [01:55<00:00,  1.01s/it]
2022-03-31 10:30:38,826 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2022-03-31 10:30:38,826 - INFO - allennlp.training.tensorboard_writer - SARI               |       N/A  |     0.556
2022-03-31 10:30:38,827 - INFO - allennlp.training.tensorboard_writer - bleu_BLEU          |       N/A  |     0.233
2022-03-31 10:30:38,827 - INFO - allennlp.training.tensorboard_writer - count              |       N/A  |   229.000
2022-03-31 10:30:38,828 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |  6843.718  |       N/A
2022-03-31 10:30:38,828 - INFO - allennlp.training.tensorboard_writer - loss               |     1.433  |     1.396
2022-03-31 10:30:38,829 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_F1   |       N/A  |     0.556
2022-03-31 10:30:38,829 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_P    |       N/A  |     0.646
2022-03-31 10:30:38,829 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_R    |       N/A  |     0.509
2022-03-31 10:30:38,830 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_F1   |       N/A  |     0.368
2022-03-31 10:30:38,830 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_P    |       N/A  |     0.430
2022-03-31 10:30:38,831 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_R    |       N/A  |     0.336
2022-03-31 10:30:38,831 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-L      |       N/A  |     0.478
2022-03-31 10:30:38,831 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5241.066  |       N/A
2022-03-31 10:30:44,980 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to './output_decomposition/best.th'.
2022-03-31 10:30:57,400 - INFO - allennlp.training.trainer - Epoch duration: 0:04:09.876655
2022-03-31 10:30:57,400 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:40:37
2022-03-31 10:30:57,401 - INFO - allennlp.training.trainer - Epoch 5/14
2022-03-31 10:30:57,401 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.1G
2022-03-31 10:30:57,401 - INFO - allennlp.training.trainer - GPU 0 memory usage: 6.7G
2022-03-31 10:30:57,402 - INFO - allennlp.training.trainer - Training
2022-03-31 10:30:57,403 - INFO - tqdm - 0%|          | 0/65 [00:00<?, ?it/s]
2022-03-31 10:31:07,836 - INFO - tqdm - batch_loss: 1.3470, loss: 1.3186 ||:   9%|9         | 6/65 [00:10<01:43,  1.75s/it]
2022-03-31 10:31:18,282 - INFO - tqdm - batch_loss: 1.5369, loss: 1.3634 ||:  18%|#8        | 12/65 [00:20<01:32,  1.74s/it]
2022-03-31 10:31:28,738 - INFO - tqdm - batch_loss: 1.3732, loss: 1.3558 ||:  28%|##7       | 18/65 [00:31<01:22,  1.75s/it]
2022-03-31 10:31:39,115 - INFO - tqdm - batch_loss: 1.4419, loss: 1.3485 ||:  37%|###6      | 24/65 [00:41<01:11,  1.74s/it]
2022-03-31 10:31:49,642 - INFO - tqdm - batch_loss: 1.3175, loss: 1.3473 ||:  46%|####6     | 30/65 [00:52<01:01,  1.75s/it]
2022-03-31 10:31:59,891 - INFO - tqdm - batch_loss: 1.4899, loss: 1.3489 ||:  55%|#####5    | 36/65 [01:02<00:49,  1.71s/it]
2022-03-31 10:32:10,434 - INFO - tqdm - batch_loss: 1.4483, loss: 1.3567 ||:  65%|######4   | 42/65 [01:13<00:40,  1.74s/it]
2022-03-31 10:32:20,739 - INFO - tqdm - batch_loss: 1.3858, loss: 1.3539 ||:  74%|#######3  | 48/65 [01:23<00:29,  1.72s/it]
2022-03-31 10:32:31,154 - INFO - tqdm - batch_loss: 1.4691, loss: 1.3614 ||:  83%|########3 | 54/65 [01:33<00:18,  1.73s/it]
2022-03-31 10:32:41,424 - INFO - tqdm - batch_loss: 1.3466, loss: 1.3631 ||:  92%|#########2| 60/65 [01:44<00:08,  1.71s/it]
2022-03-31 10:32:49,142 - INFO - tqdm - batch_loss: 1.1576, loss: 1.3629 ||: 100%|##########| 65/65 [01:51<00:00,  1.44s/it]
2022-03-31 10:32:49,143 - INFO - tqdm - batch_loss: 1.1576, loss: 1.3629 ||: 100%|##########| 65/65 [01:51<00:00,  1.72s/it]
2022-03-31 10:32:52,270 - INFO - allennlp.training.trainer - Validating
2022-03-31 10:32:52,272 - INFO - tqdm - 0%|          | 0/115 [00:00<?, ?it/s]
2022-03-31 10:33:02,708 - INFO - tqdm - bleu_BLEU: 0.1975, rouge_ROUGE-1_R: 0.4729, rouge_ROUGE-2_R: 0.3060, rouge_ROUGE-1_P: 0.6842, rouge_ROUGE-2_P: 0.4436, rouge_ROUGE-1_F1: 0.5453, rouge_ROUGE-2_F1: 0.3528, rouge_ROUGE-L: 0.4670, SARI: 0.5549, count: 22.0000, batch_loss: 1.5564, loss: 1.3328 ||:  10%|9         | 11/115 [00:10<01:43,  1.00it/s]
2022-03-31 10:33:12,760 - INFO - tqdm - bleu_BLEU: 0.1996, rouge_ROUGE-1_R: 0.4627, rouge_ROUGE-2_R: 0.3057, rouge_ROUGE-1_P: 0.6887, rouge_ROUGE-2_P: 0.4600, rouge_ROUGE-1_F1: 0.5438, rouge_ROUGE-2_F1: 0.3606, rouge_ROUGE-L: 0.4723, SARI: 0.5664, count: 44.0000, batch_loss: 1.0334, loss: 1.3417 ||:  19%|#9        | 22/115 [00:20<01:23,  1.12it/s]
2022-03-31 10:33:23,199 - INFO - tqdm - bleu_BLEU: 0.1894, rouge_ROUGE-1_R: 0.4536, rouge_ROUGE-2_R: 0.2915, rouge_ROUGE-1_P: 0.6676, rouge_ROUGE-2_P: 0.4356, rouge_ROUGE-1_F1: 0.5299, rouge_ROUGE-2_F1: 0.3424, rouge_ROUGE-L: 0.4582, SARI: 0.5388, count: 66.0000, batch_loss: 1.4015, loss: 1.3758 ||:  29%|##8       | 33/115 [00:30<01:15,  1.08it/s]
2022-03-31 10:33:34,189 - INFO - tqdm - bleu_BLEU: 0.1919, rouge_ROUGE-1_R: 0.4619, rouge_ROUGE-2_R: 0.2964, rouge_ROUGE-1_P: 0.6686, rouge_ROUGE-2_P: 0.4349, rouge_ROUGE-1_F1: 0.5355, rouge_ROUGE-2_F1: 0.3452, rouge_ROUGE-L: 0.4624, SARI: 0.5431, count: 87.0000, batch_loss: 1.3922, loss: 1.3867 ||:  38%|###8      | 44/115 [00:41<01:19,  1.12s/it]
2022-03-31 10:33:44,593 - INFO - tqdm - bleu_BLEU: 0.2012, rouge_ROUGE-1_R: 0.4636, rouge_ROUGE-2_R: 0.3016, rouge_ROUGE-1_P: 0.6631, rouge_ROUGE-2_P: 0.4372, rouge_ROUGE-1_F1: 0.5359, rouge_ROUGE-2_F1: 0.3503, rouge_ROUGE-L: 0.4673, SARI: 0.5438, count: 109.0000, batch_loss: 1.2350, loss: 1.4218 ||:  48%|####7     | 55/115 [00:52<01:00,  1.00s/it]
2022-03-31 10:33:54,662 - INFO - tqdm - bleu_BLEU: 0.2061, rouge_ROUGE-1_R: 0.4645, rouge_ROUGE-2_R: 0.3040, rouge_ROUGE-1_P: 0.6657, rouge_ROUGE-2_P: 0.4427, rouge_ROUGE-1_F1: 0.5379, rouge_ROUGE-2_F1: 0.3541, rouge_ROUGE-L: 0.4674, SARI: 0.5412, count: 129.0000, batch_loss: 1.6437, loss: 1.4083 ||:  57%|#####6    | 65/115 [01:02<00:48,  1.03it/s]
2022-03-31 10:34:05,324 - INFO - tqdm - bleu_BLEU: 0.2042, rouge_ROUGE-1_R: 0.4635, rouge_ROUGE-2_R: 0.3019, rouge_ROUGE-1_P: 0.6683, rouge_ROUGE-2_P: 0.4436, rouge_ROUGE-1_F1: 0.5380, rouge_ROUGE-2_F1: 0.3529, rouge_ROUGE-L: 0.4688, SARI: 0.5434, count: 151.0000, batch_loss: 1.0568, loss: 1.4152 ||:  66%|######6   | 76/115 [01:13<00:36,  1.06it/s]
2022-03-31 10:34:15,621 - INFO - tqdm - bleu_BLEU: 0.2148, rouge_ROUGE-1_R: 0.4777, rouge_ROUGE-2_R: 0.3146, rouge_ROUGE-1_P: 0.6682, rouge_ROUGE-2_P: 0.4470, rouge_ROUGE-1_F1: 0.5466, rouge_ROUGE-2_F1: 0.3620, rouge_ROUGE-L: 0.4782, SARI: 0.5470, count: 173.0000, batch_loss: 1.1877, loss: 1.3786 ||:  76%|#######5  | 87/115 [01:23<00:25,  1.08it/s]
2022-03-31 10:34:26,009 - INFO - tqdm - bleu_BLEU: 0.2106, rouge_ROUGE-1_R: 0.4781, rouge_ROUGE-2_R: 0.3133, rouge_ROUGE-1_P: 0.6661, rouge_ROUGE-2_P: 0.4425, rouge_ROUGE-1_F1: 0.5452, rouge_ROUGE-2_F1: 0.3589, rouge_ROUGE-L: 0.4757, SARI: 0.5483, count: 195.0000, batch_loss: 1.9032, loss: 1.4012 ||:  85%|########5 | 98/115 [01:33<00:16,  1.05it/s]
2022-03-31 10:34:36,484 - INFO - tqdm - bleu_BLEU: 0.2192, rouge_ROUGE-1_R: 0.4834, rouge_ROUGE-2_R: 0.3221, rouge_ROUGE-1_P: 0.6686, rouge_ROUGE-2_P: 0.4499, rouge_ROUGE-1_F1: 0.5496, rouge_ROUGE-2_F1: 0.3673, rouge_ROUGE-L: 0.4797, SARI: 0.5553, count: 217.0000, batch_loss: 0.7460, loss: 1.3751 ||:  95%|#########4| 109/115 [01:44<00:05,  1.08it/s]
2022-03-31 10:34:41,835 - INFO - tqdm - bleu_BLEU: 0.2201, rouge_ROUGE-1_R: 0.4867, rouge_ROUGE-2_R: 0.3231, rouge_ROUGE-1_P: 0.6647, rouge_ROUGE-2_P: 0.4460, rouge_ROUGE-1_F1: 0.5502, rouge_ROUGE-2_F1: 0.3665, rouge_ROUGE-L: 0.4805, SARI: 0.5546, count: 229.0000, batch_loss: 2.2068, loss: 1.3894 ||: 100%|##########| 115/115 [01:49<00:00,  1.09it/s]
2022-03-31 10:34:41,836 - INFO - tqdm - bleu_BLEU: 0.2201, rouge_ROUGE-1_R: 0.4867, rouge_ROUGE-2_R: 0.3231, rouge_ROUGE-1_P: 0.6647, rouge_ROUGE-2_P: 0.4460, rouge_ROUGE-1_F1: 0.5502, rouge_ROUGE-2_F1: 0.3665, rouge_ROUGE-L: 0.4805, SARI: 0.5546, count: 229.0000, batch_loss: 2.2068, loss: 1.3894 ||: 100%|##########| 115/115 [01:49<00:00,  1.05it/s]
2022-03-31 10:34:41,836 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2022-03-31 10:34:41,837 - INFO - allennlp.training.tensorboard_writer - SARI               |       N/A  |     0.555
2022-03-31 10:34:41,837 - INFO - allennlp.training.tensorboard_writer - bleu_BLEU          |       N/A  |     0.220
2022-03-31 10:34:41,838 - INFO - allennlp.training.tensorboard_writer - count              |       N/A  |   229.000
2022-03-31 10:34:41,838 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |  6843.718  |       N/A
2022-03-31 10:34:41,839 - INFO - allennlp.training.tensorboard_writer - loss               |     1.363  |     1.389
2022-03-31 10:34:41,840 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_F1   |       N/A  |     0.550
2022-03-31 10:34:41,840 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_P    |       N/A  |     0.665
2022-03-31 10:34:41,840 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_R    |       N/A  |     0.487
2022-03-31 10:34:41,841 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_F1   |       N/A  |     0.366
2022-03-31 10:34:41,841 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_P    |       N/A  |     0.446
2022-03-31 10:34:41,842 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_R    |       N/A  |     0.323
2022-03-31 10:34:41,842 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-L      |       N/A  |     0.480
2022-03-31 10:34:41,843 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5241.066  |       N/A
2022-03-31 10:34:48,071 - INFO - allennlp.training.trainer - Epoch duration: 0:03:50.670056
2022-03-31 10:34:48,071 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:36:14
2022-03-31 10:34:48,071 - INFO - allennlp.training.trainer - Epoch 6/14
2022-03-31 10:34:48,071 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.1G
2022-03-31 10:34:48,071 - INFO - allennlp.training.trainer - GPU 0 memory usage: 6.7G
2022-03-31 10:34:48,072 - INFO - allennlp.training.trainer - Training
2022-03-31 10:34:48,073 - INFO - tqdm - 0%|          | 0/65 [00:00<?, ?it/s]
2022-03-31 10:34:58,507 - INFO - tqdm - batch_loss: 1.3326, loss: 1.3159 ||:   9%|9         | 6/65 [00:10<01:42,  1.74s/it]
2022-03-31 10:35:09,718 - INFO - tqdm - batch_loss: 1.2937, loss: 1.3397 ||:  18%|#8        | 12/65 [00:21<01:37,  1.85s/it]
2022-03-31 10:35:20,406 - INFO - tqdm - batch_loss: 1.3002, loss: 1.3384 ||:  28%|##7       | 18/65 [00:32<01:23,  1.78s/it]
2022-03-31 10:35:30,818 - INFO - tqdm - batch_loss: 1.2324, loss: 1.3102 ||:  37%|###6      | 24/65 [00:42<01:11,  1.75s/it]
2022-03-31 10:35:41,133 - INFO - tqdm - batch_loss: 1.2998, loss: 1.3035 ||:  46%|####6     | 30/65 [00:53<01:00,  1.73s/it]
2022-03-31 10:35:51,312 - INFO - tqdm - batch_loss: 1.3138, loss: 1.2944 ||:  55%|#####5    | 36/65 [01:03<00:49,  1.71s/it]
2022-03-31 10:36:01,642 - INFO - tqdm - batch_loss: 1.4161, loss: 1.3034 ||:  65%|######4   | 42/65 [01:13<00:39,  1.71s/it]
2022-03-31 10:36:12,178 - INFO - tqdm - batch_loss: 1.4072, loss: 1.3124 ||:  74%|#######3  | 48/65 [01:24<00:29,  1.75s/it]
2022-03-31 10:36:22,501 - INFO - tqdm - batch_loss: 1.3540, loss: 1.3017 ||:  83%|########3 | 54/65 [01:34<00:19,  1.73s/it]
2022-03-31 10:36:32,889 - INFO - tqdm - batch_loss: 1.4026, loss: 1.2971 ||:  92%|#########2| 60/65 [01:44<00:08,  1.74s/it]
2022-03-31 10:36:40,643 - INFO - tqdm - batch_loss: 1.1538, loss: 1.2987 ||: 100%|##########| 65/65 [01:52<00:00,  1.46s/it]
2022-03-31 10:36:40,644 - INFO - tqdm - batch_loss: 1.1538, loss: 1.2987 ||: 100%|##########| 65/65 [01:52<00:00,  1.73s/it]
2022-03-31 10:36:43,751 - INFO - allennlp.training.trainer - Validating
2022-03-31 10:36:43,753 - INFO - tqdm - 0%|          | 0/115 [00:00<?, ?it/s]
2022-03-31 10:36:54,587 - INFO - tqdm - bleu_BLEU: 0.2201, rouge_ROUGE-1_R: 0.5095, rouge_ROUGE-2_R: 0.3290, rouge_ROUGE-1_P: 0.6466, rouge_ROUGE-2_P: 0.4220, rouge_ROUGE-1_F1: 0.5619, rouge_ROUGE-2_F1: 0.3644, rouge_ROUGE-L: 0.4656, SARI: 0.5532, count: 20.0000, batch_loss: 1.1634, loss: 1.3147 ||:   9%|8         | 10/115 [00:10<02:09,  1.24s/it]
2022-03-31 10:37:05,103 - INFO - tqdm - bleu_BLEU: 0.2477, rouge_ROUGE-1_R: 0.5345, rouge_ROUGE-2_R: 0.3538, rouge_ROUGE-1_P: 0.6520, rouge_ROUGE-2_P: 0.4381, rouge_ROUGE-1_F1: 0.5750, rouge_ROUGE-2_F1: 0.3832, rouge_ROUGE-L: 0.4836, SARI: 0.5623, count: 42.0000, batch_loss: 1.3020, loss: 1.3330 ||:  18%|#8        | 21/115 [00:21<01:29,  1.05it/s]
2022-03-31 10:37:15,233 - INFO - tqdm - bleu_BLEU: 0.2478, rouge_ROUGE-1_R: 0.5392, rouge_ROUGE-2_R: 0.3560, rouge_ROUGE-1_P: 0.6325, rouge_ROUGE-2_P: 0.4227, rouge_ROUGE-1_F1: 0.5670, rouge_ROUGE-2_F1: 0.3762, rouge_ROUGE-L: 0.4749, SARI: 0.5564, count: 61.0000, batch_loss: 2.4287, loss: 1.4480 ||:  27%|##6       | 31/115 [00:31<01:25,  1.01s/it]
2022-03-31 10:37:25,702 - INFO - tqdm - bleu_BLEU: 0.2430, rouge_ROUGE-1_R: 0.5295, rouge_ROUGE-2_R: 0.3465, rouge_ROUGE-1_P: 0.6316, rouge_ROUGE-2_P: 0.4178, rouge_ROUGE-1_F1: 0.5627, rouge_ROUGE-2_F1: 0.3697, rouge_ROUGE-L: 0.4775, SARI: 0.5611, count: 81.0000, batch_loss: 1.4833, loss: 1.3986 ||:  36%|###5      | 41/115 [00:41<01:24,  1.15s/it]
2022-03-31 10:37:36,369 - INFO - tqdm - bleu_BLEU: 0.2334, rouge_ROUGE-1_R: 0.5167, rouge_ROUGE-2_R: 0.3382, rouge_ROUGE-1_P: 0.6443, rouge_ROUGE-2_P: 0.4254, rouge_ROUGE-1_F1: 0.5595, rouge_ROUGE-2_F1: 0.3674, rouge_ROUGE-L: 0.4761, SARI: 0.5552, count: 103.0000, batch_loss: 1.9895, loss: 1.4342 ||:  45%|####5     | 52/115 [00:52<01:03,  1.01s/it]
2022-03-31 10:37:46,667 - INFO - tqdm - bleu_BLEU: 0.2474, rouge_ROUGE-1_R: 0.5321, rouge_ROUGE-2_R: 0.3526, rouge_ROUGE-1_P: 0.6529, rouge_ROUGE-2_P: 0.4356, rouge_ROUGE-1_F1: 0.5733, rouge_ROUGE-2_F1: 0.3809, rouge_ROUGE-L: 0.4903, SARI: 0.5583, count: 123.0000, batch_loss: 0.9631, loss: 1.3978 ||:  54%|#####3    | 62/115 [01:02<00:54,  1.03s/it]
2022-03-31 10:37:57,227 - INFO - tqdm - bleu_BLEU: 0.2377, rouge_ROUGE-1_R: 0.5209, rouge_ROUGE-2_R: 0.3411, rouge_ROUGE-1_P: 0.6439, rouge_ROUGE-2_P: 0.4240, rouge_ROUGE-1_F1: 0.5633, rouge_ROUGE-2_F1: 0.3696, rouge_ROUGE-L: 0.4811, SARI: 0.5548, count: 143.0000, batch_loss: 1.0988, loss: 1.3699 ||:  63%|######2   | 72/115 [01:13<00:42,  1.02it/s]
2022-03-31 10:38:07,845 - INFO - tqdm - bleu_BLEU: 0.2381, rouge_ROUGE-1_R: 0.5185, rouge_ROUGE-2_R: 0.3391, rouge_ROUGE-1_P: 0.6415, rouge_ROUGE-2_P: 0.4229, rouge_ROUGE-1_F1: 0.5612, rouge_ROUGE-2_F1: 0.3682, rouge_ROUGE-L: 0.4798, SARI: 0.5551, count: 165.0000, batch_loss: 0.7512, loss: 1.3687 ||:  72%|#######2  | 83/115 [01:24<00:30,  1.04it/s]
2022-03-31 10:38:18,749 - INFO - tqdm - bleu_BLEU: 0.2362, rouge_ROUGE-1_R: 0.5204, rouge_ROUGE-2_R: 0.3389, rouge_ROUGE-1_P: 0.6424, rouge_ROUGE-2_P: 0.4218, rouge_ROUGE-1_F1: 0.5631, rouge_ROUGE-2_F1: 0.3680, rouge_ROUGE-L: 0.4821, SARI: 0.5548, count: 187.0000, batch_loss: 1.0066, loss: 1.3730 ||:  82%|########1 | 94/115 [01:34<00:21,  1.01s/it]
2022-03-31 10:38:28,821 - INFO - tqdm - bleu_BLEU: 0.2325, rouge_ROUGE-1_R: 0.5153, rouge_ROUGE-2_R: 0.3363, rouge_ROUGE-1_P: 0.6481, rouge_ROUGE-2_P: 0.4266, rouge_ROUGE-1_F1: 0.5617, rouge_ROUGE-2_F1: 0.3678, rouge_ROUGE-L: 0.4824, SARI: 0.5558, count: 209.0000, batch_loss: 1.5640, loss: 1.3878 ||:  91%|#########1| 105/115 [01:45<00:09,  1.08it/s]
2022-03-31 10:38:38,259 - INFO - tqdm - bleu_BLEU: 0.2279, rouge_ROUGE-1_R: 0.5092, rouge_ROUGE-2_R: 0.3309, rouge_ROUGE-1_P: 0.6457, rouge_ROUGE-2_P: 0.4238, rouge_ROUGE-1_F1: 0.5562, rouge_ROUGE-2_F1: 0.3629, rouge_ROUGE-L: 0.4774, SARI: 0.5578, count: 229.0000, batch_loss: 1.5204, loss: 1.3918 ||: 100%|##########| 115/115 [01:54<00:00,  1.07it/s]
2022-03-31 10:38:38,259 - INFO - tqdm - bleu_BLEU: 0.2279, rouge_ROUGE-1_R: 0.5092, rouge_ROUGE-2_R: 0.3309, rouge_ROUGE-1_P: 0.6457, rouge_ROUGE-2_P: 0.4238, rouge_ROUGE-1_F1: 0.5562, rouge_ROUGE-2_F1: 0.3629, rouge_ROUGE-L: 0.4774, SARI: 0.5578, count: 229.0000, batch_loss: 1.5204, loss: 1.3918 ||: 100%|##########| 115/115 [01:54<00:00,  1.00it/s]
2022-03-31 10:38:38,261 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2022-03-31 10:38:38,261 - INFO - allennlp.training.tensorboard_writer - SARI               |       N/A  |     0.558
2022-03-31 10:38:38,262 - INFO - allennlp.training.tensorboard_writer - bleu_BLEU          |       N/A  |     0.228
2022-03-31 10:38:38,262 - INFO - allennlp.training.tensorboard_writer - count              |       N/A  |   229.000
2022-03-31 10:38:38,263 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |  6843.718  |       N/A
2022-03-31 10:38:38,264 - INFO - allennlp.training.tensorboard_writer - loss               |     1.299  |     1.392
2022-03-31 10:38:38,264 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_F1   |       N/A  |     0.556
2022-03-31 10:38:38,265 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_P    |       N/A  |     0.646
2022-03-31 10:38:38,265 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_R    |       N/A  |     0.509
2022-03-31 10:38:38,266 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_F1   |       N/A  |     0.363
2022-03-31 10:38:38,266 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_P    |       N/A  |     0.424
2022-03-31 10:38:38,266 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_R    |       N/A  |     0.331
2022-03-31 10:38:38,267 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-L      |       N/A  |     0.477
2022-03-31 10:38:38,267 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5241.066  |       N/A
2022-03-31 10:38:44,436 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to './output_decomposition/best.th'.
2022-03-31 10:39:05,562 - INFO - allennlp.training.trainer - Epoch duration: 0:04:17.491043
2022-03-31 10:39:05,562 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:32:30
2022-03-31 10:39:05,563 - INFO - allennlp.training.trainer - Epoch 7/14
2022-03-31 10:39:05,563 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.1G
2022-03-31 10:39:05,563 - INFO - allennlp.training.trainer - GPU 0 memory usage: 6.7G
2022-03-31 10:39:05,564 - INFO - allennlp.training.trainer - Training
2022-03-31 10:39:05,565 - INFO - tqdm - 0%|          | 0/65 [00:00<?, ?it/s]
2022-03-31 10:39:15,963 - INFO - tqdm - batch_loss: 1.3558, loss: 1.2611 ||:   9%|9         | 6/65 [00:10<01:41,  1.72s/it]
2022-03-31 10:39:26,415 - INFO - tqdm - batch_loss: 1.3528, loss: 1.2754 ||:  18%|#8        | 12/65 [00:20<01:32,  1.74s/it]
2022-03-31 10:39:37,008 - INFO - tqdm - batch_loss: 1.2346, loss: 1.2636 ||:  28%|##7       | 18/65 [00:31<01:22,  1.76s/it]
2022-03-31 10:39:47,528 - INFO - tqdm - batch_loss: 1.1044, loss: 1.2453 ||:  37%|###6      | 24/65 [00:41<01:12,  1.76s/it]
2022-03-31 10:39:57,804 - INFO - tqdm - batch_loss: 1.1259, loss: 1.2407 ||:  46%|####6     | 30/65 [00:52<00:59,  1.71s/it]
2022-03-31 10:40:08,255 - INFO - tqdm - batch_loss: 1.2391, loss: 1.2457 ||:  55%|#####5    | 36/65 [01:02<00:50,  1.74s/it]
2022-03-31 10:40:18,612 - INFO - tqdm - batch_loss: 1.2089, loss: 1.2378 ||:  65%|######4   | 42/65 [01:13<00:39,  1.73s/it]
2022-03-31 10:40:29,385 - INFO - tqdm - batch_loss: 1.2092, loss: 1.2350 ||:  74%|#######3  | 48/65 [01:23<00:29,  1.76s/it]
2022-03-31 10:40:39,746 - INFO - tqdm - batch_loss: 1.1869, loss: 1.2361 ||:  83%|########3 | 54/65 [01:34<00:19,  1.73s/it]
2022-03-31 10:40:50,122 - INFO - tqdm - batch_loss: 1.3372, loss: 1.2417 ||:  92%|#########2| 60/65 [01:44<00:08,  1.73s/it]
2022-03-31 10:40:57,894 - INFO - tqdm - batch_loss: 1.2843, loss: 1.2414 ||: 100%|##########| 65/65 [01:52<00:00,  1.46s/it]
2022-03-31 10:40:57,894 - INFO - tqdm - batch_loss: 1.2843, loss: 1.2414 ||: 100%|##########| 65/65 [01:52<00:00,  1.73s/it]
2022-03-31 10:41:01,007 - INFO - allennlp.training.trainer - Validating
2022-03-31 10:41:01,008 - INFO - tqdm - 0%|          | 0/115 [00:00<?, ?it/s]
2022-03-31 10:41:11,055 - INFO - tqdm - bleu_BLEU: 0.1977, rouge_ROUGE-1_R: 0.5016, rouge_ROUGE-2_R: 0.3168, rouge_ROUGE-1_P: 0.6251, rouge_ROUGE-2_P: 0.3991, rouge_ROUGE-1_F1: 0.5476, rouge_ROUGE-2_F1: 0.3471, rouge_ROUGE-L: 0.4728, SARI: 0.5489, count: 20.0000, batch_loss: 1.6696, loss: 1.4378 ||:   9%|8         | 10/115 [00:10<01:43,  1.01it/s]
2022-03-31 10:41:21,240 - INFO - tqdm - bleu_BLEU: 0.2438, rouge_ROUGE-1_R: 0.5242, rouge_ROUGE-2_R: 0.3417, rouge_ROUGE-1_P: 0.6373, rouge_ROUGE-2_P: 0.4216, rouge_ROUGE-1_F1: 0.5650, rouge_ROUGE-2_F1: 0.3706, rouge_ROUGE-L: 0.4805, SARI: 0.5590, count: 40.0000, batch_loss: 0.9957, loss: 1.4119 ||:  17%|#7        | 20/115 [00:20<01:25,  1.11it/s]
2022-03-31 10:41:31,901 - INFO - tqdm - bleu_BLEU: 0.2160, rouge_ROUGE-1_R: 0.4956, rouge_ROUGE-2_R: 0.3173, rouge_ROUGE-1_P: 0.6196, rouge_ROUGE-2_P: 0.4013, rouge_ROUGE-1_F1: 0.5389, rouge_ROUGE-2_F1: 0.3463, rouge_ROUGE-L: 0.4600, SARI: 0.5584, count: 60.0000, batch_loss: 1.3906, loss: 1.5084 ||:  26%|##6       | 30/115 [00:30<01:22,  1.03it/s]
2022-03-31 10:41:42,432 - INFO - tqdm - bleu_BLEU: 0.2252, rouge_ROUGE-1_R: 0.5096, rouge_ROUGE-2_R: 0.3257, rouge_ROUGE-1_P: 0.6179, rouge_ROUGE-2_P: 0.4001, rouge_ROUGE-1_F1: 0.5453, rouge_ROUGE-2_F1: 0.3500, rouge_ROUGE-L: 0.4676, SARI: 0.5514, count: 82.0000, batch_loss: 2.6512, loss: 1.5114 ||:  36%|###5      | 41/115 [00:41<01:10,  1.06it/s]
2022-03-31 10:41:52,913 - INFO - tqdm - bleu_BLEU: 0.2220, rouge_ROUGE-1_R: 0.5054, rouge_ROUGE-2_R: 0.3231, rouge_ROUGE-1_P: 0.6225, rouge_ROUGE-2_P: 0.4030, rouge_ROUGE-1_F1: 0.5456, rouge_ROUGE-2_F1: 0.3503, rouge_ROUGE-L: 0.4703, SARI: 0.5559, count: 102.0000, batch_loss: 1.2804, loss: 1.4891 ||:  44%|####4     | 51/115 [00:51<01:00,  1.06it/s]
2022-03-31 10:42:02,952 - INFO - tqdm - bleu_BLEU: 0.2299, rouge_ROUGE-1_R: 0.5110, rouge_ROUGE-2_R: 0.3312, rouge_ROUGE-1_P: 0.6310, rouge_ROUGE-2_P: 0.4143, rouge_ROUGE-1_F1: 0.5521, rouge_ROUGE-2_F1: 0.3595, rouge_ROUGE-L: 0.4791, SARI: 0.5574, count: 121.0000, batch_loss: 1.3995, loss: 1.4278 ||:  53%|#####3    | 61/115 [01:01<00:56,  1.05s/it]
2022-03-31 10:42:13,551 - INFO - tqdm - bleu_BLEU: 0.2263, rouge_ROUGE-1_R: 0.5105, rouge_ROUGE-2_R: 0.3316, rouge_ROUGE-1_P: 0.6444, rouge_ROUGE-2_P: 0.4238, rouge_ROUGE-1_F1: 0.5569, rouge_ROUGE-2_F1: 0.3632, rouge_ROUGE-L: 0.4794, SARI: 0.5539, count: 143.0000, batch_loss: 0.9573, loss: 1.4132 ||:  63%|######2   | 72/115 [01:12<00:42,  1.02it/s]
2022-03-31 10:42:24,093 - INFO - tqdm - bleu_BLEU: 0.2283, rouge_ROUGE-1_R: 0.5145, rouge_ROUGE-2_R: 0.3340, rouge_ROUGE-1_P: 0.6371, rouge_ROUGE-2_P: 0.4180, rouge_ROUGE-1_F1: 0.5563, rouge_ROUGE-2_F1: 0.3624, rouge_ROUGE-L: 0.4791, SARI: 0.5540, count: 163.0000, batch_loss: 1.0382, loss: 1.3919 ||:  71%|#######1  | 82/115 [01:23<00:35,  1.09s/it]
2022-03-31 10:42:34,827 - INFO - tqdm - bleu_BLEU: 0.2258, rouge_ROUGE-1_R: 0.5092, rouge_ROUGE-2_R: 0.3300, rouge_ROUGE-1_P: 0.6414, rouge_ROUGE-2_P: 0.4212, rouge_ROUGE-1_F1: 0.5545, rouge_ROUGE-2_F1: 0.3609, rouge_ROUGE-L: 0.4780, SARI: 0.5565, count: 185.0000, batch_loss: 1.7842, loss: 1.4136 ||:  81%|########  | 93/115 [01:33<00:21,  1.02it/s]
2022-03-31 10:42:45,324 - INFO - tqdm - bleu_BLEU: 0.2254, rouge_ROUGE-1_R: 0.5071, rouge_ROUGE-2_R: 0.3296, rouge_ROUGE-1_P: 0.6435, rouge_ROUGE-2_P: 0.4232, rouge_ROUGE-1_F1: 0.5547, rouge_ROUGE-2_F1: 0.3619, rouge_ROUGE-L: 0.4756, SARI: 0.5569, count: 207.0000, batch_loss: 1.4998, loss: 1.4082 ||:  90%|######### | 104/115 [01:44<00:10,  1.05it/s]
2022-03-31 10:42:55,368 - INFO - tqdm - bleu_BLEU: 0.2321, rouge_ROUGE-1_R: 0.5127, rouge_ROUGE-2_R: 0.3364, rouge_ROUGE-1_P: 0.6452, rouge_ROUGE-2_P: 0.4277, rouge_ROUGE-1_F1: 0.5591, rouge_ROUGE-2_F1: 0.3681, rouge_ROUGE-L: 0.4802, SARI: 0.5600, count: 227.0000, batch_loss: 1.7044, loss: 1.3930 ||:  99%|#########9| 114/115 [01:54<00:01,  1.04s/it]
2022-03-31 10:42:56,122 - INFO - tqdm - bleu_BLEU: 0.2327, rouge_ROUGE-1_R: 0.5132, rouge_ROUGE-2_R: 0.3371, rouge_ROUGE-1_P: 0.6452, rouge_ROUGE-2_P: 0.4281, rouge_ROUGE-1_F1: 0.5595, rouge_ROUGE-2_F1: 0.3687, rouge_ROUGE-L: 0.4813, SARI: 0.5588, count: 229.0000, batch_loss: 0.7072, loss: 1.3870 ||: 100%|##########| 115/115 [01:55<00:00,  1.05it/s]
2022-03-31 10:42:56,122 - INFO - tqdm - bleu_BLEU: 0.2327, rouge_ROUGE-1_R: 0.5132, rouge_ROUGE-2_R: 0.3371, rouge_ROUGE-1_P: 0.6452, rouge_ROUGE-2_P: 0.4281, rouge_ROUGE-1_F1: 0.5595, rouge_ROUGE-2_F1: 0.3687, rouge_ROUGE-L: 0.4813, SARI: 0.5588, count: 229.0000, batch_loss: 0.7072, loss: 1.3870 ||: 100%|##########| 115/115 [01:55<00:00,  1.00s/it]
2022-03-31 10:42:56,123 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2022-03-31 10:42:56,123 - INFO - allennlp.training.tensorboard_writer - SARI               |       N/A  |     0.559
2022-03-31 10:42:56,124 - INFO - allennlp.training.tensorboard_writer - bleu_BLEU          |       N/A  |     0.233
2022-03-31 10:42:56,124 - INFO - allennlp.training.tensorboard_writer - count              |       N/A  |   229.000
2022-03-31 10:42:56,125 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |  6843.718  |       N/A
2022-03-31 10:42:56,125 - INFO - allennlp.training.tensorboard_writer - loss               |     1.241  |     1.387
2022-03-31 10:42:56,126 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_F1   |       N/A  |     0.559
2022-03-31 10:42:56,126 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_P    |       N/A  |     0.645
2022-03-31 10:42:56,126 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_R    |       N/A  |     0.513
2022-03-31 10:42:56,127 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_F1   |       N/A  |     0.369
2022-03-31 10:42:56,127 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_P    |       N/A  |     0.428
2022-03-31 10:42:56,128 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_R    |       N/A  |     0.337
2022-03-31 10:42:56,128 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-L      |       N/A  |     0.481
2022-03-31 10:42:56,128 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5241.066  |       N/A
2022-03-31 10:43:02,417 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to './output_decomposition/best.th'.
2022-03-31 10:43:25,336 - INFO - allennlp.training.trainer - Epoch duration: 0:04:19.773200
2022-03-31 10:43:25,336 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:28:40
2022-03-31 10:43:25,336 - INFO - allennlp.training.trainer - Epoch 8/14
2022-03-31 10:43:25,336 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.1G
2022-03-31 10:43:25,337 - INFO - allennlp.training.trainer - GPU 0 memory usage: 6.7G
2022-03-31 10:43:25,338 - INFO - allennlp.training.trainer - Training
2022-03-31 10:43:25,338 - INFO - tqdm - 0%|          | 0/65 [00:00<?, ?it/s]
2022-03-31 10:43:35,831 - INFO - tqdm - batch_loss: 1.1702, loss: 1.1120 ||:   9%|9         | 6/65 [00:10<01:43,  1.76s/it]
2022-03-31 10:43:46,285 - INFO - tqdm - batch_loss: 1.1719, loss: 1.1680 ||:  18%|#8        | 12/65 [00:20<01:32,  1.74s/it]
2022-03-31 10:43:56,562 - INFO - tqdm - batch_loss: 1.1798, loss: 1.1607 ||:  28%|##7       | 18/65 [00:31<01:21,  1.73s/it]
2022-03-31 10:44:06,974 - INFO - tqdm - batch_loss: 1.3435, loss: 1.1784 ||:  37%|###6      | 24/65 [00:41<01:11,  1.73s/it]
2022-03-31 10:44:17,302 - INFO - tqdm - batch_loss: 1.2755, loss: 1.1870 ||:  46%|####6     | 30/65 [00:51<01:00,  1.72s/it]
2022-03-31 10:44:27,595 - INFO - tqdm - batch_loss: 1.2296, loss: 1.1948 ||:  55%|#####5    | 36/65 [01:02<00:50,  1.73s/it]
2022-03-31 10:44:37,966 - INFO - tqdm - batch_loss: 1.1654, loss: 1.1903 ||:  65%|######4   | 42/65 [01:12<00:39,  1.73s/it]
2022-03-31 10:44:48,287 - INFO - tqdm - batch_loss: 1.1602, loss: 1.1928 ||:  74%|#######3  | 48/65 [01:22<00:29,  1.72s/it]
2022-03-31 10:44:58,673 - INFO - tqdm - batch_loss: 1.1375, loss: 1.2003 ||:  83%|########3 | 54/65 [01:33<00:18,  1.72s/it]
2022-03-31 10:45:09,013 - INFO - tqdm - batch_loss: 1.2161, loss: 1.1961 ||:  92%|#########2| 60/65 [01:43<00:08,  1.73s/it]
2022-03-31 10:45:16,704 - INFO - tqdm - batch_loss: 1.3362, loss: 1.1981 ||: 100%|##########| 65/65 [01:51<00:00,  1.45s/it]
2022-03-31 10:45:16,704 - INFO - tqdm - batch_loss: 1.3362, loss: 1.1981 ||: 100%|##########| 65/65 [01:51<00:00,  1.71s/it]
2022-03-31 10:45:19,857 - INFO - allennlp.training.trainer - Validating
2022-03-31 10:45:19,859 - INFO - tqdm - 0%|          | 0/115 [00:00<?, ?it/s]
2022-03-31 10:45:30,588 - INFO - tqdm - bleu_BLEU: 0.2100, rouge_ROUGE-1_R: 0.4825, rouge_ROUGE-2_R: 0.3124, rouge_ROUGE-1_P: 0.6370, rouge_ROUGE-2_P: 0.4131, rouge_ROUGE-1_F1: 0.5389, rouge_ROUGE-2_F1: 0.3489, rouge_ROUGE-L: 0.4870, SARI: 0.5331, count: 22.0000, batch_loss: 2.0075, loss: 1.4928 ||:  10%|9         | 11/115 [00:10<01:37,  1.06it/s]
2022-03-31 10:45:41,520 - INFO - tqdm - bleu_BLEU: 0.2109, rouge_ROUGE-1_R: 0.4800, rouge_ROUGE-2_R: 0.3084, rouge_ROUGE-1_P: 0.6360, rouge_ROUGE-2_P: 0.4088, rouge_ROUGE-1_F1: 0.5363, rouge_ROUGE-2_F1: 0.3447, rouge_ROUGE-L: 0.4722, SARI: 0.5408, count: 42.0000, batch_loss: 1.1489, loss: 1.5328 ||:  18%|#8        | 21/115 [00:21<01:39,  1.05s/it]
2022-03-31 10:45:51,861 - INFO - tqdm - bleu_BLEU: 0.2291, rouge_ROUGE-1_R: 0.5065, rouge_ROUGE-2_R: 0.3275, rouge_ROUGE-1_P: 0.6261, rouge_ROUGE-2_P: 0.4066, rouge_ROUGE-1_F1: 0.5486, rouge_ROUGE-2_F1: 0.3556, rouge_ROUGE-L: 0.4748, SARI: 0.5521, count: 62.0000, batch_loss: 0.2345, loss: 1.4141 ||:  27%|##6       | 31/115 [00:32<01:21,  1.03it/s]
2022-03-31 10:46:02,862 - INFO - tqdm - bleu_BLEU: 0.2243, rouge_ROUGE-1_R: 0.5011, rouge_ROUGE-2_R: 0.3219, rouge_ROUGE-1_P: 0.6259, rouge_ROUGE-2_P: 0.4040, rouge_ROUGE-1_F1: 0.5448, rouge_ROUGE-2_F1: 0.3510, rouge_ROUGE-L: 0.4689, SARI: 0.5610, count: 82.0000, batch_loss: 1.5316, loss: 1.4317 ||:  36%|###5      | 41/115 [00:43<01:23,  1.12s/it]
2022-03-31 10:46:13,154 - INFO - tqdm - bleu_BLEU: 0.2196, rouge_ROUGE-1_R: 0.5036, rouge_ROUGE-2_R: 0.3227, rouge_ROUGE-1_P: 0.6337, rouge_ROUGE-2_P: 0.4080, rouge_ROUGE-1_F1: 0.5480, rouge_ROUGE-2_F1: 0.3522, rouge_ROUGE-L: 0.4681, SARI: 0.5464, count: 103.0000, batch_loss: 1.4040, loss: 1.4192 ||:  45%|####5     | 52/115 [00:53<00:57,  1.09it/s]
2022-03-31 10:46:23,280 - INFO - tqdm - bleu_BLEU: 0.2308, rouge_ROUGE-1_R: 0.5114, rouge_ROUGE-2_R: 0.3312, rouge_ROUGE-1_P: 0.6428, rouge_ROUGE-2_P: 0.4190, rouge_ROUGE-1_F1: 0.5563, rouge_ROUGE-2_F1: 0.3615, rouge_ROUGE-L: 0.4763, SARI: 0.5501, count: 123.0000, batch_loss: 1.8277, loss: 1.3901 ||:  54%|#####3    | 62/115 [01:03<00:53,  1.01s/it]
2022-03-31 10:46:34,102 - INFO - tqdm - bleu_BLEU: 0.2302, rouge_ROUGE-1_R: 0.5082, rouge_ROUGE-2_R: 0.3297, rouge_ROUGE-1_P: 0.6396, rouge_ROUGE-2_P: 0.4181, rouge_ROUGE-1_F1: 0.5537, rouge_ROUGE-2_F1: 0.3605, rouge_ROUGE-L: 0.4775, SARI: 0.5526, count: 145.0000, batch_loss: 1.2100, loss: 1.3884 ||:  63%|######3   | 73/115 [01:14<00:42,  1.00s/it]
2022-03-31 10:46:44,818 - INFO - tqdm - bleu_BLEU: 0.2362, rouge_ROUGE-1_R: 0.5173, rouge_ROUGE-2_R: 0.3365, rouge_ROUGE-1_P: 0.6255, rouge_ROUGE-2_P: 0.4089, rouge_ROUGE-1_F1: 0.5521, rouge_ROUGE-2_F1: 0.3598, rouge_ROUGE-L: 0.4787, SARI: 0.5485, count: 165.0000, batch_loss: 1.8183, loss: 1.4013 ||:  72%|#######2  | 83/115 [01:24<00:34,  1.08s/it]
2022-03-31 10:46:54,977 - INFO - tqdm - bleu_BLEU: 0.2355, rouge_ROUGE-1_R: 0.5169, rouge_ROUGE-2_R: 0.3361, rouge_ROUGE-1_P: 0.6298, rouge_ROUGE-2_P: 0.4118, rouge_ROUGE-1_F1: 0.5542, rouge_ROUGE-2_F1: 0.3612, rouge_ROUGE-L: 0.4799, SARI: 0.5541, count: 185.0000, batch_loss: 1.7656, loss: 1.3947 ||:  81%|########  | 93/115 [01:35<00:25,  1.15s/it]
2022-03-31 10:47:05,026 - INFO - tqdm - bleu_BLEU: 0.2315, rouge_ROUGE-1_R: 0.5140, rouge_ROUGE-2_R: 0.3336, rouge_ROUGE-1_P: 0.6318, rouge_ROUGE-2_P: 0.4131, rouge_ROUGE-1_F1: 0.5535, rouge_ROUGE-2_F1: 0.3603, rouge_ROUGE-L: 0.4776, SARI: 0.5507, count: 205.0000, batch_loss: 1.6004, loss: 1.3893 ||:  90%|########9 | 103/115 [01:45<00:12,  1.06s/it]
2022-03-31 10:47:15,652 - INFO - tqdm - bleu_BLEU: 0.2325, rouge_ROUGE-1_R: 0.5129, rouge_ROUGE-2_R: 0.3355, rouge_ROUGE-1_P: 0.6397, rouge_ROUGE-2_P: 0.4222, rouge_ROUGE-1_F1: 0.5564, rouge_ROUGE-2_F1: 0.3653, rouge_ROUGE-L: 0.4794, SARI: 0.5544, count: 227.0000, batch_loss: 2.0193, loss: 1.3867 ||:  99%|#########9| 114/115 [01:55<00:00,  1.05it/s]
2022-03-31 10:47:16,564 - INFO - tqdm - bleu_BLEU: 0.2337, rouge_ROUGE-1_R: 0.5133, rouge_ROUGE-2_R: 0.3363, rouge_ROUGE-1_P: 0.6407, rouge_ROUGE-2_P: 0.4236, rouge_ROUGE-1_F1: 0.5572, rouge_ROUGE-2_F1: 0.3664, rouge_ROUGE-L: 0.4806, SARI: 0.5559, count: 229.0000, batch_loss: 0.9731, loss: 1.3831 ||: 100%|##########| 115/115 [01:56<00:00,  1.07it/s]
2022-03-31 10:47:16,564 - INFO - tqdm - bleu_BLEU: 0.2337, rouge_ROUGE-1_R: 0.5133, rouge_ROUGE-2_R: 0.3363, rouge_ROUGE-1_P: 0.6407, rouge_ROUGE-2_P: 0.4236, rouge_ROUGE-1_F1: 0.5572, rouge_ROUGE-2_F1: 0.3664, rouge_ROUGE-L: 0.4806, SARI: 0.5559, count: 229.0000, batch_loss: 0.9731, loss: 1.3831 ||: 100%|##########| 115/115 [01:56<00:00,  1.01s/it]
2022-03-31 10:47:16,565 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2022-03-31 10:47:16,565 - INFO - allennlp.training.tensorboard_writer - SARI               |       N/A  |     0.556
2022-03-31 10:47:16,566 - INFO - allennlp.training.tensorboard_writer - bleu_BLEU          |       N/A  |     0.234
2022-03-31 10:47:16,567 - INFO - allennlp.training.tensorboard_writer - count              |       N/A  |   229.000
2022-03-31 10:47:16,567 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |  6843.718  |       N/A
2022-03-31 10:47:16,567 - INFO - allennlp.training.tensorboard_writer - loss               |     1.198  |     1.383
2022-03-31 10:47:16,568 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_F1   |       N/A  |     0.557
2022-03-31 10:47:16,568 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_P    |       N/A  |     0.641
2022-03-31 10:47:16,569 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_R    |       N/A  |     0.513
2022-03-31 10:47:16,569 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_F1   |       N/A  |     0.366
2022-03-31 10:47:16,570 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_P    |       N/A  |     0.424
2022-03-31 10:47:16,570 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_R    |       N/A  |     0.336
2022-03-31 10:47:16,571 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-L      |       N/A  |     0.481
2022-03-31 10:47:16,571 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5241.066  |       N/A
2022-03-31 10:47:22,836 - INFO - allennlp.training.trainer - Epoch duration: 0:03:57.499605
2022-03-31 10:47:22,836 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:24:29
2022-03-31 10:47:22,836 - INFO - allennlp.training.trainer - Epoch 9/14
2022-03-31 10:47:22,836 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.1G
2022-03-31 10:47:22,837 - INFO - allennlp.training.trainer - GPU 0 memory usage: 6.7G
2022-03-31 10:47:22,838 - INFO - allennlp.training.trainer - Training
2022-03-31 10:47:22,838 - INFO - tqdm - 0%|          | 0/65 [00:00<?, ?it/s]
2022-03-31 10:47:33,348 - INFO - tqdm - batch_loss: 1.1211, loss: 1.1432 ||:   9%|9         | 6/65 [00:10<01:43,  1.75s/it]
2022-03-31 10:47:43,839 - INFO - tqdm - batch_loss: 1.1715, loss: 1.1371 ||:  18%|#8        | 12/65 [00:21<01:33,  1.76s/it]
2022-03-31 10:47:55,113 - INFO - tqdm - batch_loss: 1.0724, loss: 1.1309 ||:  28%|##7       | 18/65 [00:32<01:26,  1.84s/it]
2022-03-31 10:48:05,744 - INFO - tqdm - batch_loss: 1.1358, loss: 1.1241 ||:  37%|###6      | 24/65 [00:42<01:13,  1.78s/it]
2022-03-31 10:48:16,139 - INFO - tqdm - batch_loss: 1.2020, loss: 1.1265 ||:  46%|####6     | 30/65 [00:53<01:00,  1.74s/it]
2022-03-31 10:48:26,500 - INFO - tqdm - batch_loss: 1.2347, loss: 1.1306 ||:  55%|#####5    | 36/65 [01:03<00:50,  1.74s/it]
2022-03-31 10:48:36,792 - INFO - tqdm - batch_loss: 1.2642, loss: 1.1377 ||:  65%|######4   | 42/65 [01:13<00:39,  1.71s/it]
2022-03-31 10:48:46,969 - INFO - tqdm - batch_loss: 1.0559, loss: 1.1319 ||:  74%|#######3  | 48/65 [01:24<00:28,  1.70s/it]
2022-03-31 10:48:57,254 - INFO - tqdm - batch_loss: 1.1959, loss: 1.1354 ||:  83%|########3 | 54/65 [01:34<00:18,  1.71s/it]
2022-03-31 10:49:07,673 - INFO - tqdm - batch_loss: 1.1040, loss: 1.1383 ||:  92%|#########2| 60/65 [01:44<00:08,  1.73s/it]
2022-03-31 10:49:15,462 - INFO - tqdm - batch_loss: 1.1797, loss: 1.1386 ||: 100%|##########| 65/65 [01:52<00:00,  1.47s/it]
2022-03-31 10:49:15,462 - INFO - tqdm - batch_loss: 1.1797, loss: 1.1386 ||: 100%|##########| 65/65 [01:52<00:00,  1.73s/it]
2022-03-31 10:49:18,789 - INFO - allennlp.training.trainer - Validating
2022-03-31 10:49:18,790 - INFO - tqdm - 0%|          | 0/115 [00:00<?, ?it/s]
2022-03-31 10:49:29,075 - INFO - tqdm - bleu_BLEU: 0.2251, rouge_ROUGE-1_R: 0.5571, rouge_ROUGE-2_R: 0.3478, rouge_ROUGE-1_P: 0.6317, rouge_ROUGE-2_P: 0.3968, rouge_ROUGE-1_F1: 0.5773, rouge_ROUGE-2_F1: 0.3618, rouge_ROUGE-L: 0.4940, SARI: 0.5770, count: 22.0000, batch_loss: 2.1369, loss: 1.3179 ||:  10%|9         | 11/115 [00:10<01:35,  1.08it/s]
2022-03-31 10:49:40,067 - INFO - tqdm - bleu_BLEU: 0.2397, rouge_ROUGE-1_R: 0.5517, rouge_ROUGE-2_R: 0.3558, rouge_ROUGE-1_P: 0.6685, rouge_ROUGE-2_P: 0.4340, rouge_ROUGE-1_F1: 0.5892, rouge_ROUGE-2_F1: 0.3807, rouge_ROUGE-L: 0.5055, SARI: 0.5837, count: 44.0000, batch_loss: 1.4029, loss: 1.3286 ||:  19%|#9        | 22/115 [00:21<01:36,  1.04s/it]
2022-03-31 10:49:50,107 - INFO - tqdm - bleu_BLEU: 0.2286, rouge_ROUGE-1_R: 0.5288, rouge_ROUGE-2_R: 0.3432, rouge_ROUGE-1_P: 0.6660, rouge_ROUGE-2_P: 0.4344, rouge_ROUGE-1_F1: 0.5749, rouge_ROUGE-2_F1: 0.3736, rouge_ROUGE-L: 0.4937, SARI: 0.5759, count: 64.0000, batch_loss: 0.8637, loss: 1.3314 ||:  28%|##7       | 32/115 [00:31<01:25,  1.03s/it]
2022-03-31 10:50:00,730 - INFO - tqdm - bleu_BLEU: 0.2211, rouge_ROUGE-1_R: 0.5194, rouge_ROUGE-2_R: 0.3344, rouge_ROUGE-1_P: 0.6543, rouge_ROUGE-2_P: 0.4235, rouge_ROUGE-1_F1: 0.5649, rouge_ROUGE-2_F1: 0.3642, rouge_ROUGE-L: 0.4833, SARI: 0.5669, count: 82.0000, batch_loss: 1.1755, loss: 1.3111 ||:  36%|###5      | 41/115 [00:41<01:23,  1.12s/it]
2022-03-31 10:50:11,259 - INFO - tqdm - bleu_BLEU: 0.2187, rouge_ROUGE-1_R: 0.5132, rouge_ROUGE-2_R: 0.3290, rouge_ROUGE-1_P: 0.6349, rouge_ROUGE-2_P: 0.4103, rouge_ROUGE-1_F1: 0.5526, rouge_ROUGE-2_F1: 0.3550, rouge_ROUGE-L: 0.4735, SARI: 0.5568, count: 102.0000, batch_loss: 2.2103, loss: 1.3773 ||:  44%|####4     | 51/115 [00:52<01:08,  1.07s/it]
2022-03-31 10:50:21,407 - INFO - tqdm - bleu_BLEU: 0.2133, rouge_ROUGE-1_R: 0.5037, rouge_ROUGE-2_R: 0.3208, rouge_ROUGE-1_P: 0.6289, rouge_ROUGE-2_P: 0.4042, rouge_ROUGE-1_F1: 0.5460, rouge_ROUGE-2_F1: 0.3487, rouge_ROUGE-L: 0.4679, SARI: 0.5530, count: 124.0000, batch_loss: 0.9616, loss: 1.4043 ||:  54%|#####3    | 62/115 [01:02<00:47,  1.12it/s]
2022-03-31 10:50:32,104 - INFO - tqdm - bleu_BLEU: 0.2189, rouge_ROUGE-1_R: 0.5130, rouge_ROUGE-2_R: 0.3302, rouge_ROUGE-1_P: 0.6233, rouge_ROUGE-2_P: 0.4029, rouge_ROUGE-1_F1: 0.5469, rouge_ROUGE-2_F1: 0.3520, rouge_ROUGE-L: 0.4723, SARI: 0.5568, count: 144.0000, batch_loss: 2.3264, loss: 1.3870 ||:  63%|######2   | 72/115 [01:13<00:44,  1.04s/it]
2022-03-31 10:50:42,881 - INFO - tqdm - bleu_BLEU: 0.2187, rouge_ROUGE-1_R: 0.5095, rouge_ROUGE-2_R: 0.3293, rouge_ROUGE-1_P: 0.6315, rouge_ROUGE-2_P: 0.4114, rouge_ROUGE-1_F1: 0.5486, rouge_ROUGE-2_F1: 0.3551, rouge_ROUGE-L: 0.4728, SARI: 0.5581, count: 166.0000, batch_loss: 1.5557, loss: 1.3931 ||:  72%|#######2  | 83/115 [01:24<00:31,  1.02it/s]
2022-03-31 10:50:52,897 - INFO - tqdm - bleu_BLEU: 0.2152, rouge_ROUGE-1_R: 0.5044, rouge_ROUGE-2_R: 0.3253, rouge_ROUGE-1_P: 0.6367, rouge_ROUGE-2_P: 0.4137, rouge_ROUGE-1_F1: 0.5481, rouge_ROUGE-2_F1: 0.3540, rouge_ROUGE-L: 0.4719, SARI: 0.5540, count: 187.0000, batch_loss: 1.6153, loss: 1.4043 ||:  82%|########1 | 94/115 [01:34<00:19,  1.10it/s]
2022-03-31 10:51:03,122 - INFO - tqdm - bleu_BLEU: 0.2203, rouge_ROUGE-1_R: 0.5083, rouge_ROUGE-2_R: 0.3297, rouge_ROUGE-1_P: 0.6424, rouge_ROUGE-2_P: 0.4198, rouge_ROUGE-1_F1: 0.5528, rouge_ROUGE-2_F1: 0.3593, rouge_ROUGE-L: 0.4772, SARI: 0.5512, count: 209.0000, batch_loss: 1.2532, loss: 1.4116 ||:  91%|#########1| 105/115 [01:44<00:09,  1.05it/s]
2022-03-31 10:51:13,849 - INFO - tqdm - bleu_BLEU: 0.2245, rouge_ROUGE-1_R: 0.5111, rouge_ROUGE-2_R: 0.3314, rouge_ROUGE-1_P: 0.6404, rouge_ROUGE-2_P: 0.4189, rouge_ROUGE-1_F1: 0.5546, rouge_ROUGE-2_F1: 0.3606, rouge_ROUGE-L: 0.4785, SARI: 0.5550, count: 229.0000, batch_loss: 1.3175, loss: 1.3972 ||: 100%|##########| 115/115 [01:55<00:00,  1.15s/it]
2022-03-31 10:51:13,850 - INFO - tqdm - bleu_BLEU: 0.2245, rouge_ROUGE-1_R: 0.5111, rouge_ROUGE-2_R: 0.3314, rouge_ROUGE-1_P: 0.6404, rouge_ROUGE-2_P: 0.4189, rouge_ROUGE-1_F1: 0.5546, rouge_ROUGE-2_F1: 0.3606, rouge_ROUGE-L: 0.4785, SARI: 0.5550, count: 229.0000, batch_loss: 1.3175, loss: 1.3972 ||: 100%|##########| 115/115 [01:55<00:00,  1.00s/it]
2022-03-31 10:51:13,850 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2022-03-31 10:51:13,851 - INFO - allennlp.training.tensorboard_writer - SARI               |       N/A  |     0.555
2022-03-31 10:51:13,851 - INFO - allennlp.training.tensorboard_writer - bleu_BLEU          |       N/A  |     0.224
2022-03-31 10:51:13,852 - INFO - allennlp.training.tensorboard_writer - count              |       N/A  |   229.000
2022-03-31 10:51:13,852 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |  6843.718  |       N/A
2022-03-31 10:51:13,853 - INFO - allennlp.training.tensorboard_writer - loss               |     1.139  |     1.397
2022-03-31 10:51:13,854 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_F1   |       N/A  |     0.555
2022-03-31 10:51:13,854 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_P    |       N/A  |     0.640
2022-03-31 10:51:13,854 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_R    |       N/A  |     0.511
2022-03-31 10:51:13,855 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_F1   |       N/A  |     0.361
2022-03-31 10:51:13,855 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_P    |       N/A  |     0.419
2022-03-31 10:51:13,855 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_R    |       N/A  |     0.331
2022-03-31 10:51:13,856 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-L      |       N/A  |     0.478
2022-03-31 10:51:13,856 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5241.066  |       N/A
2022-03-31 10:51:20,200 - INFO - allennlp.training.trainer - Epoch duration: 0:03:57.364019
2022-03-31 10:51:20,201 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:20:20
2022-03-31 10:51:20,201 - INFO - allennlp.training.trainer - Epoch 10/14
2022-03-31 10:51:20,201 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.1G
2022-03-31 10:51:20,201 - INFO - allennlp.training.trainer - GPU 0 memory usage: 6.7G
2022-03-31 10:51:20,202 - INFO - allennlp.training.trainer - Training
2022-03-31 10:51:20,202 - INFO - tqdm - 0%|          | 0/65 [00:00<?, ?it/s]
2022-03-31 10:51:30,706 - INFO - tqdm - batch_loss: 1.1654, loss: 1.1081 ||:   9%|9         | 6/65 [00:10<01:43,  1.75s/it]
2022-03-31 10:51:41,137 - INFO - tqdm - batch_loss: 1.1587, loss: 1.1048 ||:  18%|#8        | 12/65 [00:20<01:32,  1.74s/it]
2022-03-31 10:51:51,529 - INFO - tqdm - batch_loss: 1.1700, loss: 1.1160 ||:  28%|##7       | 18/65 [00:31<01:21,  1.73s/it]
2022-03-31 10:52:02,023 - INFO - tqdm - batch_loss: 0.9804, loss: 1.1129 ||:  37%|###6      | 24/65 [00:41<01:11,  1.73s/it]
2022-03-31 10:52:12,348 - INFO - tqdm - batch_loss: 1.1779, loss: 1.1053 ||:  46%|####6     | 30/65 [00:52<01:00,  1.73s/it]
2022-03-31 10:52:22,716 - INFO - tqdm - batch_loss: 1.1602, loss: 1.0977 ||:  55%|#####5    | 36/65 [01:02<00:49,  1.72s/it]
2022-03-31 10:52:33,003 - INFO - tqdm - batch_loss: 1.0720, loss: 1.0999 ||:  65%|######4   | 42/65 [01:12<00:39,  1.72s/it]
2022-03-31 10:52:43,132 - INFO - tqdm - batch_loss: 1.1180, loss: 1.1029 ||:  74%|#######3  | 48/65 [01:22<00:28,  1.69s/it]
2022-03-31 10:52:53,922 - INFO - tqdm - batch_loss: 1.2108, loss: 1.1019 ||:  83%|########3 | 54/65 [01:33<00:19,  1.74s/it]
2022-03-31 10:53:04,210 - INFO - tqdm - batch_loss: 1.1896, loss: 1.1091 ||:  92%|#########2| 60/65 [01:44<00:08,  1.73s/it]
2022-03-31 10:53:11,928 - INFO - tqdm - batch_loss: 0.8284, loss: 1.1049 ||: 100%|##########| 65/65 [01:51<00:00,  1.45s/it]
2022-03-31 10:53:11,928 - INFO - tqdm - batch_loss: 0.8284, loss: 1.1049 ||: 100%|##########| 65/65 [01:51<00:00,  1.72s/it]
2022-03-31 10:53:14,579 - INFO - allennlp.training.trainer - Validating
2022-03-31 10:53:14,580 - INFO - tqdm - 0%|          | 0/115 [00:00<?, ?it/s]
2022-03-31 10:53:25,260 - INFO - tqdm - bleu_BLEU: 0.2226, rouge_ROUGE-1_R: 0.5324, rouge_ROUGE-2_R: 0.3504, rouge_ROUGE-1_P: 0.6675, rouge_ROUGE-2_P: 0.4401, rouge_ROUGE-1_F1: 0.5837, rouge_ROUGE-2_F1: 0.3844, rouge_ROUGE-L: 0.4818, SARI: 0.5606, count: 20.0000, batch_loss: 0.6815, loss: 1.1771 ||:   9%|8         | 10/115 [00:10<01:51,  1.06s/it]
2022-03-31 10:53:35,926 - INFO - tqdm - bleu_BLEU: 0.2266, rouge_ROUGE-1_R: 0.5271, rouge_ROUGE-2_R: 0.3455, rouge_ROUGE-1_P: 0.6717, rouge_ROUGE-2_P: 0.4420, rouge_ROUGE-1_F1: 0.5806, rouge_ROUGE-2_F1: 0.3811, rouge_ROUGE-L: 0.4920, SARI: 0.5521, count: 44.0000, batch_loss: 0.9682, loss: 1.2523 ||:  19%|#9        | 22/115 [00:21<01:23,  1.12it/s]
2022-03-31 10:53:45,985 - INFO - tqdm - bleu_BLEU: 0.2550, rouge_ROUGE-1_R: 0.5440, rouge_ROUGE-2_R: 0.3673, rouge_ROUGE-1_P: 0.6666, rouge_ROUGE-2_P: 0.4494, rouge_ROUGE-1_F1: 0.5893, rouge_ROUGE-2_F1: 0.3976, rouge_ROUGE-L: 0.5120, SARI: 0.5554, count: 66.0000, batch_loss: 0.6917, loss: 1.3171 ||:  29%|##8       | 33/115 [00:31<01:10,  1.17it/s]
2022-03-31 10:53:56,543 - INFO - tqdm - bleu_BLEU: 0.2350, rouge_ROUGE-1_R: 0.5148, rouge_ROUGE-2_R: 0.3438, rouge_ROUGE-1_P: 0.6562, rouge_ROUGE-2_P: 0.4391, rouge_ROUGE-1_F1: 0.5670, rouge_ROUGE-2_F1: 0.3789, rouge_ROUGE-L: 0.4965, SARI: 0.5603, count: 88.0000, batch_loss: 1.9379, loss: 1.3521 ||:  38%|###8      | 44/115 [00:41<01:04,  1.09it/s]
2022-03-31 10:54:06,686 - INFO - tqdm - bleu_BLEU: 0.2357, rouge_ROUGE-1_R: 0.5104, rouge_ROUGE-2_R: 0.3374, rouge_ROUGE-1_P: 0.6538, rouge_ROUGE-2_P: 0.4348, rouge_ROUGE-1_F1: 0.5645, rouge_ROUGE-2_F1: 0.3740, rouge_ROUGE-L: 0.4946, SARI: 0.5627, count: 110.0000, batch_loss: 0.7560, loss: 1.3570 ||:  48%|####7     | 55/115 [00:52<00:55,  1.08it/s]
2022-03-31 10:54:17,052 - INFO - tqdm - bleu_BLEU: 0.2299, rouge_ROUGE-1_R: 0.5041, rouge_ROUGE-2_R: 0.3307, rouge_ROUGE-1_P: 0.6478, rouge_ROUGE-2_P: 0.4280, rouge_ROUGE-1_F1: 0.5583, rouge_ROUGE-2_F1: 0.3672, rouge_ROUGE-L: 0.4892, SARI: 0.5568, count: 130.0000, batch_loss: 1.1752, loss: 1.4018 ||:  57%|#####6    | 65/115 [01:02<00:52,  1.05s/it]
2022-03-31 10:54:27,989 - INFO - tqdm - bleu_BLEU: 0.2384, rouge_ROUGE-1_R: 0.5126, rouge_ROUGE-2_R: 0.3393, rouge_ROUGE-1_P: 0.6479, rouge_ROUGE-2_P: 0.4317, rouge_ROUGE-1_F1: 0.5622, rouge_ROUGE-2_F1: 0.3731, rouge_ROUGE-L: 0.4958, SARI: 0.5664, count: 152.0000, batch_loss: 0.9508, loss: 1.3795 ||:  66%|######6   | 76/115 [01:13<00:38,  1.01it/s]
2022-03-31 10:54:38,529 - INFO - tqdm - bleu_BLEU: 0.2322, rouge_ROUGE-1_R: 0.5096, rouge_ROUGE-2_R: 0.3339, rouge_ROUGE-1_P: 0.6411, rouge_ROUGE-2_P: 0.4235, rouge_ROUGE-1_F1: 0.5565, rouge_ROUGE-2_F1: 0.3659, rouge_ROUGE-L: 0.4884, SARI: 0.5649, count: 174.0000, batch_loss: 1.2096, loss: 1.3924 ||:  76%|#######5  | 87/115 [01:23<00:25,  1.10it/s]
2022-03-31 10:54:49,223 - INFO - tqdm - bleu_BLEU: 0.2348, rouge_ROUGE-1_R: 0.5113, rouge_ROUGE-2_R: 0.3376, rouge_ROUGE-1_P: 0.6466, rouge_ROUGE-2_P: 0.4304, rouge_ROUGE-1_F1: 0.5592, rouge_ROUGE-2_F1: 0.3703, rouge_ROUGE-L: 0.4900, SARI: 0.5640, count: 196.0000, batch_loss: 1.3821, loss: 1.3683 ||:  85%|########5 | 98/115 [01:34<00:15,  1.08it/s]
2022-03-31 10:55:00,103 - INFO - tqdm - bleu_BLEU: 0.2256, rouge_ROUGE-1_R: 0.5013, rouge_ROUGE-2_R: 0.3292, rouge_ROUGE-1_P: 0.6486, rouge_ROUGE-2_P: 0.4290, rouge_ROUGE-1_F1: 0.5534, rouge_ROUGE-2_F1: 0.3643, rouge_ROUGE-L: 0.4828, SARI: 0.5586, count: 219.0000, batch_loss: 2.3996, loss: 1.4002 ||:  96%|#########5| 110/115 [01:45<00:04,  1.05it/s]
2022-03-31 10:55:04,865 - INFO - tqdm - bleu_BLEU: 0.2265, rouge_ROUGE-1_R: 0.5049, rouge_ROUGE-2_R: 0.3300, rouge_ROUGE-1_P: 0.6443, rouge_ROUGE-2_P: 0.4248, rouge_ROUGE-1_F1: 0.5539, rouge_ROUGE-2_F1: 0.3631, rouge_ROUGE-L: 0.4816, SARI: 0.5558, count: 229.0000, batch_loss: 1.3467, loss: 1.4050 ||: 100%|##########| 115/115 [01:50<00:00,  1.05it/s]
2022-03-31 10:55:04,866 - INFO - tqdm - bleu_BLEU: 0.2265, rouge_ROUGE-1_R: 0.5049, rouge_ROUGE-2_R: 0.3300, rouge_ROUGE-1_P: 0.6443, rouge_ROUGE-2_P: 0.4248, rouge_ROUGE-1_F1: 0.5539, rouge_ROUGE-2_F1: 0.3631, rouge_ROUGE-L: 0.4816, SARI: 0.5558, count: 229.0000, batch_loss: 1.3467, loss: 1.4050 ||: 100%|##########| 115/115 [01:50<00:00,  1.04it/s]
2022-03-31 10:55:04,866 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2022-03-31 10:55:04,866 - INFO - allennlp.training.tensorboard_writer - SARI               |       N/A  |     0.556
2022-03-31 10:55:04,867 - INFO - allennlp.training.tensorboard_writer - bleu_BLEU          |       N/A  |     0.226
2022-03-31 10:55:04,867 - INFO - allennlp.training.tensorboard_writer - count              |       N/A  |   229.000
2022-03-31 10:55:04,867 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |  6843.718  |       N/A
2022-03-31 10:55:04,868 - INFO - allennlp.training.tensorboard_writer - loss               |     1.105  |     1.405
2022-03-31 10:55:04,869 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_F1   |       N/A  |     0.554
2022-03-31 10:55:04,870 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_P    |       N/A  |     0.644
2022-03-31 10:55:04,870 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_R    |       N/A  |     0.505
2022-03-31 10:55:04,871 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_F1   |       N/A  |     0.363
2022-03-31 10:55:04,871 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_P    |       N/A  |     0.425
2022-03-31 10:55:04,871 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_R    |       N/A  |     0.330
2022-03-31 10:55:04,871 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-L      |       N/A  |     0.482
2022-03-31 10:55:04,871 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5241.066  |       N/A
2022-03-31 10:55:10,310 - INFO - allennlp.training.trainer - Epoch duration: 0:03:50.108066
2022-03-31 10:55:10,310 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:16:11
2022-03-31 10:55:10,310 - INFO - allennlp.training.trainer - Epoch 11/14
2022-03-31 10:55:10,310 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.1G
2022-03-31 10:55:10,311 - INFO - allennlp.training.trainer - GPU 0 memory usage: 6.7G
2022-03-31 10:55:10,312 - INFO - allennlp.training.trainer - Training
2022-03-31 10:55:10,312 - INFO - tqdm - 0%|          | 0/65 [00:00<?, ?it/s]
2022-03-31 10:55:20,846 - INFO - tqdm - batch_loss: 1.1985, loss: 1.0503 ||:   9%|9         | 6/65 [00:10<01:43,  1.76s/it]
2022-03-31 10:55:31,367 - INFO - tqdm - batch_loss: 1.0811, loss: 1.0673 ||:  18%|#8        | 12/65 [00:21<01:33,  1.76s/it]
2022-03-31 10:55:41,702 - INFO - tqdm - batch_loss: 1.0080, loss: 1.0849 ||:  28%|##7       | 18/65 [00:31<01:21,  1.73s/it]
2022-03-31 10:55:52,098 - INFO - tqdm - batch_loss: 1.1285, loss: 1.0877 ||:  37%|###6      | 24/65 [00:41<01:11,  1.73s/it]
2022-03-31 10:56:02,390 - INFO - tqdm - batch_loss: 1.1010, loss: 1.0777 ||:  46%|####6     | 30/65 [00:52<01:00,  1.72s/it]
2022-03-31 10:56:12,780 - INFO - tqdm - batch_loss: 1.0740, loss: 1.0781 ||:  55%|#####5    | 36/65 [01:02<00:50,  1.73s/it]
2022-03-31 10:56:23,202 - INFO - tqdm - batch_loss: 1.0801, loss: 1.0808 ||:  65%|######4   | 42/65 [01:12<00:39,  1.72s/it]
2022-03-31 10:56:33,550 - INFO - tqdm - batch_loss: 1.0657, loss: 1.0736 ||:  74%|#######3  | 48/65 [01:23<00:29,  1.73s/it]
2022-03-31 10:56:43,811 - INFO - tqdm - batch_loss: 1.0570, loss: 1.0691 ||:  83%|########3 | 54/65 [01:33<00:18,  1.71s/it]
2022-03-31 10:56:54,319 - INFO - tqdm - batch_loss: 1.1677, loss: 1.0720 ||:  92%|#########2| 60/65 [01:44<00:08,  1.76s/it]
2022-03-31 10:57:02,208 - INFO - tqdm - batch_loss: 1.3208, loss: 1.0740 ||: 100%|##########| 65/65 [01:51<00:00,  1.49s/it]
2022-03-31 10:57:02,208 - INFO - tqdm - batch_loss: 1.3208, loss: 1.0740 ||: 100%|##########| 65/65 [01:51<00:00,  1.72s/it]
2022-03-31 10:57:04,805 - INFO - allennlp.training.trainer - Validating
2022-03-31 10:57:04,807 - INFO - tqdm - 0%|          | 0/115 [00:00<?, ?it/s]
2022-03-31 10:57:15,487 - INFO - tqdm - bleu_BLEU: 0.1722, rouge_ROUGE-1_R: 0.4762, rouge_ROUGE-2_R: 0.2871, rouge_ROUGE-1_P: 0.6080, rouge_ROUGE-2_P: 0.3662, rouge_ROUGE-1_F1: 0.5238, rouge_ROUGE-2_F1: 0.3161, rouge_ROUGE-L: 0.4469, SARI: 0.4939, count: 22.0000, batch_loss: 1.9323, loss: 1.4129 ||:  10%|9         | 11/115 [00:10<01:40,  1.03it/s]
2022-03-31 10:57:25,730 - INFO - tqdm - bleu_BLEU: 0.2020, rouge_ROUGE-1_R: 0.4950, rouge_ROUGE-2_R: 0.3104, rouge_ROUGE-1_P: 0.6106, rouge_ROUGE-2_P: 0.3840, rouge_ROUGE-1_F1: 0.5398, rouge_ROUGE-2_F1: 0.3391, rouge_ROUGE-L: 0.4620, SARI: 0.5304, count: 44.0000, batch_loss: 1.7559, loss: 1.3013 ||:  19%|#9        | 22/115 [00:20<01:30,  1.03it/s]
2022-03-31 10:57:36,199 - INFO - tqdm - bleu_BLEU: 0.2239, rouge_ROUGE-1_R: 0.5090, rouge_ROUGE-2_R: 0.3318, rouge_ROUGE-1_P: 0.6270, rouge_ROUGE-2_P: 0.4096, rouge_ROUGE-1_F1: 0.5537, rouge_ROUGE-2_F1: 0.3613, rouge_ROUGE-L: 0.4789, SARI: 0.5375, count: 64.0000, batch_loss: 1.5421, loss: 1.2969 ||:  28%|##7       | 32/115 [00:31<01:32,  1.11s/it]
2022-03-31 10:57:46,491 - INFO - tqdm - bleu_BLEU: 0.2110, rouge_ROUGE-1_R: 0.4918, rouge_ROUGE-2_R: 0.3185, rouge_ROUGE-1_P: 0.6337, rouge_ROUGE-2_P: 0.4105, rouge_ROUGE-1_F1: 0.5450, rouge_ROUGE-2_F1: 0.3530, rouge_ROUGE-L: 0.4741, SARI: 0.5337, count: 86.0000, batch_loss: 2.0595, loss: 1.3368 ||:  37%|###7      | 43/115 [00:41<01:09,  1.04it/s]
2022-03-31 10:57:56,494 - INFO - tqdm - bleu_BLEU: 0.2154, rouge_ROUGE-1_R: 0.4993, rouge_ROUGE-2_R: 0.3234, rouge_ROUGE-1_P: 0.6362, rouge_ROUGE-2_P: 0.4128, rouge_ROUGE-1_F1: 0.5494, rouge_ROUGE-2_F1: 0.3558, rouge_ROUGE-L: 0.4733, SARI: 0.5386, count: 106.0000, batch_loss: 1.0330, loss: 1.3498 ||:  46%|####6     | 53/115 [00:51<01:01,  1.00it/s]
2022-03-31 10:58:06,679 - INFO - tqdm - bleu_BLEU: 0.2210, rouge_ROUGE-1_R: 0.5026, rouge_ROUGE-2_R: 0.3276, rouge_ROUGE-1_P: 0.6426, rouge_ROUGE-2_P: 0.4210, rouge_ROUGE-1_F1: 0.5539, rouge_ROUGE-2_F1: 0.3617, rouge_ROUGE-L: 0.4777, SARI: 0.5427, count: 128.0000, batch_loss: 2.0950, loss: 1.3608 ||:  56%|#####5    | 64/115 [01:01<00:49,  1.04it/s]
2022-03-31 10:58:17,315 - INFO - tqdm - bleu_BLEU: 0.2308, rouge_ROUGE-1_R: 0.5084, rouge_ROUGE-2_R: 0.3340, rouge_ROUGE-1_P: 0.6429, rouge_ROUGE-2_P: 0.4253, rouge_ROUGE-1_F1: 0.5573, rouge_ROUGE-2_F1: 0.3672, rouge_ROUGE-L: 0.4829, SARI: 0.5507, count: 150.0000, batch_loss: 1.4950, loss: 1.3749 ||:  65%|######5   | 75/115 [01:12<00:40,  1.00s/it]
2022-03-31 10:58:28,278 - INFO - tqdm - bleu_BLEU: 0.2307, rouge_ROUGE-1_R: 0.5096, rouge_ROUGE-2_R: 0.3349, rouge_ROUGE-1_P: 0.6431, rouge_ROUGE-2_P: 0.4252, rouge_ROUGE-1_F1: 0.5587, rouge_ROUGE-2_F1: 0.3680, rouge_ROUGE-L: 0.4807, SARI: 0.5545, count: 172.0000, batch_loss: 1.5093, loss: 1.3780 ||:  75%|#######4  | 86/115 [01:23<00:33,  1.15s/it]
2022-03-31 10:58:38,323 - INFO - tqdm - bleu_BLEU: 0.2339, rouge_ROUGE-1_R: 0.5156, rouge_ROUGE-2_R: 0.3366, rouge_ROUGE-1_P: 0.6398, rouge_ROUGE-2_P: 0.4206, rouge_ROUGE-1_F1: 0.5600, rouge_ROUGE-2_F1: 0.3666, rouge_ROUGE-L: 0.4815, SARI: 0.5577, count: 194.0000, batch_loss: 0.9862, loss: 1.3943 ||:  84%|########4 | 97/115 [01:33<00:16,  1.10it/s]
2022-03-31 10:58:48,361 - INFO - tqdm - bleu_BLEU: 0.2342, rouge_ROUGE-1_R: 0.5185, rouge_ROUGE-2_R: 0.3383, rouge_ROUGE-1_P: 0.6362, rouge_ROUGE-2_P: 0.4176, rouge_ROUGE-1_F1: 0.5603, rouge_ROUGE-2_F1: 0.3665, rouge_ROUGE-L: 0.4808, SARI: 0.5571, count: 214.0000, batch_loss: 1.1235, loss: 1.4117 ||:  93%|#########3| 107/115 [01:43<00:08,  1.07s/it]
2022-03-31 10:58:56,639 - INFO - tqdm - bleu_BLEU: 0.2300, rouge_ROUGE-1_R: 0.5154, rouge_ROUGE-2_R: 0.3353, rouge_ROUGE-1_P: 0.6357, rouge_ROUGE-2_P: 0.4161, rouge_ROUGE-1_F1: 0.5582, rouge_ROUGE-2_F1: 0.3640, rouge_ROUGE-L: 0.4769, SARI: 0.5556, count: 229.0000, batch_loss: 2.0272, loss: 1.4065 ||: 100%|##########| 115/115 [01:51<00:00,  1.04s/it]
2022-03-31 10:58:56,639 - INFO - tqdm - bleu_BLEU: 0.2300, rouge_ROUGE-1_R: 0.5154, rouge_ROUGE-2_R: 0.3353, rouge_ROUGE-1_P: 0.6357, rouge_ROUGE-2_P: 0.4161, rouge_ROUGE-1_F1: 0.5582, rouge_ROUGE-2_F1: 0.3640, rouge_ROUGE-L: 0.4769, SARI: 0.5556, count: 229.0000, batch_loss: 2.0272, loss: 1.4065 ||: 100%|##########| 115/115 [01:51<00:00,  1.03it/s]
2022-03-31 10:58:56,640 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2022-03-31 10:58:56,640 - INFO - allennlp.training.tensorboard_writer - SARI               |       N/A  |     0.556
2022-03-31 10:58:56,640 - INFO - allennlp.training.tensorboard_writer - bleu_BLEU          |       N/A  |     0.230
2022-03-31 10:58:56,641 - INFO - allennlp.training.tensorboard_writer - count              |       N/A  |   229.000
2022-03-31 10:58:56,641 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |  6843.718  |       N/A
2022-03-31 10:58:56,641 - INFO - allennlp.training.tensorboard_writer - loss               |     1.074  |     1.406
2022-03-31 10:58:56,642 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_F1   |       N/A  |     0.558
2022-03-31 10:58:56,642 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_P    |       N/A  |     0.636
2022-03-31 10:58:56,643 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_R    |       N/A  |     0.515
2022-03-31 10:58:56,643 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_F1   |       N/A  |     0.364
2022-03-31 10:58:56,643 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_P    |       N/A  |     0.416
2022-03-31 10:58:56,644 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_R    |       N/A  |     0.335
2022-03-31 10:58:56,644 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-L      |       N/A  |     0.477
2022-03-31 10:58:56,644 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5241.066  |       N/A
2022-03-31 10:58:57,152 - CRITICAL - root - Uncaught exception
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/torch/serialization.py", line 372, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol)
  File "/opt/conda/lib/python3.7/site-packages/torch/serialization.py", line 493, in _save
    zip_file.write_record(name, buf_value, len(buf_value))
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "run_scripts/train.py", line 100, in <module>
    main()
  File "run_scripts/train.py", line 96, in main
    return run(args)
  File "run_scripts/train.py", line 69, in run
    run_main()
  File "/home/jupyter/src/strategyqa/run_scripts/run.py", line 53, in main
    run(args)
  File "/home/jupyter/src/strategyqa/run_scripts/run.py", line 45, in run
    allennlp_main()
  File "/opt/conda/lib/python3.7/site-packages/allennlp/commands/__init__.py", line 118, in main
    args.func(args)
  File "/opt/conda/lib/python3.7/site-packages/allennlp/commands/train.py", line 119, in train_model_from_args
    file_friendly_logging=args.file_friendly_logging,
  File "/opt/conda/lib/python3.7/site-packages/allennlp/commands/train.py", line 178, in train_model_from_file
    file_friendly_logging=file_friendly_logging,
  File "/opt/conda/lib/python3.7/site-packages/allennlp/commands/train.py", line 242, in train_model
    file_friendly_logging=file_friendly_logging,
  File "/opt/conda/lib/python3.7/site-packages/allennlp/commands/train.py", line 466, in _train_worker
    metrics = train_loop.run()
  File "/opt/conda/lib/python3.7/site-packages/allennlp/commands/train.py", line 528, in run
    return self.trainer.train()
  File "/opt/conda/lib/python3.7/site-packages/allennlp/training/trainer.py", line 966, in train
    return self._try_train()
  File "/opt/conda/lib/python3.7/site-packages/allennlp/training/trainer.py", line 1088, in _try_train
    epoch, self, is_best_so_far=self._metric_tracker.is_best_so_far()
  File "/opt/conda/lib/python3.7/site-packages/allennlp/training/checkpointer.py", line 110, in save_checkpoint
    torch.save({**training_states, "epoch": epoch}, training_path)
  File "/opt/conda/lib/python3.7/site-packages/torch/serialization.py", line 373, in save
    return
  File "/opt/conda/lib/python3.7/site-packages/torch/serialization.py", line 259, in __exit__
    self.file_like.write_end_of_file()
RuntimeError: [enforce fail at inline_container.cc:274] . unexpected pos 302594368 vs 302594256
2022-03-31 11:14:17,637 - INFO - allennlp.common.params - random_seed = 42
2022-03-31 11:14:17,637 - INFO - allennlp.common.params - numpy_seed = 42
2022-03-31 11:14:17,637 - INFO - allennlp.common.params - pytorch_seed = 42
2022-03-31 11:14:18,305 - INFO - allennlp.common.checks - Pytorch version: 1.7.1
2022-03-31 11:14:18,306 - INFO - allennlp.common.params - type = default
2022-03-31 11:14:18,306 - INFO - allennlp.common.params - dataset_reader.type = strategy_decomposition_reader
2022-03-31 11:14:18,306 - INFO - allennlp.common.params - dataset_reader.lazy = False
2022-03-31 11:14:18,306 - INFO - allennlp.common.params - dataset_reader.cache_directory = None
2022-03-31 11:14:18,306 - INFO - allennlp.common.params - dataset_reader.max_instances = None
2022-03-31 11:14:18,306 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False
2022-03-31 11:14:18,307 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False
2022-03-31 11:14:18,307 - INFO - allennlp.common.params - dataset_reader.tokenizer_wrapper.type = default
2022-03-31 11:14:18,307 - INFO - allennlp.common.params - dataset_reader.tokenizer_wrapper.pretrained_model = facebook/bart-large
2022-03-31 11:14:18,307 - INFO - allennlp.common.params - dataset_reader.tokenizer_wrapper.init_kwargs.add_prefix_space = True
2022-03-31 11:14:18,391 - INFO - allennlp.common.params - dataset_reader.save_tokenizer = True
2022-03-31 11:14:18,392 - INFO - allennlp.common.params - dataset_reader.is_training = True
2022-03-31 11:14:18,392 - INFO - allennlp.common.params - dataset_reader.pickle.action = None
2022-03-31 11:14:18,392 - INFO - allennlp.common.params - train_data_path = data/strategyqa/train.json
2022-03-31 11:14:18,392 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7f6911396c50>
2022-03-31 11:14:18,392 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2022-03-31 11:14:18,392 - INFO - allennlp.common.params - validation_dataset_reader.type = strategy_decomposition_reader
2022-03-31 11:14:18,393 - INFO - allennlp.common.params - validation_dataset_reader.lazy = False
2022-03-31 11:14:18,393 - INFO - allennlp.common.params - validation_dataset_reader.cache_directory = None
2022-03-31 11:14:18,393 - INFO - allennlp.common.params - validation_dataset_reader.max_instances = None
2022-03-31 11:14:18,393 - INFO - allennlp.common.params - validation_dataset_reader.manual_distributed_sharding = False
2022-03-31 11:14:18,393 - INFO - allennlp.common.params - validation_dataset_reader.manual_multi_process_sharding = False
2022-03-31 11:14:18,393 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer_wrapper.type = default
2022-03-31 11:14:18,393 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer_wrapper.pretrained_model = facebook/bart-large
2022-03-31 11:14:18,393 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer_wrapper.init_kwargs.add_prefix_space = True
2022-03-31 11:14:18,467 - INFO - allennlp.common.params - validation_dataset_reader.save_tokenizer = False
2022-03-31 11:14:18,467 - INFO - allennlp.common.params - validation_dataset_reader.is_training = False
2022-03-31 11:14:18,467 - INFO - allennlp.common.params - validation_dataset_reader.pickle.action = None
2022-03-31 11:14:18,467 - INFO - allennlp.common.params - validation_data_path = data/strategyqa/dev.json
2022-03-31 11:14:18,467 - INFO - allennlp.common.params - validation_data_loader = None
2022-03-31 11:14:18,467 - INFO - allennlp.common.params - test_data_path = None
2022-03-31 11:14:18,467 - INFO - allennlp.common.params - evaluate_on_test = False
2022-03-31 11:14:18,467 - INFO - allennlp.common.params - batch_weight_key = 
2022-03-31 11:14:18,467 - INFO - allennlp.training.util - Reading training data from data/strategyqa/train.json
2022-03-31 11:14:18,468 - INFO - tqdm - reading instances: 0it [00:00, ?it/s]
2022-03-31 11:14:18,468 - INFO - src.data.dataset_readers.base.base_dataset_reader - Reading the dataset from scratch
2022-03-31 11:14:18,468 - INFO - src.data.dataset_readers.strategy_decomposition_reader - Reading the dataset:
2022-03-31 11:14:18,468 - INFO - src.data.dataset_readers.strategy_decomposition_reader - Reading file at data/strategyqa/train.json
2022-03-31 11:14:19,873 - INFO - allennlp.training.util - Reading validation data from data/strategyqa/dev.json
2022-03-31 11:14:19,874 - INFO - tqdm - reading instances: 0it [00:00, ?it/s]
2022-03-31 11:14:19,874 - INFO - src.data.dataset_readers.base.base_dataset_reader - Reading the dataset from scratch
2022-03-31 11:14:19,874 - INFO - src.data.dataset_readers.strategy_decomposition_reader - Reading the dataset:
2022-03-31 11:14:19,874 - INFO - src.data.dataset_readers.strategy_decomposition_reader - Reading file at data/strategyqa/dev.json
2022-03-31 11:14:20,024 - INFO - allennlp.common.params - type = from_instances
2022-03-31 11:14:20,024 - INFO - allennlp.common.params - min_count = None
2022-03-31 11:14:20,024 - INFO - allennlp.common.params - max_vocab_size = None
2022-03-31 11:14:20,024 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2022-03-31 11:14:20,025 - INFO - allennlp.common.params - pretrained_files = None
2022-03-31 11:14:20,025 - INFO - allennlp.common.params - only_include_pretrained_words = False
2022-03-31 11:14:20,025 - INFO - allennlp.common.params - tokens_to_add = None
2022-03-31 11:14:20,025 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2022-03-31 11:14:20,025 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2022-03-31 11:14:20,025 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2022-03-31 11:14:20,025 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2022-03-31 11:14:20,025 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2022-03-31 11:14:20,029 - INFO - allennlp.common.params - model.type = gen
2022-03-31 11:14:20,030 - INFO - allennlp.common.params - model.regularizer = None
2022-03-31 11:14:20,030 - INFO - allennlp.common.params - model.pretrained_model = facebook/bart-large
2022-03-31 11:14:20,030 - INFO - allennlp.common.params - model.tokenizer_wrapper.type = default
2022-03-31 11:14:20,030 - INFO - allennlp.common.params - model.tokenizer_wrapper.pretrained_model = facebook/bart-large
2022-03-31 11:14:20,030 - INFO - allennlp.common.params - model.tokenizer_wrapper.init_kwargs.add_prefix_space = True
2022-03-31 11:14:20,105 - INFO - allennlp.common.params - model.generate_while_training = False
2022-03-31 11:14:20,105 - INFO - allennlp.common.params - model.repetition_penalty = 2.5
2022-03-31 11:14:20,106 - INFO - allennlp.common.params - model.metrics.bleu.type = bleu
2022-03-31 11:14:20,106 - INFO - allennlp.common.params - model.metrics.bleu.ngram_weights = (0.25, 0.25, 0.25, 0.25)
2022-03-31 11:14:20,106 - INFO - allennlp.common.params - model.metrics.bleu.exclude_indices = None
2022-03-31 11:14:20,106 - INFO - allennlp.common.params - model.metrics.rouge.type = rouge
2022-03-31 11:14:20,106 - INFO - allennlp.common.params - model.metrics.rouge.ngram_size = 2
2022-03-31 11:14:20,106 - INFO - allennlp.common.params - model.metrics.rouge.exclude_indices = None
2022-03-31 11:14:20,106 - INFO - allennlp.common.params - model.metrics.sari.type = sari
2022-03-31 11:14:20,106 - INFO - allennlp.common.params - model.metrics.sari.is_main = True
2022-03-31 11:14:20,107 - INFO - allennlp.common.params - model.is_dummy = False
2022-03-31 11:14:20,107 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f690674ad90>
2022-03-31 11:14:36,212 - INFO - allennlp.nn.initializers - Initializing parameters
2022-03-31 11:14:36,215 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-03-31 11:14:36,215 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.embed_positions.weight
2022-03-31 11:14:36,215 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layernorm_embedding.bias
2022-03-31 11:14:36,215 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layernorm_embedding.weight
2022-03-31 11:14:36,215 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.k_proj.bias
2022-03-31 11:14:36,215 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.k_proj.weight
2022-03-31 11:14:36,215 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.out_proj.bias
2022-03-31 11:14:36,215 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.out_proj.weight
2022-03-31 11:14:36,215 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.q_proj.bias
2022-03-31 11:14:36,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.q_proj.weight
2022-03-31 11:14:36,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.v_proj.bias
2022-03-31 11:14:36,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.v_proj.weight
2022-03-31 11:14:36,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn_layer_norm.bias
2022-03-31 11:14:36,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn_layer_norm.weight
2022-03-31 11:14:36,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.fc1.bias
2022-03-31 11:14:36,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.fc1.weight
2022-03-31 11:14:36,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.fc2.bias
2022-03-31 11:14:36,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.fc2.weight
2022-03-31 11:14:36,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.final_layer_norm.bias
2022-03-31 11:14:36,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.final_layer_norm.weight
2022-03-31 11:14:36,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.k_proj.bias
2022-03-31 11:14:36,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.k_proj.weight
2022-03-31 11:14:36,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.out_proj.bias
2022-03-31 11:14:36,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.out_proj.weight
2022-03-31 11:14:36,216 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.q_proj.bias
2022-03-31 11:14:36,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.q_proj.weight
2022-03-31 11:14:36,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.v_proj.bias
2022-03-31 11:14:36,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.v_proj.weight
2022-03-31 11:14:36,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn_layer_norm.bias
2022-03-31 11:14:36,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn_layer_norm.weight
2022-03-31 11:14:36,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.k_proj.bias
2022-03-31 11:14:36,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.k_proj.weight
2022-03-31 11:14:36,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.out_proj.bias
2022-03-31 11:14:36,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.out_proj.weight
2022-03-31 11:14:36,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.q_proj.bias
2022-03-31 11:14:36,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.q_proj.weight
2022-03-31 11:14:36,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.v_proj.bias
2022-03-31 11:14:36,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.v_proj.weight
2022-03-31 11:14:36,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn_layer_norm.bias
2022-03-31 11:14:36,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn_layer_norm.weight
2022-03-31 11:14:36,217 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.fc1.bias
2022-03-31 11:14:36,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.fc1.weight
2022-03-31 11:14:36,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.fc2.bias
2022-03-31 11:14:36,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.fc2.weight
2022-03-31 11:14:36,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.final_layer_norm.bias
2022-03-31 11:14:36,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.final_layer_norm.weight
2022-03-31 11:14:36,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.k_proj.bias
2022-03-31 11:14:36,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.k_proj.weight
2022-03-31 11:14:36,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.out_proj.bias
2022-03-31 11:14:36,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.out_proj.weight
2022-03-31 11:14:36,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.q_proj.bias
2022-03-31 11:14:36,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.q_proj.weight
2022-03-31 11:14:36,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.v_proj.bias
2022-03-31 11:14:36,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.v_proj.weight
2022-03-31 11:14:36,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn_layer_norm.bias
2022-03-31 11:14:36,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn_layer_norm.weight
2022-03-31 11:14:36,218 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.k_proj.bias
2022-03-31 11:14:36,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.k_proj.weight
2022-03-31 11:14:36,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.out_proj.bias
2022-03-31 11:14:36,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.out_proj.weight
2022-03-31 11:14:36,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.q_proj.bias
2022-03-31 11:14:36,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.q_proj.weight
2022-03-31 11:14:36,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.v_proj.bias
2022-03-31 11:14:36,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.v_proj.weight
2022-03-31 11:14:36,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn_layer_norm.bias
2022-03-31 11:14:36,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn_layer_norm.weight
2022-03-31 11:14:36,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.fc1.bias
2022-03-31 11:14:36,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.fc1.weight
2022-03-31 11:14:36,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.fc2.bias
2022-03-31 11:14:36,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.fc2.weight
2022-03-31 11:14:36,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.final_layer_norm.bias
2022-03-31 11:14:36,219 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.final_layer_norm.weight
2022-03-31 11:14:36,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.k_proj.bias
2022-03-31 11:14:36,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.k_proj.weight
2022-03-31 11:14:36,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.out_proj.bias
2022-03-31 11:14:36,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.out_proj.weight
2022-03-31 11:14:36,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.q_proj.bias
2022-03-31 11:14:36,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.q_proj.weight
2022-03-31 11:14:36,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.v_proj.bias
2022-03-31 11:14:36,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.v_proj.weight
2022-03-31 11:14:36,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn_layer_norm.bias
2022-03-31 11:14:36,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn_layer_norm.weight
2022-03-31 11:14:36,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.k_proj.bias
2022-03-31 11:14:36,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.k_proj.weight
2022-03-31 11:14:36,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.out_proj.bias
2022-03-31 11:14:36,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.out_proj.weight
2022-03-31 11:14:36,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.q_proj.bias
2022-03-31 11:14:36,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.q_proj.weight
2022-03-31 11:14:36,220 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.v_proj.bias
2022-03-31 11:14:36,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.v_proj.weight
2022-03-31 11:14:36,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn_layer_norm.bias
2022-03-31 11:14:36,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn_layer_norm.weight
2022-03-31 11:14:36,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.fc1.bias
2022-03-31 11:14:36,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.fc1.weight
2022-03-31 11:14:36,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.fc2.bias
2022-03-31 11:14:36,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.fc2.weight
2022-03-31 11:14:36,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.final_layer_norm.bias
2022-03-31 11:14:36,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.final_layer_norm.weight
2022-03-31 11:14:36,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.k_proj.bias
2022-03-31 11:14:36,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.k_proj.weight
2022-03-31 11:14:36,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.out_proj.bias
2022-03-31 11:14:36,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.out_proj.weight
2022-03-31 11:14:36,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.q_proj.bias
2022-03-31 11:14:36,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.q_proj.weight
2022-03-31 11:14:36,221 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.v_proj.bias
2022-03-31 11:14:36,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.v_proj.weight
2022-03-31 11:14:36,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn_layer_norm.bias
2022-03-31 11:14:36,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn_layer_norm.weight
2022-03-31 11:14:36,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.k_proj.bias
2022-03-31 11:14:36,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.k_proj.weight
2022-03-31 11:14:36,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.out_proj.bias
2022-03-31 11:14:36,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.out_proj.weight
2022-03-31 11:14:36,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.q_proj.bias
2022-03-31 11:14:36,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.q_proj.weight
2022-03-31 11:14:36,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.v_proj.bias
2022-03-31 11:14:36,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.v_proj.weight
2022-03-31 11:14:36,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn_layer_norm.bias
2022-03-31 11:14:36,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn_layer_norm.weight
2022-03-31 11:14:36,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.fc1.bias
2022-03-31 11:14:36,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.fc1.weight
2022-03-31 11:14:36,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.fc2.bias
2022-03-31 11:14:36,222 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.fc2.weight
2022-03-31 11:14:36,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.final_layer_norm.bias
2022-03-31 11:14:36,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.final_layer_norm.weight
2022-03-31 11:14:36,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.k_proj.bias
2022-03-31 11:14:36,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.k_proj.weight
2022-03-31 11:14:36,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.out_proj.bias
2022-03-31 11:14:36,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.out_proj.weight
2022-03-31 11:14:36,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.q_proj.bias
2022-03-31 11:14:36,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.q_proj.weight
2022-03-31 11:14:36,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.v_proj.bias
2022-03-31 11:14:36,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.v_proj.weight
2022-03-31 11:14:36,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn_layer_norm.bias
2022-03-31 11:14:36,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn_layer_norm.weight
2022-03-31 11:14:36,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.k_proj.bias
2022-03-31 11:14:36,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.k_proj.weight
2022-03-31 11:14:36,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.out_proj.bias
2022-03-31 11:14:36,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.out_proj.weight
2022-03-31 11:14:36,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.q_proj.bias
2022-03-31 11:14:36,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.q_proj.weight
2022-03-31 11:14:36,223 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.v_proj.bias
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.v_proj.weight
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn_layer_norm.bias
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn_layer_norm.weight
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.fc1.bias
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.fc1.weight
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.fc2.bias
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.fc2.weight
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.final_layer_norm.bias
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.final_layer_norm.weight
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.k_proj.bias
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.k_proj.weight
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.out_proj.bias
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.out_proj.weight
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.q_proj.bias
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.q_proj.weight
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.v_proj.bias
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.v_proj.weight
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn_layer_norm.bias
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn_layer_norm.weight
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.k_proj.bias
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.k_proj.weight
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.out_proj.bias
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.out_proj.weight
2022-03-31 11:14:36,224 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.q_proj.bias
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.q_proj.weight
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.v_proj.bias
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.v_proj.weight
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn_layer_norm.bias
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn_layer_norm.weight
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.fc1.bias
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.fc1.weight
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.fc2.bias
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.fc2.weight
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.final_layer_norm.bias
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.final_layer_norm.weight
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.k_proj.bias
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.k_proj.weight
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.out_proj.bias
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.out_proj.weight
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.q_proj.bias
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.q_proj.weight
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.v_proj.bias
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.v_proj.weight
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn_layer_norm.bias
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn_layer_norm.weight
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.k_proj.bias
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.k_proj.weight
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.out_proj.bias
2022-03-31 11:14:36,225 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.out_proj.weight
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.q_proj.bias
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.q_proj.weight
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.v_proj.bias
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.v_proj.weight
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn_layer_norm.bias
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn_layer_norm.weight
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.fc1.bias
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.fc1.weight
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.fc2.bias
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.fc2.weight
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.final_layer_norm.bias
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.final_layer_norm.weight
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.k_proj.bias
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.k_proj.weight
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.out_proj.bias
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.out_proj.weight
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.q_proj.bias
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.q_proj.weight
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.v_proj.bias
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.v_proj.weight
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn_layer_norm.bias
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn_layer_norm.weight
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.k_proj.bias
2022-03-31 11:14:36,226 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.k_proj.weight
2022-03-31 11:14:36,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.out_proj.bias
2022-03-31 11:14:36,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.out_proj.weight
2022-03-31 11:14:36,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.q_proj.bias
2022-03-31 11:14:36,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.q_proj.weight
2022-03-31 11:14:36,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.v_proj.bias
2022-03-31 11:14:36,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.v_proj.weight
2022-03-31 11:14:36,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn_layer_norm.bias
2022-03-31 11:14:36,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn_layer_norm.weight
2022-03-31 11:14:36,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.fc1.bias
2022-03-31 11:14:36,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.fc1.weight
2022-03-31 11:14:36,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.fc2.bias
2022-03-31 11:14:36,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.fc2.weight
2022-03-31 11:14:36,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.final_layer_norm.bias
2022-03-31 11:14:36,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.final_layer_norm.weight
2022-03-31 11:14:36,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.k_proj.bias
2022-03-31 11:14:36,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.k_proj.weight
2022-03-31 11:14:36,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.out_proj.bias
2022-03-31 11:14:36,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.out_proj.weight
2022-03-31 11:14:36,227 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.q_proj.bias
2022-03-31 11:14:36,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.q_proj.weight
2022-03-31 11:14:36,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.v_proj.bias
2022-03-31 11:14:36,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.v_proj.weight
2022-03-31 11:14:36,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn_layer_norm.bias
2022-03-31 11:14:36,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn_layer_norm.weight
2022-03-31 11:14:36,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.k_proj.bias
2022-03-31 11:14:36,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.k_proj.weight
2022-03-31 11:14:36,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.out_proj.bias
2022-03-31 11:14:36,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.out_proj.weight
2022-03-31 11:14:36,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.q_proj.bias
2022-03-31 11:14:36,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.q_proj.weight
2022-03-31 11:14:36,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.v_proj.bias
2022-03-31 11:14:36,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.v_proj.weight
2022-03-31 11:14:36,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn_layer_norm.bias
2022-03-31 11:14:36,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn_layer_norm.weight
2022-03-31 11:14:36,228 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.fc1.bias
2022-03-31 11:14:36,229 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.fc1.weight
2022-03-31 11:14:36,229 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.fc2.bias
2022-03-31 11:14:36,229 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.fc2.weight
2022-03-31 11:14:36,229 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.final_layer_norm.bias
2022-03-31 11:14:36,229 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.final_layer_norm.weight
2022-03-31 11:14:36,229 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.k_proj.bias
2022-03-31 11:14:36,229 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.k_proj.weight
2022-03-31 11:14:36,229 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.out_proj.bias
2022-03-31 11:14:36,229 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.out_proj.weight
2022-03-31 11:14:36,229 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.q_proj.bias
2022-03-31 11:14:36,229 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.q_proj.weight
2022-03-31 11:14:36,229 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.v_proj.bias
2022-03-31 11:14:36,229 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.v_proj.weight
2022-03-31 11:14:36,229 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn_layer_norm.bias
2022-03-31 11:14:36,229 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn_layer_norm.weight
2022-03-31 11:14:36,229 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.k_proj.bias
2022-03-31 11:14:36,229 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.k_proj.weight
2022-03-31 11:14:36,230 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.out_proj.bias
2022-03-31 11:14:36,230 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.out_proj.weight
2022-03-31 11:14:36,230 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.q_proj.bias
2022-03-31 11:14:36,230 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.q_proj.weight
2022-03-31 11:14:36,230 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.v_proj.bias
2022-03-31 11:14:36,230 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.v_proj.weight
2022-03-31 11:14:36,230 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn_layer_norm.bias
2022-03-31 11:14:36,230 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn_layer_norm.weight
2022-03-31 11:14:36,230 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.fc1.bias
2022-03-31 11:14:36,230 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.fc1.weight
2022-03-31 11:14:36,230 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.fc2.bias
2022-03-31 11:14:36,230 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.fc2.weight
2022-03-31 11:14:36,230 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.final_layer_norm.bias
2022-03-31 11:14:36,230 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.final_layer_norm.weight
2022-03-31 11:14:36,230 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.k_proj.bias
2022-03-31 11:14:36,230 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.k_proj.weight
2022-03-31 11:14:36,231 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.out_proj.bias
2022-03-31 11:14:36,231 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.out_proj.weight
2022-03-31 11:14:36,231 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.q_proj.bias
2022-03-31 11:14:36,231 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.q_proj.weight
2022-03-31 11:14:36,231 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.v_proj.bias
2022-03-31 11:14:36,231 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.v_proj.weight
2022-03-31 11:14:36,231 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn_layer_norm.bias
2022-03-31 11:14:36,231 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn_layer_norm.weight
2022-03-31 11:14:36,231 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.k_proj.bias
2022-03-31 11:14:36,231 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.k_proj.weight
2022-03-31 11:14:36,231 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.out_proj.bias
2022-03-31 11:14:36,231 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.out_proj.weight
2022-03-31 11:14:36,231 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.q_proj.bias
2022-03-31 11:14:36,231 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.q_proj.weight
2022-03-31 11:14:36,231 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.v_proj.bias
2022-03-31 11:14:36,231 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.v_proj.weight
2022-03-31 11:14:36,231 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn_layer_norm.bias
2022-03-31 11:14:36,232 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn_layer_norm.weight
2022-03-31 11:14:36,232 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.fc1.bias
2022-03-31 11:14:36,232 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.fc1.weight
2022-03-31 11:14:36,232 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.fc2.bias
2022-03-31 11:14:36,232 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.fc2.weight
2022-03-31 11:14:36,232 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.final_layer_norm.bias
2022-03-31 11:14:36,232 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.final_layer_norm.weight
2022-03-31 11:14:36,232 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.k_proj.bias
2022-03-31 11:14:36,232 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.k_proj.weight
2022-03-31 11:14:36,232 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.out_proj.bias
2022-03-31 11:14:36,232 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.out_proj.weight
2022-03-31 11:14:36,232 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.q_proj.bias
2022-03-31 11:14:36,232 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.q_proj.weight
2022-03-31 11:14:36,232 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.v_proj.bias
2022-03-31 11:14:36,232 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.v_proj.weight
2022-03-31 11:14:36,233 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn_layer_norm.bias
2022-03-31 11:14:36,233 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn_layer_norm.weight
2022-03-31 11:14:36,233 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.embed_positions.weight
2022-03-31 11:14:36,233 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layernorm_embedding.bias
2022-03-31 11:14:36,233 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layernorm_embedding.weight
2022-03-31 11:14:36,233 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.fc1.bias
2022-03-31 11:14:36,233 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.fc1.weight
2022-03-31 11:14:36,233 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.fc2.bias
2022-03-31 11:14:36,233 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.fc2.weight
2022-03-31 11:14:36,233 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.final_layer_norm.bias
2022-03-31 11:14:36,233 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.final_layer_norm.weight
2022-03-31 11:14:36,233 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.k_proj.bias
2022-03-31 11:14:36,233 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.k_proj.weight
2022-03-31 11:14:36,233 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.out_proj.bias
2022-03-31 11:14:36,233 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.out_proj.weight
2022-03-31 11:14:36,233 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.q_proj.bias
2022-03-31 11:14:36,234 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.q_proj.weight
2022-03-31 11:14:36,234 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.v_proj.bias
2022-03-31 11:14:36,234 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.v_proj.weight
2022-03-31 11:14:36,234 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn_layer_norm.bias
2022-03-31 11:14:36,234 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn_layer_norm.weight
2022-03-31 11:14:36,234 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.fc1.bias
2022-03-31 11:14:36,234 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.fc1.weight
2022-03-31 11:14:36,234 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.fc2.bias
2022-03-31 11:14:36,234 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.fc2.weight
2022-03-31 11:14:36,234 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.final_layer_norm.bias
2022-03-31 11:14:36,234 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.final_layer_norm.weight
2022-03-31 11:14:36,234 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.k_proj.bias
2022-03-31 11:14:36,234 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.k_proj.weight
2022-03-31 11:14:36,234 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.out_proj.bias
2022-03-31 11:14:36,234 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.out_proj.weight
2022-03-31 11:14:36,234 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.q_proj.bias
2022-03-31 11:14:36,235 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.q_proj.weight
2022-03-31 11:14:36,235 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.v_proj.bias
2022-03-31 11:14:36,235 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.v_proj.weight
2022-03-31 11:14:36,235 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn_layer_norm.bias
2022-03-31 11:14:36,235 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn_layer_norm.weight
2022-03-31 11:14:36,235 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.fc1.bias
2022-03-31 11:14:36,235 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.fc1.weight
2022-03-31 11:14:36,235 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.fc2.bias
2022-03-31 11:14:36,235 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.fc2.weight
2022-03-31 11:14:36,235 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.final_layer_norm.bias
2022-03-31 11:14:36,235 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.final_layer_norm.weight
2022-03-31 11:14:36,235 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.k_proj.bias
2022-03-31 11:14:36,235 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.k_proj.weight
2022-03-31 11:14:36,235 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.out_proj.bias
2022-03-31 11:14:36,235 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.out_proj.weight
2022-03-31 11:14:36,235 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.q_proj.bias
2022-03-31 11:14:36,235 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.q_proj.weight
2022-03-31 11:14:36,236 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.v_proj.bias
2022-03-31 11:14:36,236 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.v_proj.weight
2022-03-31 11:14:36,236 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn_layer_norm.bias
2022-03-31 11:14:36,236 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn_layer_norm.weight
2022-03-31 11:14:36,236 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.fc1.bias
2022-03-31 11:14:36,236 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.fc1.weight
2022-03-31 11:14:36,236 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.fc2.bias
2022-03-31 11:14:36,236 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.fc2.weight
2022-03-31 11:14:36,236 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.final_layer_norm.bias
2022-03-31 11:14:36,236 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.final_layer_norm.weight
2022-03-31 11:14:36,236 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.k_proj.bias
2022-03-31 11:14:36,236 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.k_proj.weight
2022-03-31 11:14:36,236 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.out_proj.bias
2022-03-31 11:14:36,236 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.out_proj.weight
2022-03-31 11:14:36,236 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.q_proj.bias
2022-03-31 11:14:36,237 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.q_proj.weight
2022-03-31 11:14:36,237 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.v_proj.bias
2022-03-31 11:14:36,237 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.v_proj.weight
2022-03-31 11:14:36,237 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn_layer_norm.bias
2022-03-31 11:14:36,237 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn_layer_norm.weight
2022-03-31 11:14:36,237 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.fc1.bias
2022-03-31 11:14:36,237 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.fc1.weight
2022-03-31 11:14:36,237 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.fc2.bias
2022-03-31 11:14:36,237 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.fc2.weight
2022-03-31 11:14:36,237 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.final_layer_norm.bias
2022-03-31 11:14:36,237 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.final_layer_norm.weight
2022-03-31 11:14:36,237 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.k_proj.bias
2022-03-31 11:14:36,237 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.k_proj.weight
2022-03-31 11:14:36,237 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.out_proj.bias
2022-03-31 11:14:36,237 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.out_proj.weight
2022-03-31 11:14:36,237 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.q_proj.bias
2022-03-31 11:14:36,238 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.q_proj.weight
2022-03-31 11:14:36,238 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.v_proj.bias
2022-03-31 11:14:36,238 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.v_proj.weight
2022-03-31 11:14:36,238 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn_layer_norm.bias
2022-03-31 11:14:36,238 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn_layer_norm.weight
2022-03-31 11:14:36,238 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.fc1.bias
2022-03-31 11:14:36,238 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.fc1.weight
2022-03-31 11:14:36,238 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.fc2.bias
2022-03-31 11:14:36,238 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.fc2.weight
2022-03-31 11:14:36,238 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.final_layer_norm.bias
2022-03-31 11:14:36,238 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.final_layer_norm.weight
2022-03-31 11:14:36,238 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.k_proj.bias
2022-03-31 11:14:36,238 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.k_proj.weight
2022-03-31 11:14:36,238 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.out_proj.bias
2022-03-31 11:14:36,238 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.out_proj.weight
2022-03-31 11:14:36,238 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.q_proj.bias
2022-03-31 11:14:36,239 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.q_proj.weight
2022-03-31 11:14:36,239 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.v_proj.bias
2022-03-31 11:14:36,239 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.v_proj.weight
2022-03-31 11:14:36,239 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn_layer_norm.bias
2022-03-31 11:14:36,239 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn_layer_norm.weight
2022-03-31 11:14:36,239 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.fc1.bias
2022-03-31 11:14:36,239 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.fc1.weight
2022-03-31 11:14:36,239 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.fc2.bias
2022-03-31 11:14:36,239 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.fc2.weight
2022-03-31 11:14:36,239 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.final_layer_norm.bias
2022-03-31 11:14:36,239 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.final_layer_norm.weight
2022-03-31 11:14:36,239 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.k_proj.bias
2022-03-31 11:14:36,239 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.k_proj.weight
2022-03-31 11:14:36,239 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.out_proj.bias
2022-03-31 11:14:36,239 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.out_proj.weight
2022-03-31 11:14:36,239 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.q_proj.bias
2022-03-31 11:14:36,240 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.q_proj.weight
2022-03-31 11:14:36,240 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.v_proj.bias
2022-03-31 11:14:36,240 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.v_proj.weight
2022-03-31 11:14:36,240 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn_layer_norm.bias
2022-03-31 11:14:36,240 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn_layer_norm.weight
2022-03-31 11:14:36,240 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.fc1.bias
2022-03-31 11:14:36,240 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.fc1.weight
2022-03-31 11:14:36,240 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.fc2.bias
2022-03-31 11:14:36,240 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.fc2.weight
2022-03-31 11:14:36,240 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.final_layer_norm.bias
2022-03-31 11:14:36,240 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.final_layer_norm.weight
2022-03-31 11:14:36,240 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.k_proj.bias
2022-03-31 11:14:36,240 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.k_proj.weight
2022-03-31 11:14:36,240 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.out_proj.bias
2022-03-31 11:14:36,240 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.out_proj.weight
2022-03-31 11:14:36,240 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.q_proj.bias
2022-03-31 11:14:36,240 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.q_proj.weight
2022-03-31 11:14:36,241 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.v_proj.bias
2022-03-31 11:14:36,241 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.v_proj.weight
2022-03-31 11:14:36,241 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn_layer_norm.bias
2022-03-31 11:14:36,241 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn_layer_norm.weight
2022-03-31 11:14:36,241 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.fc1.bias
2022-03-31 11:14:36,241 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.fc1.weight
2022-03-31 11:14:36,241 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.fc2.bias
2022-03-31 11:14:36,241 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.fc2.weight
2022-03-31 11:14:36,241 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.final_layer_norm.bias
2022-03-31 11:14:36,241 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.final_layer_norm.weight
2022-03-31 11:14:36,241 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.k_proj.bias
2022-03-31 11:14:36,241 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.k_proj.weight
2022-03-31 11:14:36,241 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.out_proj.bias
2022-03-31 11:14:36,241 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.out_proj.weight
2022-03-31 11:14:36,241 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.q_proj.bias
2022-03-31 11:14:36,242 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.q_proj.weight
2022-03-31 11:14:36,242 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.v_proj.bias
2022-03-31 11:14:36,242 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.v_proj.weight
2022-03-31 11:14:36,242 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn_layer_norm.bias
2022-03-31 11:14:36,242 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn_layer_norm.weight
2022-03-31 11:14:36,242 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.fc1.bias
2022-03-31 11:14:36,242 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.fc1.weight
2022-03-31 11:14:36,242 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.fc2.bias
2022-03-31 11:14:36,242 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.fc2.weight
2022-03-31 11:14:36,242 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.final_layer_norm.bias
2022-03-31 11:14:36,242 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.final_layer_norm.weight
2022-03-31 11:14:36,242 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.k_proj.bias
2022-03-31 11:14:36,242 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.k_proj.weight
2022-03-31 11:14:36,242 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.out_proj.bias
2022-03-31 11:14:36,242 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.out_proj.weight
2022-03-31 11:14:36,242 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.q_proj.bias
2022-03-31 11:14:36,243 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.q_proj.weight
2022-03-31 11:14:36,243 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.v_proj.bias
2022-03-31 11:14:36,243 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.v_proj.weight
2022-03-31 11:14:36,243 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn_layer_norm.bias
2022-03-31 11:14:36,243 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn_layer_norm.weight
2022-03-31 11:14:36,243 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.fc1.bias
2022-03-31 11:14:36,243 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.fc1.weight
2022-03-31 11:14:36,243 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.fc2.bias
2022-03-31 11:14:36,243 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.fc2.weight
2022-03-31 11:14:36,243 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.final_layer_norm.bias
2022-03-31 11:14:36,243 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.final_layer_norm.weight
2022-03-31 11:14:36,243 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.k_proj.bias
2022-03-31 11:14:36,243 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.k_proj.weight
2022-03-31 11:14:36,243 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.out_proj.bias
2022-03-31 11:14:36,243 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.out_proj.weight
2022-03-31 11:14:36,243 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.q_proj.bias
2022-03-31 11:14:36,244 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.q_proj.weight
2022-03-31 11:14:36,244 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.v_proj.bias
2022-03-31 11:14:36,244 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.v_proj.weight
2022-03-31 11:14:36,244 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn_layer_norm.bias
2022-03-31 11:14:36,244 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn_layer_norm.weight
2022-03-31 11:14:36,244 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.fc1.bias
2022-03-31 11:14:36,244 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.fc1.weight
2022-03-31 11:14:36,244 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.fc2.bias
2022-03-31 11:14:36,244 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.fc2.weight
2022-03-31 11:14:36,244 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.final_layer_norm.bias
2022-03-31 11:14:36,244 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.final_layer_norm.weight
2022-03-31 11:14:36,244 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.k_proj.bias
2022-03-31 11:14:36,244 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.k_proj.weight
2022-03-31 11:14:36,244 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.out_proj.bias
2022-03-31 11:14:36,244 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.out_proj.weight
2022-03-31 11:14:36,245 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.q_proj.bias
2022-03-31 11:14:36,245 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.q_proj.weight
2022-03-31 11:14:36,245 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.v_proj.bias
2022-03-31 11:14:36,245 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.v_proj.weight
2022-03-31 11:14:36,245 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn_layer_norm.bias
2022-03-31 11:14:36,245 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn_layer_norm.weight
2022-03-31 11:14:36,245 - INFO - allennlp.nn.initializers -    _seq2seq.model.shared.weight
2022-03-31 11:14:36,658 - WARNING - allennlp.data.vocabulary - vocabulary serialization directory ./output_decomposition/vocabulary is not empty
2022-03-31 11:14:36,658 - INFO - filelock - Lock 140089237380368 acquired on ./output_decomposition/vocabulary/.lock
2022-03-31 11:14:36,659 - INFO - filelock - Lock 140089237380368 released on ./output_decomposition/vocabulary/.lock
2022-03-31 11:14:36,659 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader
2022-03-31 11:14:36,659 - INFO - allennlp.common.params - data_loader.batch_size = 1
2022-03-31 11:14:36,659 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-31 11:14:36,659 - INFO - allennlp.common.params - data_loader.sampler = None
2022-03-31 11:14:36,660 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-31 11:14:36,660 - INFO - allennlp.common.params - data_loader.pin_memory = False
2022-03-31 11:14:36,660 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-31 11:14:36,660 - INFO - allennlp.common.params - data_loader.timeout = 0
2022-03-31 11:14:36,660 - INFO - allennlp.common.params - data_loader.worker_init_fn = None
2022-03-31 11:14:36,660 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None
2022-03-31 11:14:36,660 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-31 11:14:36,660 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-31 11:14:36,660 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 2
2022-03-31 11:14:36,661 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-31 11:14:36,661 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-31 11:14:36,661 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-31 11:14:36,661 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader
2022-03-31 11:14:36,661 - INFO - allennlp.common.params - data_loader.batch_size = 1
2022-03-31 11:14:36,662 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-31 11:14:36,662 - INFO - allennlp.common.params - data_loader.sampler = None
2022-03-31 11:14:36,662 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-31 11:14:36,662 - INFO - allennlp.common.params - data_loader.pin_memory = False
2022-03-31 11:14:36,662 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-31 11:14:36,662 - INFO - allennlp.common.params - data_loader.timeout = 0
2022-03-31 11:14:36,662 - INFO - allennlp.common.params - data_loader.worker_init_fn = None
2022-03-31 11:14:36,662 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None
2022-03-31 11:14:36,662 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-31 11:14:36,662 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-31 11:14:36,663 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 2
2022-03-31 11:14:36,663 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-31 11:14:36,663 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-31 11:14:36,663 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-31 11:14:36,663 - INFO - allennlp.common.params - trainer.type = gradient_descent
2022-03-31 11:14:36,663 - INFO - allennlp.common.params - trainer.patience = None
2022-03-31 11:14:36,664 - INFO - allennlp.common.params - trainer.validation_metric = +SARI
2022-03-31 11:14:36,664 - INFO - allennlp.common.params - trainer.num_epochs = 15
2022-03-31 11:14:36,664 - INFO - allennlp.common.params - trainer.cuda_device = 0
2022-03-31 11:14:36,664 - INFO - allennlp.common.params - trainer.grad_norm = None
2022-03-31 11:14:36,664 - INFO - allennlp.common.params - trainer.grad_clipping = None
2022-03-31 11:14:36,664 - INFO - allennlp.common.params - trainer.distributed = False
2022-03-31 11:14:36,664 - INFO - allennlp.common.params - trainer.world_size = 1
2022-03-31 11:14:36,664 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 16
2022-03-31 11:14:36,664 - INFO - allennlp.common.params - trainer.use_amp = False
2022-03-31 11:14:36,664 - INFO - allennlp.common.params - trainer.no_grad = None
2022-03-31 11:14:36,665 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2022-03-31 11:14:36,665 - INFO - allennlp.common.params - trainer.tensorboard_writer = <allennlp.common.lazy.Lazy object at 0x7f6906f3bf10>
2022-03-31 11:14:36,665 - INFO - allennlp.common.params - trainer.moving_average = None
2022-03-31 11:14:36,665 - INFO - allennlp.common.params - trainer.batch_callbacks = None
2022-03-31 11:14:36,665 - INFO - allennlp.common.params - trainer.epoch_callbacks = None
2022-03-31 11:14:36,665 - INFO - allennlp.common.params - trainer.end_callbacks = None
2022-03-31 11:14:36,665 - INFO - allennlp.common.params - trainer.trainer_callbacks = None
2022-03-31 11:14:39,637 - INFO - allennlp.common.params - trainer.optimizer.type = huggingface_adamw
2022-03-31 11:14:39,637 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups = None
2022-03-31 11:14:39,637 - INFO - allennlp.common.params - trainer.optimizer.lr = 3e-05
2022-03-31 11:14:39,637 - INFO - allennlp.common.params - trainer.optimizer.betas = [0.9, 0.999]
2022-03-31 11:14:39,637 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08
2022-03-31 11:14:39,637 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.0
2022-03-31 11:14:39,638 - INFO - allennlp.common.params - trainer.optimizer.correct_bias = True
2022-03-31 11:14:39,638 - INFO - allennlp.training.optimizers - Number of trainable parameters: 406291456
2022-03-31 11:14:39,640 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2022-03-31 11:14:39,643 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2022-03-31 11:14:39,644 - INFO - allennlp.common.util - _seq2seq.model.shared.weight
2022-03-31 11:14:39,644 - INFO - allennlp.common.util - _seq2seq.model.encoder.embed_positions.weight
2022-03-31 11:14:39,644 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.k_proj.weight
2022-03-31 11:14:39,644 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.k_proj.bias
2022-03-31 11:14:39,644 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.v_proj.weight
2022-03-31 11:14:39,644 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.v_proj.bias
2022-03-31 11:14:39,644 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.q_proj.weight
2022-03-31 11:14:39,644 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.q_proj.bias
2022-03-31 11:14:39,644 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.out_proj.weight
2022-03-31 11:14:39,644 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.out_proj.bias
2022-03-31 11:14:39,644 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn_layer_norm.weight
2022-03-31 11:14:39,645 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn_layer_norm.bias
2022-03-31 11:14:39,645 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.fc1.weight
2022-03-31 11:14:39,645 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.fc1.bias
2022-03-31 11:14:39,645 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.fc2.weight
2022-03-31 11:14:39,645 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.fc2.bias
2022-03-31 11:14:39,645 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.final_layer_norm.weight
2022-03-31 11:14:39,645 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.final_layer_norm.bias
2022-03-31 11:14:39,645 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.k_proj.weight
2022-03-31 11:14:39,645 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.k_proj.bias
2022-03-31 11:14:39,645 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.v_proj.weight
2022-03-31 11:14:39,646 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.v_proj.bias
2022-03-31 11:14:39,646 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.q_proj.weight
2022-03-31 11:14:39,646 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.q_proj.bias
2022-03-31 11:14:39,646 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.out_proj.weight
2022-03-31 11:14:39,646 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.out_proj.bias
2022-03-31 11:14:39,646 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn_layer_norm.weight
2022-03-31 11:14:39,646 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn_layer_norm.bias
2022-03-31 11:14:39,646 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.fc1.weight
2022-03-31 11:14:39,646 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.fc1.bias
2022-03-31 11:14:39,646 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.fc2.weight
2022-03-31 11:14:39,647 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.fc2.bias
2022-03-31 11:14:39,647 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.final_layer_norm.weight
2022-03-31 11:14:39,647 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.final_layer_norm.bias
2022-03-31 11:14:39,647 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.k_proj.weight
2022-03-31 11:14:39,647 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.k_proj.bias
2022-03-31 11:14:39,647 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.v_proj.weight
2022-03-31 11:14:39,647 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.v_proj.bias
2022-03-31 11:14:39,647 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.q_proj.weight
2022-03-31 11:14:39,647 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.q_proj.bias
2022-03-31 11:14:39,647 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.out_proj.weight
2022-03-31 11:14:39,648 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.out_proj.bias
2022-03-31 11:14:39,648 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn_layer_norm.weight
2022-03-31 11:14:39,648 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn_layer_norm.bias
2022-03-31 11:14:39,648 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.fc1.weight
2022-03-31 11:14:39,648 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.fc1.bias
2022-03-31 11:14:39,648 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.fc2.weight
2022-03-31 11:14:39,648 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.fc2.bias
2022-03-31 11:14:39,648 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.final_layer_norm.weight
2022-03-31 11:14:39,648 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.final_layer_norm.bias
2022-03-31 11:14:39,648 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.k_proj.weight
2022-03-31 11:14:39,649 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.k_proj.bias
2022-03-31 11:14:39,649 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.v_proj.weight
2022-03-31 11:14:39,649 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.v_proj.bias
2022-03-31 11:14:39,649 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.q_proj.weight
2022-03-31 11:14:39,649 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.q_proj.bias
2022-03-31 11:14:39,649 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.out_proj.weight
2022-03-31 11:14:39,649 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.out_proj.bias
2022-03-31 11:14:39,649 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn_layer_norm.weight
2022-03-31 11:14:39,649 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn_layer_norm.bias
2022-03-31 11:14:39,649 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.fc1.weight
2022-03-31 11:14:39,650 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.fc1.bias
2022-03-31 11:14:39,650 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.fc2.weight
2022-03-31 11:14:39,650 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.fc2.bias
2022-03-31 11:14:39,650 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.final_layer_norm.weight
2022-03-31 11:14:39,650 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.final_layer_norm.bias
2022-03-31 11:14:39,650 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.k_proj.weight
2022-03-31 11:14:39,650 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.k_proj.bias
2022-03-31 11:14:39,650 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.v_proj.weight
2022-03-31 11:14:39,650 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.v_proj.bias
2022-03-31 11:14:39,650 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.q_proj.weight
2022-03-31 11:14:39,650 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.q_proj.bias
2022-03-31 11:14:39,651 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.out_proj.weight
2022-03-31 11:14:39,651 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.out_proj.bias
2022-03-31 11:14:39,651 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn_layer_norm.weight
2022-03-31 11:14:39,651 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn_layer_norm.bias
2022-03-31 11:14:39,651 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.fc1.weight
2022-03-31 11:14:39,651 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.fc1.bias
2022-03-31 11:14:39,651 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.fc2.weight
2022-03-31 11:14:39,651 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.fc2.bias
2022-03-31 11:14:39,651 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.final_layer_norm.weight
2022-03-31 11:14:39,651 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.final_layer_norm.bias
2022-03-31 11:14:39,652 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.k_proj.weight
2022-03-31 11:14:39,652 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.k_proj.bias
2022-03-31 11:14:39,652 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.v_proj.weight
2022-03-31 11:14:39,652 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.v_proj.bias
2022-03-31 11:14:39,652 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.q_proj.weight
2022-03-31 11:14:39,652 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.q_proj.bias
2022-03-31 11:14:39,652 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.out_proj.weight
2022-03-31 11:14:39,652 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.out_proj.bias
2022-03-31 11:14:39,652 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn_layer_norm.weight
2022-03-31 11:14:39,652 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn_layer_norm.bias
2022-03-31 11:14:39,652 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.fc1.weight
2022-03-31 11:14:39,653 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.fc1.bias
2022-03-31 11:14:39,653 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.fc2.weight
2022-03-31 11:14:39,653 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.fc2.bias
2022-03-31 11:14:39,653 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.final_layer_norm.weight
2022-03-31 11:14:39,653 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.final_layer_norm.bias
2022-03-31 11:14:39,653 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.k_proj.weight
2022-03-31 11:14:39,653 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.k_proj.bias
2022-03-31 11:14:39,653 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.v_proj.weight
2022-03-31 11:14:39,653 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.v_proj.bias
2022-03-31 11:14:39,653 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.q_proj.weight
2022-03-31 11:14:39,654 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.q_proj.bias
2022-03-31 11:14:39,654 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.out_proj.weight
2022-03-31 11:14:39,654 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.out_proj.bias
2022-03-31 11:14:39,654 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn_layer_norm.weight
2022-03-31 11:14:39,654 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn_layer_norm.bias
2022-03-31 11:14:39,654 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.fc1.weight
2022-03-31 11:14:39,654 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.fc1.bias
2022-03-31 11:14:39,654 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.fc2.weight
2022-03-31 11:14:39,654 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.fc2.bias
2022-03-31 11:14:39,654 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.final_layer_norm.weight
2022-03-31 11:14:39,655 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.final_layer_norm.bias
2022-03-31 11:14:39,655 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.k_proj.weight
2022-03-31 11:14:39,655 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.k_proj.bias
2022-03-31 11:14:39,655 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.v_proj.weight
2022-03-31 11:14:39,655 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.v_proj.bias
2022-03-31 11:14:39,655 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.q_proj.weight
2022-03-31 11:14:39,655 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.q_proj.bias
2022-03-31 11:14:39,655 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.out_proj.weight
2022-03-31 11:14:39,655 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.out_proj.bias
2022-03-31 11:14:39,655 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn_layer_norm.weight
2022-03-31 11:14:39,656 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn_layer_norm.bias
2022-03-31 11:14:39,656 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.fc1.weight
2022-03-31 11:14:39,656 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.fc1.bias
2022-03-31 11:14:39,656 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.fc2.weight
2022-03-31 11:14:39,656 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.fc2.bias
2022-03-31 11:14:39,656 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.final_layer_norm.weight
2022-03-31 11:14:39,656 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.final_layer_norm.bias
2022-03-31 11:14:39,656 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.k_proj.weight
2022-03-31 11:14:39,656 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.k_proj.bias
2022-03-31 11:14:39,656 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.v_proj.weight
2022-03-31 11:14:39,657 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.v_proj.bias
2022-03-31 11:14:39,657 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.q_proj.weight
2022-03-31 11:14:39,657 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.q_proj.bias
2022-03-31 11:14:39,657 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.out_proj.weight
2022-03-31 11:14:39,657 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.out_proj.bias
2022-03-31 11:14:39,657 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn_layer_norm.weight
2022-03-31 11:14:39,657 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn_layer_norm.bias
2022-03-31 11:14:39,657 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.fc1.weight
2022-03-31 11:14:39,657 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.fc1.bias
2022-03-31 11:14:39,657 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.fc2.weight
2022-03-31 11:14:39,658 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.fc2.bias
2022-03-31 11:14:39,658 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.final_layer_norm.weight
2022-03-31 11:14:39,658 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.final_layer_norm.bias
2022-03-31 11:14:39,658 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.k_proj.weight
2022-03-31 11:14:39,658 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.k_proj.bias
2022-03-31 11:14:39,658 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.v_proj.weight
2022-03-31 11:14:39,658 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.v_proj.bias
2022-03-31 11:14:39,658 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.q_proj.weight
2022-03-31 11:14:39,658 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.q_proj.bias
2022-03-31 11:14:39,658 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.out_proj.weight
2022-03-31 11:14:39,659 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.out_proj.bias
2022-03-31 11:14:39,659 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn_layer_norm.weight
2022-03-31 11:14:39,659 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn_layer_norm.bias
2022-03-31 11:14:39,659 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.fc1.weight
2022-03-31 11:14:39,659 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.fc1.bias
2022-03-31 11:14:39,659 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.fc2.weight
2022-03-31 11:14:39,659 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.fc2.bias
2022-03-31 11:14:39,659 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.final_layer_norm.weight
2022-03-31 11:14:39,659 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.final_layer_norm.bias
2022-03-31 11:14:39,659 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.k_proj.weight
2022-03-31 11:14:39,660 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.k_proj.bias
2022-03-31 11:14:39,660 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.v_proj.weight
2022-03-31 11:14:39,660 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.v_proj.bias
2022-03-31 11:14:39,660 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.q_proj.weight
2022-03-31 11:14:39,660 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.q_proj.bias
2022-03-31 11:14:39,660 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.out_proj.weight
2022-03-31 11:14:39,660 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.out_proj.bias
2022-03-31 11:14:39,660 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn_layer_norm.weight
2022-03-31 11:14:39,660 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn_layer_norm.bias
2022-03-31 11:14:39,660 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.fc1.weight
2022-03-31 11:14:39,661 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.fc1.bias
2022-03-31 11:14:39,661 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.fc2.weight
2022-03-31 11:14:39,661 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.fc2.bias
2022-03-31 11:14:39,661 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.final_layer_norm.weight
2022-03-31 11:14:39,661 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.final_layer_norm.bias
2022-03-31 11:14:39,661 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.k_proj.weight
2022-03-31 11:14:39,661 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.k_proj.bias
2022-03-31 11:14:39,661 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.v_proj.weight
2022-03-31 11:14:39,661 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.v_proj.bias
2022-03-31 11:14:39,661 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.q_proj.weight
2022-03-31 11:14:39,661 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.q_proj.bias
2022-03-31 11:14:39,662 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.out_proj.weight
2022-03-31 11:14:39,662 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.out_proj.bias
2022-03-31 11:14:39,662 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn_layer_norm.weight
2022-03-31 11:14:39,662 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn_layer_norm.bias
2022-03-31 11:14:39,662 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.fc1.weight
2022-03-31 11:14:39,662 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.fc1.bias
2022-03-31 11:14:39,662 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.fc2.weight
2022-03-31 11:14:39,662 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.fc2.bias
2022-03-31 11:14:39,662 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.final_layer_norm.weight
2022-03-31 11:14:39,662 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.final_layer_norm.bias
2022-03-31 11:14:39,663 - INFO - allennlp.common.util - _seq2seq.model.encoder.layernorm_embedding.weight
2022-03-31 11:14:39,663 - INFO - allennlp.common.util - _seq2seq.model.encoder.layernorm_embedding.bias
2022-03-31 11:14:39,663 - INFO - allennlp.common.util - _seq2seq.model.decoder.embed_positions.weight
2022-03-31 11:14:39,663 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.k_proj.weight
2022-03-31 11:14:39,663 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.k_proj.bias
2022-03-31 11:14:39,663 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.v_proj.weight
2022-03-31 11:14:39,663 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.v_proj.bias
2022-03-31 11:14:39,663 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.q_proj.weight
2022-03-31 11:14:39,663 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.q_proj.bias
2022-03-31 11:14:39,663 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.out_proj.weight
2022-03-31 11:14:39,663 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.out_proj.bias
2022-03-31 11:14:39,664 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn_layer_norm.weight
2022-03-31 11:14:39,664 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn_layer_norm.bias
2022-03-31 11:14:39,664 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.k_proj.weight
2022-03-31 11:14:39,664 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.k_proj.bias
2022-03-31 11:14:39,664 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.v_proj.weight
2022-03-31 11:14:39,664 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.v_proj.bias
2022-03-31 11:14:39,664 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.q_proj.weight
2022-03-31 11:14:39,664 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.q_proj.bias
2022-03-31 11:14:39,664 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.out_proj.weight
2022-03-31 11:14:39,664 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.out_proj.bias
2022-03-31 11:14:39,665 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn_layer_norm.weight
2022-03-31 11:14:39,665 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn_layer_norm.bias
2022-03-31 11:14:39,665 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.fc1.weight
2022-03-31 11:14:39,665 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.fc1.bias
2022-03-31 11:14:39,665 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.fc2.weight
2022-03-31 11:14:39,665 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.fc2.bias
2022-03-31 11:14:39,665 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.final_layer_norm.weight
2022-03-31 11:14:39,665 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.final_layer_norm.bias
2022-03-31 11:14:39,665 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.k_proj.weight
2022-03-31 11:14:39,665 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.k_proj.bias
2022-03-31 11:14:39,666 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.v_proj.weight
2022-03-31 11:14:39,666 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.v_proj.bias
2022-03-31 11:14:39,666 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.q_proj.weight
2022-03-31 11:14:39,666 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.q_proj.bias
2022-03-31 11:14:39,666 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.out_proj.weight
2022-03-31 11:14:39,666 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.out_proj.bias
2022-03-31 11:14:39,666 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn_layer_norm.weight
2022-03-31 11:14:39,666 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn_layer_norm.bias
2022-03-31 11:14:39,666 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.k_proj.weight
2022-03-31 11:14:39,666 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.k_proj.bias
2022-03-31 11:14:39,667 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.v_proj.weight
2022-03-31 11:14:39,667 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.v_proj.bias
2022-03-31 11:14:39,667 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.q_proj.weight
2022-03-31 11:14:39,667 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.q_proj.bias
2022-03-31 11:14:39,667 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.out_proj.weight
2022-03-31 11:14:39,667 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.out_proj.bias
2022-03-31 11:14:39,667 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn_layer_norm.weight
2022-03-31 11:14:39,667 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn_layer_norm.bias
2022-03-31 11:14:39,667 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.fc1.weight
2022-03-31 11:14:39,667 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.fc1.bias
2022-03-31 11:14:39,667 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.fc2.weight
2022-03-31 11:14:39,668 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.fc2.bias
2022-03-31 11:14:39,668 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.final_layer_norm.weight
2022-03-31 11:14:39,668 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.final_layer_norm.bias
2022-03-31 11:14:39,668 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.k_proj.weight
2022-03-31 11:14:39,668 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.k_proj.bias
2022-03-31 11:14:39,668 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.v_proj.weight
2022-03-31 11:14:39,668 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.v_proj.bias
2022-03-31 11:14:39,668 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.q_proj.weight
2022-03-31 11:14:39,668 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.q_proj.bias
2022-03-31 11:14:39,668 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.out_proj.weight
2022-03-31 11:14:39,669 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.out_proj.bias
2022-03-31 11:14:39,669 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn_layer_norm.weight
2022-03-31 11:14:39,669 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn_layer_norm.bias
2022-03-31 11:14:39,669 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.k_proj.weight
2022-03-31 11:14:39,669 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.k_proj.bias
2022-03-31 11:14:39,669 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.v_proj.weight
2022-03-31 11:14:39,669 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.v_proj.bias
2022-03-31 11:14:39,669 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.q_proj.weight
2022-03-31 11:14:39,669 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.q_proj.bias
2022-03-31 11:14:39,669 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.out_proj.weight
2022-03-31 11:14:39,670 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.out_proj.bias
2022-03-31 11:14:39,670 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn_layer_norm.weight
2022-03-31 11:14:39,670 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn_layer_norm.bias
2022-03-31 11:14:39,670 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.fc1.weight
2022-03-31 11:14:39,670 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.fc1.bias
2022-03-31 11:14:39,670 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.fc2.weight
2022-03-31 11:14:39,670 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.fc2.bias
2022-03-31 11:14:39,670 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.final_layer_norm.weight
2022-03-31 11:14:39,670 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.final_layer_norm.bias
2022-03-31 11:14:39,670 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.k_proj.weight
2022-03-31 11:14:39,670 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.k_proj.bias
2022-03-31 11:14:39,670 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.v_proj.weight
2022-03-31 11:14:39,671 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.v_proj.bias
2022-03-31 11:14:39,671 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.q_proj.weight
2022-03-31 11:14:39,671 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.q_proj.bias
2022-03-31 11:14:39,671 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.out_proj.weight
2022-03-31 11:14:39,671 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.out_proj.bias
2022-03-31 11:14:39,671 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn_layer_norm.weight
2022-03-31 11:14:39,671 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn_layer_norm.bias
2022-03-31 11:14:39,671 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.k_proj.weight
2022-03-31 11:14:39,671 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.k_proj.bias
2022-03-31 11:14:39,671 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.v_proj.weight
2022-03-31 11:14:39,671 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.v_proj.bias
2022-03-31 11:14:39,672 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.q_proj.weight
2022-03-31 11:14:39,672 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.q_proj.bias
2022-03-31 11:14:39,672 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.out_proj.weight
2022-03-31 11:14:39,672 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.out_proj.bias
2022-03-31 11:14:39,672 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn_layer_norm.weight
2022-03-31 11:14:39,672 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn_layer_norm.bias
2022-03-31 11:14:39,672 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.fc1.weight
2022-03-31 11:14:39,672 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.fc1.bias
2022-03-31 11:14:39,672 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.fc2.weight
2022-03-31 11:14:39,672 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.fc2.bias
2022-03-31 11:14:39,673 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.final_layer_norm.weight
2022-03-31 11:14:39,673 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.final_layer_norm.bias
2022-03-31 11:14:39,673 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.k_proj.weight
2022-03-31 11:14:39,673 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.k_proj.bias
2022-03-31 11:14:39,673 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.v_proj.weight
2022-03-31 11:14:39,673 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.v_proj.bias
2022-03-31 11:14:39,673 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.q_proj.weight
2022-03-31 11:14:39,673 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.q_proj.bias
2022-03-31 11:14:39,673 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.out_proj.weight
2022-03-31 11:14:39,673 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.out_proj.bias
2022-03-31 11:14:39,674 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn_layer_norm.weight
2022-03-31 11:14:39,674 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn_layer_norm.bias
2022-03-31 11:14:39,674 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.k_proj.weight
2022-03-31 11:14:39,674 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.k_proj.bias
2022-03-31 11:14:39,674 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.v_proj.weight
2022-03-31 11:14:39,674 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.v_proj.bias
2022-03-31 11:14:39,674 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.q_proj.weight
2022-03-31 11:14:39,674 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.q_proj.bias
2022-03-31 11:14:39,674 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.out_proj.weight
2022-03-31 11:14:39,674 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.out_proj.bias
2022-03-31 11:14:39,674 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn_layer_norm.weight
2022-03-31 11:14:39,675 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn_layer_norm.bias
2022-03-31 11:14:39,675 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.fc1.weight
2022-03-31 11:14:39,675 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.fc1.bias
2022-03-31 11:14:39,675 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.fc2.weight
2022-03-31 11:14:39,675 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.fc2.bias
2022-03-31 11:14:39,675 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.final_layer_norm.weight
2022-03-31 11:14:39,675 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.final_layer_norm.bias
2022-03-31 11:14:39,675 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.k_proj.weight
2022-03-31 11:14:39,675 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.k_proj.bias
2022-03-31 11:14:39,675 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.v_proj.weight
2022-03-31 11:14:39,675 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.v_proj.bias
2022-03-31 11:14:39,676 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.q_proj.weight
2022-03-31 11:14:39,676 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.q_proj.bias
2022-03-31 11:14:39,676 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.out_proj.weight
2022-03-31 11:14:39,676 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.out_proj.bias
2022-03-31 11:14:39,676 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn_layer_norm.weight
2022-03-31 11:14:39,676 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn_layer_norm.bias
2022-03-31 11:14:39,676 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.k_proj.weight
2022-03-31 11:14:39,676 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.k_proj.bias
2022-03-31 11:14:39,676 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.v_proj.weight
2022-03-31 11:14:39,676 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.v_proj.bias
2022-03-31 11:14:39,677 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.q_proj.weight
2022-03-31 11:14:39,677 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.q_proj.bias
2022-03-31 11:14:39,677 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.out_proj.weight
2022-03-31 11:14:39,677 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.out_proj.bias
2022-03-31 11:14:39,677 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn_layer_norm.weight
2022-03-31 11:14:39,677 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn_layer_norm.bias
2022-03-31 11:14:39,677 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.fc1.weight
2022-03-31 11:14:39,677 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.fc1.bias
2022-03-31 11:14:39,677 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.fc2.weight
2022-03-31 11:14:39,677 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.fc2.bias
2022-03-31 11:14:39,678 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.final_layer_norm.weight
2022-03-31 11:14:39,678 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.final_layer_norm.bias
2022-03-31 11:14:39,678 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.k_proj.weight
2022-03-31 11:14:39,678 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.k_proj.bias
2022-03-31 11:14:39,678 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.v_proj.weight
2022-03-31 11:14:39,678 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.v_proj.bias
2022-03-31 11:14:39,678 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.q_proj.weight
2022-03-31 11:14:39,678 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.q_proj.bias
2022-03-31 11:14:39,678 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.out_proj.weight
2022-03-31 11:14:39,678 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.out_proj.bias
2022-03-31 11:14:39,679 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn_layer_norm.weight
2022-03-31 11:14:39,679 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn_layer_norm.bias
2022-03-31 11:14:39,679 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.k_proj.weight
2022-03-31 11:14:39,679 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.k_proj.bias
2022-03-31 11:14:39,679 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.v_proj.weight
2022-03-31 11:14:39,679 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.v_proj.bias
2022-03-31 11:14:39,679 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.q_proj.weight
2022-03-31 11:14:39,679 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.q_proj.bias
2022-03-31 11:14:39,679 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.out_proj.weight
2022-03-31 11:14:39,679 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.out_proj.bias
2022-03-31 11:14:39,680 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn_layer_norm.weight
2022-03-31 11:14:39,680 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn_layer_norm.bias
2022-03-31 11:14:39,680 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.fc1.weight
2022-03-31 11:14:39,680 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.fc1.bias
2022-03-31 11:14:39,680 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.fc2.weight
2022-03-31 11:14:39,680 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.fc2.bias
2022-03-31 11:14:39,680 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.final_layer_norm.weight
2022-03-31 11:14:39,680 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.final_layer_norm.bias
2022-03-31 11:14:39,680 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.k_proj.weight
2022-03-31 11:14:39,680 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.k_proj.bias
2022-03-31 11:14:39,680 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.v_proj.weight
2022-03-31 11:14:39,681 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.v_proj.bias
2022-03-31 11:14:39,681 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.q_proj.weight
2022-03-31 11:14:39,681 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.q_proj.bias
2022-03-31 11:14:39,681 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.out_proj.weight
2022-03-31 11:14:39,681 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.out_proj.bias
2022-03-31 11:14:39,681 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn_layer_norm.weight
2022-03-31 11:14:39,681 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn_layer_norm.bias
2022-03-31 11:14:39,681 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.k_proj.weight
2022-03-31 11:14:39,681 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.k_proj.bias
2022-03-31 11:14:39,682 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.v_proj.weight
2022-03-31 11:14:39,682 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.v_proj.bias
2022-03-31 11:14:39,682 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.q_proj.weight
2022-03-31 11:14:39,682 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.q_proj.bias
2022-03-31 11:14:39,682 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.out_proj.weight
2022-03-31 11:14:39,682 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.out_proj.bias
2022-03-31 11:14:39,682 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn_layer_norm.weight
2022-03-31 11:14:39,682 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn_layer_norm.bias
2022-03-31 11:14:39,682 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.fc1.weight
2022-03-31 11:14:39,682 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.fc1.bias
2022-03-31 11:14:39,682 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.fc2.weight
2022-03-31 11:14:39,683 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.fc2.bias
2022-03-31 11:14:39,683 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.final_layer_norm.weight
2022-03-31 11:14:39,683 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.final_layer_norm.bias
2022-03-31 11:14:39,683 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.k_proj.weight
2022-03-31 11:14:39,683 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.k_proj.bias
2022-03-31 11:14:39,683 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.v_proj.weight
2022-03-31 11:14:39,683 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.v_proj.bias
2022-03-31 11:14:39,683 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.q_proj.weight
2022-03-31 11:14:39,683 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.q_proj.bias
2022-03-31 11:14:39,683 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.out_proj.weight
2022-03-31 11:14:39,683 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.out_proj.bias
2022-03-31 11:14:39,684 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn_layer_norm.weight
2022-03-31 11:14:39,684 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn_layer_norm.bias
2022-03-31 11:14:39,684 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.k_proj.weight
2022-03-31 11:14:39,684 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.k_proj.bias
2022-03-31 11:14:39,684 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.v_proj.weight
2022-03-31 11:14:39,684 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.v_proj.bias
2022-03-31 11:14:39,684 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.q_proj.weight
2022-03-31 11:14:39,684 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.q_proj.bias
2022-03-31 11:14:39,684 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.out_proj.weight
2022-03-31 11:14:39,684 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.out_proj.bias
2022-03-31 11:14:39,685 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn_layer_norm.weight
2022-03-31 11:14:39,685 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn_layer_norm.bias
2022-03-31 11:14:39,685 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.fc1.weight
2022-03-31 11:14:39,685 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.fc1.bias
2022-03-31 11:14:39,685 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.fc2.weight
2022-03-31 11:14:39,685 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.fc2.bias
2022-03-31 11:14:39,685 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.final_layer_norm.weight
2022-03-31 11:14:39,685 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.final_layer_norm.bias
2022-03-31 11:14:39,685 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.k_proj.weight
2022-03-31 11:14:39,685 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.k_proj.bias
2022-03-31 11:14:39,686 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.v_proj.weight
2022-03-31 11:14:39,686 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.v_proj.bias
2022-03-31 11:14:39,686 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.q_proj.weight
2022-03-31 11:14:39,686 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.q_proj.bias
2022-03-31 11:14:39,686 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.out_proj.weight
2022-03-31 11:14:39,686 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.out_proj.bias
2022-03-31 11:14:39,686 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn_layer_norm.weight
2022-03-31 11:14:39,686 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn_layer_norm.bias
2022-03-31 11:14:39,686 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.k_proj.weight
2022-03-31 11:14:39,686 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.k_proj.bias
2022-03-31 11:14:39,687 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.v_proj.weight
2022-03-31 11:14:39,687 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.v_proj.bias
2022-03-31 11:14:39,687 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.q_proj.weight
2022-03-31 11:14:39,687 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.q_proj.bias
2022-03-31 11:14:39,687 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.out_proj.weight
2022-03-31 11:14:39,687 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.out_proj.bias
2022-03-31 11:14:39,687 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn_layer_norm.weight
2022-03-31 11:14:39,687 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn_layer_norm.bias
2022-03-31 11:14:39,687 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.fc1.weight
2022-03-31 11:14:39,687 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.fc1.bias
2022-03-31 11:14:39,687 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.fc2.weight
2022-03-31 11:14:39,687 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.fc2.bias
2022-03-31 11:14:39,688 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.final_layer_norm.weight
2022-03-31 11:14:39,688 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.final_layer_norm.bias
2022-03-31 11:14:39,688 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.k_proj.weight
2022-03-31 11:14:39,688 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.k_proj.bias
2022-03-31 11:14:39,688 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.v_proj.weight
2022-03-31 11:14:39,688 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.v_proj.bias
2022-03-31 11:14:39,688 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.q_proj.weight
2022-03-31 11:14:39,688 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.q_proj.bias
2022-03-31 11:14:39,688 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.out_proj.weight
2022-03-31 11:14:39,688 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.out_proj.bias
2022-03-31 11:14:39,688 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn_layer_norm.weight
2022-03-31 11:14:39,689 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn_layer_norm.bias
2022-03-31 11:14:39,689 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.k_proj.weight
2022-03-31 11:14:39,689 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.k_proj.bias
2022-03-31 11:14:39,689 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.v_proj.weight
2022-03-31 11:14:39,689 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.v_proj.bias
2022-03-31 11:14:39,689 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.q_proj.weight
2022-03-31 11:14:39,689 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.q_proj.bias
2022-03-31 11:14:39,689 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.out_proj.weight
2022-03-31 11:14:39,689 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.out_proj.bias
2022-03-31 11:14:39,689 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn_layer_norm.weight
2022-03-31 11:14:39,689 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn_layer_norm.bias
2022-03-31 11:14:39,690 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.fc1.weight
2022-03-31 11:14:39,690 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.fc1.bias
2022-03-31 11:14:39,690 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.fc2.weight
2022-03-31 11:14:39,690 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.fc2.bias
2022-03-31 11:14:39,690 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.final_layer_norm.weight
2022-03-31 11:14:39,690 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.final_layer_norm.bias
2022-03-31 11:14:39,690 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.k_proj.weight
2022-03-31 11:14:39,690 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.k_proj.bias
2022-03-31 11:14:39,690 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.v_proj.weight
2022-03-31 11:14:39,690 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.v_proj.bias
2022-03-31 11:14:39,691 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.q_proj.weight
2022-03-31 11:14:39,691 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.q_proj.bias
2022-03-31 11:14:39,691 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.out_proj.weight
2022-03-31 11:14:39,691 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.out_proj.bias
2022-03-31 11:14:39,691 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn_layer_norm.weight
2022-03-31 11:14:39,691 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn_layer_norm.bias
2022-03-31 11:14:39,691 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.k_proj.weight
2022-03-31 11:14:39,691 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.k_proj.bias
2022-03-31 11:14:39,691 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.v_proj.weight
2022-03-31 11:14:39,691 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.v_proj.bias
2022-03-31 11:14:39,691 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.q_proj.weight
2022-03-31 11:14:39,691 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.q_proj.bias
2022-03-31 11:14:39,692 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.out_proj.weight
2022-03-31 11:14:39,692 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.out_proj.bias
2022-03-31 11:14:39,692 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn_layer_norm.weight
2022-03-31 11:14:39,692 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn_layer_norm.bias
2022-03-31 11:14:39,692 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.fc1.weight
2022-03-31 11:14:39,692 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.fc1.bias
2022-03-31 11:14:39,692 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.fc2.weight
2022-03-31 11:14:39,692 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.fc2.bias
2022-03-31 11:14:39,692 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.final_layer_norm.weight
2022-03-31 11:14:39,692 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.final_layer_norm.bias
2022-03-31 11:14:39,692 - INFO - allennlp.common.util - _seq2seq.model.decoder.layernorm_embedding.weight
2022-03-31 11:14:39,693 - INFO - allennlp.common.util - _seq2seq.model.decoder.layernorm_embedding.bias
2022-03-31 11:14:39,693 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = polynomial_decay
2022-03-31 11:14:39,693 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.power = 1.0
2022-03-31 11:14:39,693 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.warmup_steps = 0
2022-03-31 11:14:39,693 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.end_learning_rate = 0.0
2022-03-31 11:14:39,693 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.last_epoch = -1
2022-03-31 11:14:39,694 - INFO - allennlp.common.params - trainer.checkpointer.type = default
2022-03-31 11:14:39,694 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None
2022-03-31 11:14:39,694 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = -1
2022-03-31 11:14:39,694 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None
2022-03-31 11:14:39,694 - INFO - allennlp.common.params - summary_interval = 100
2022-03-31 11:14:39,694 - INFO - allennlp.common.params - histogram_interval = None
2022-03-31 11:14:39,694 - INFO - allennlp.common.params - batch_size_interval = None
2022-03-31 11:14:39,695 - INFO - allennlp.common.params - should_log_parameter_statistics = True
2022-03-31 11:14:39,695 - INFO - allennlp.common.params - should_log_learning_rate = False
2022-03-31 11:14:39,695 - INFO - allennlp.common.params - get_batch_num_total = None
2022-03-31 11:14:39,697 - WARNING - allennlp.training.trainer - You provided a validation dataset but patience was set to None, meaning that early stopping is disabled
2022-03-31 11:14:40,504 - CRITICAL - root - Uncaught exception
Traceback (most recent call last):
  File "run_scripts/train.py", line 100, in <module>
    main()
  File "run_scripts/train.py", line 96, in main
    return run(args)
  File "run_scripts/train.py", line 69, in run
    run_main()
  File "/home/jupyter/src/strategyqa/run_scripts/run.py", line 53, in main
    run(args)
  File "/home/jupyter/src/strategyqa/run_scripts/run.py", line 45, in run
    allennlp_main()
  File "/opt/conda/lib/python3.7/site-packages/allennlp/commands/__init__.py", line 118, in main
    args.func(args)
  File "/opt/conda/lib/python3.7/site-packages/allennlp/commands/train.py", line 119, in train_model_from_args
    file_friendly_logging=args.file_friendly_logging,
  File "/opt/conda/lib/python3.7/site-packages/allennlp/commands/train.py", line 178, in train_model_from_file
    file_friendly_logging=file_friendly_logging,
  File "/opt/conda/lib/python3.7/site-packages/allennlp/commands/train.py", line 242, in train_model
    file_friendly_logging=file_friendly_logging,
  File "/opt/conda/lib/python3.7/site-packages/allennlp/commands/train.py", line 466, in _train_worker
    metrics = train_loop.run()
  File "/opt/conda/lib/python3.7/site-packages/allennlp/commands/train.py", line 528, in run
    return self.trainer.train()
  File "/opt/conda/lib/python3.7/site-packages/allennlp/training/trainer.py", line 966, in train
    return self._try_train()
  File "/opt/conda/lib/python3.7/site-packages/allennlp/training/trainer.py", line 973, in _try_train
    epoch_counter = self._restore_checkpoint()
  File "/opt/conda/lib/python3.7/site-packages/allennlp/training/trainer.py", line 1172, in _restore_checkpoint
    model_state, training_state = self._checkpointer.restore_checkpoint()
  File "/opt/conda/lib/python3.7/site-packages/allennlp/training/checkpointer.py", line 223, in restore_checkpoint
    training_state = torch.load(training_state_path, map_location=nn_util.device_mapping(-1))
  File "/opt/conda/lib/python3.7/site-packages/torch/serialization.py", line 581, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/opt/conda/lib/python3.7/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/opt/conda/lib/python3.7/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output_decomposition/training_state_epoch_11.th'
2022-03-31 11:22:34,339 - INFO - allennlp.common.params - random_seed = 42
2022-03-31 11:22:34,340 - INFO - allennlp.common.params - numpy_seed = 42
2022-03-31 11:22:34,340 - INFO - allennlp.common.params - pytorch_seed = 42
2022-03-31 11:22:35,008 - INFO - allennlp.common.checks - Pytorch version: 1.7.1
2022-03-31 11:22:35,009 - INFO - allennlp.common.params - type = default
2022-03-31 11:22:35,010 - INFO - allennlp.common.params - dataset_reader.type = strategy_decomposition_reader
2022-03-31 11:22:35,010 - INFO - allennlp.common.params - dataset_reader.lazy = False
2022-03-31 11:22:35,010 - INFO - allennlp.common.params - dataset_reader.cache_directory = None
2022-03-31 11:22:35,010 - INFO - allennlp.common.params - dataset_reader.max_instances = None
2022-03-31 11:22:35,011 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False
2022-03-31 11:22:35,011 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False
2022-03-31 11:22:35,011 - INFO - allennlp.common.params - dataset_reader.tokenizer_wrapper.type = default
2022-03-31 11:22:35,011 - INFO - allennlp.common.params - dataset_reader.tokenizer_wrapper.pretrained_model = facebook/bart-large
2022-03-31 11:22:35,011 - INFO - allennlp.common.params - dataset_reader.tokenizer_wrapper.init_kwargs.add_prefix_space = True
2022-03-31 11:22:35,100 - INFO - allennlp.common.params - dataset_reader.save_tokenizer = True
2022-03-31 11:22:35,100 - INFO - allennlp.common.params - dataset_reader.is_training = True
2022-03-31 11:22:35,100 - INFO - allennlp.common.params - dataset_reader.pickle.action = None
2022-03-31 11:22:35,100 - INFO - allennlp.common.params - train_data_path = data/strategyqa/train.json
2022-03-31 11:22:35,101 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7f446bc5fcd0>
2022-03-31 11:22:35,101 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2022-03-31 11:22:35,101 - INFO - allennlp.common.params - validation_dataset_reader.type = strategy_decomposition_reader
2022-03-31 11:22:35,101 - INFO - allennlp.common.params - validation_dataset_reader.lazy = False
2022-03-31 11:22:35,101 - INFO - allennlp.common.params - validation_dataset_reader.cache_directory = None
2022-03-31 11:22:35,101 - INFO - allennlp.common.params - validation_dataset_reader.max_instances = None
2022-03-31 11:22:35,101 - INFO - allennlp.common.params - validation_dataset_reader.manual_distributed_sharding = False
2022-03-31 11:22:35,101 - INFO - allennlp.common.params - validation_dataset_reader.manual_multi_process_sharding = False
2022-03-31 11:22:35,101 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer_wrapper.type = default
2022-03-31 11:22:35,102 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer_wrapper.pretrained_model = facebook/bart-large
2022-03-31 11:22:35,102 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer_wrapper.init_kwargs.add_prefix_space = True
2022-03-31 11:22:35,174 - INFO - allennlp.common.params - validation_dataset_reader.save_tokenizer = False
2022-03-31 11:22:35,174 - INFO - allennlp.common.params - validation_dataset_reader.is_training = False
2022-03-31 11:22:35,174 - INFO - allennlp.common.params - validation_dataset_reader.pickle.action = None
2022-03-31 11:22:35,174 - INFO - allennlp.common.params - validation_data_path = data/strategyqa/dev.json
2022-03-31 11:22:35,174 - INFO - allennlp.common.params - validation_data_loader = None
2022-03-31 11:22:35,175 - INFO - allennlp.common.params - test_data_path = None
2022-03-31 11:22:35,175 - INFO - allennlp.common.params - evaluate_on_test = False
2022-03-31 11:22:35,175 - INFO - allennlp.common.params - batch_weight_key = 
2022-03-31 11:22:35,175 - INFO - allennlp.training.util - Reading training data from data/strategyqa/train.json
2022-03-31 11:22:35,175 - INFO - tqdm - reading instances: 0it [00:00, ?it/s]
2022-03-31 11:22:35,175 - INFO - src.data.dataset_readers.base.base_dataset_reader - Reading the dataset from scratch
2022-03-31 11:22:35,175 - INFO - src.data.dataset_readers.strategy_decomposition_reader - Reading the dataset:
2022-03-31 11:22:35,175 - INFO - src.data.dataset_readers.strategy_decomposition_reader - Reading file at data/strategyqa/train.json
2022-03-31 11:22:36,540 - INFO - allennlp.training.util - Reading validation data from data/strategyqa/dev.json
2022-03-31 11:22:36,540 - INFO - tqdm - reading instances: 0it [00:00, ?it/s]
2022-03-31 11:22:36,540 - INFO - src.data.dataset_readers.base.base_dataset_reader - Reading the dataset from scratch
2022-03-31 11:22:36,540 - INFO - src.data.dataset_readers.strategy_decomposition_reader - Reading the dataset:
2022-03-31 11:22:36,540 - INFO - src.data.dataset_readers.strategy_decomposition_reader - Reading file at data/strategyqa/dev.json
2022-03-31 11:22:36,688 - INFO - allennlp.common.params - type = from_instances
2022-03-31 11:22:36,688 - INFO - allennlp.common.params - min_count = None
2022-03-31 11:22:36,688 - INFO - allennlp.common.params - max_vocab_size = None
2022-03-31 11:22:36,688 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2022-03-31 11:22:36,688 - INFO - allennlp.common.params - pretrained_files = None
2022-03-31 11:22:36,688 - INFO - allennlp.common.params - only_include_pretrained_words = False
2022-03-31 11:22:36,688 - INFO - allennlp.common.params - tokens_to_add = None
2022-03-31 11:22:36,689 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2022-03-31 11:22:36,689 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2022-03-31 11:22:36,689 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2022-03-31 11:22:36,689 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2022-03-31 11:22:36,689 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2022-03-31 11:22:36,693 - INFO - allennlp.common.params - model.type = gen
2022-03-31 11:22:36,693 - INFO - allennlp.common.params - model.regularizer = None
2022-03-31 11:22:36,693 - INFO - allennlp.common.params - model.pretrained_model = facebook/bart-large
2022-03-31 11:22:36,694 - INFO - allennlp.common.params - model.tokenizer_wrapper.type = default
2022-03-31 11:22:36,694 - INFO - allennlp.common.params - model.tokenizer_wrapper.pretrained_model = facebook/bart-large
2022-03-31 11:22:36,694 - INFO - allennlp.common.params - model.tokenizer_wrapper.init_kwargs.add_prefix_space = True
2022-03-31 11:22:36,769 - INFO - allennlp.common.params - model.generate_while_training = False
2022-03-31 11:22:36,769 - INFO - allennlp.common.params - model.repetition_penalty = 2.5
2022-03-31 11:22:36,769 - INFO - allennlp.common.params - model.metrics.bleu.type = bleu
2022-03-31 11:22:36,769 - INFO - allennlp.common.params - model.metrics.bleu.ngram_weights = (0.25, 0.25, 0.25, 0.25)
2022-03-31 11:22:36,769 - INFO - allennlp.common.params - model.metrics.bleu.exclude_indices = None
2022-03-31 11:22:36,769 - INFO - allennlp.common.params - model.metrics.rouge.type = rouge
2022-03-31 11:22:36,770 - INFO - allennlp.common.params - model.metrics.rouge.ngram_size = 2
2022-03-31 11:22:36,770 - INFO - allennlp.common.params - model.metrics.rouge.exclude_indices = None
2022-03-31 11:22:36,770 - INFO - allennlp.common.params - model.metrics.sari.type = sari
2022-03-31 11:22:36,770 - INFO - allennlp.common.params - model.metrics.sari.is_main = True
2022-03-31 11:22:36,770 - INFO - allennlp.common.params - model.is_dummy = False
2022-03-31 11:22:36,770 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f44610234d0>
2022-03-31 11:22:52,639 - INFO - allennlp.nn.initializers - Initializing parameters
2022-03-31 11:22:52,642 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-03-31 11:22:52,643 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.embed_positions.weight
2022-03-31 11:22:52,643 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layernorm_embedding.bias
2022-03-31 11:22:52,643 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layernorm_embedding.weight
2022-03-31 11:22:52,643 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.k_proj.bias
2022-03-31 11:22:52,643 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.k_proj.weight
2022-03-31 11:22:52,643 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.out_proj.bias
2022-03-31 11:22:52,643 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.out_proj.weight
2022-03-31 11:22:52,643 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.q_proj.bias
2022-03-31 11:22:52,643 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.q_proj.weight
2022-03-31 11:22:52,643 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.v_proj.bias
2022-03-31 11:22:52,643 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.v_proj.weight
2022-03-31 11:22:52,643 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn_layer_norm.bias
2022-03-31 11:22:52,643 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn_layer_norm.weight
2022-03-31 11:22:52,644 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.fc1.bias
2022-03-31 11:22:52,644 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.fc1.weight
2022-03-31 11:22:52,644 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.fc2.bias
2022-03-31 11:22:52,644 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.fc2.weight
2022-03-31 11:22:52,644 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.final_layer_norm.bias
2022-03-31 11:22:52,644 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.final_layer_norm.weight
2022-03-31 11:22:52,644 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.k_proj.bias
2022-03-31 11:22:52,644 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.k_proj.weight
2022-03-31 11:22:52,644 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.out_proj.bias
2022-03-31 11:22:52,644 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.out_proj.weight
2022-03-31 11:22:52,644 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.q_proj.bias
2022-03-31 11:22:52,644 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.q_proj.weight
2022-03-31 11:22:52,644 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.v_proj.bias
2022-03-31 11:22:52,644 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.v_proj.weight
2022-03-31 11:22:52,644 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn_layer_norm.bias
2022-03-31 11:22:52,644 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn_layer_norm.weight
2022-03-31 11:22:52,645 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.k_proj.bias
2022-03-31 11:22:52,645 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.k_proj.weight
2022-03-31 11:22:52,645 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.out_proj.bias
2022-03-31 11:22:52,645 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.out_proj.weight
2022-03-31 11:22:52,645 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.q_proj.bias
2022-03-31 11:22:52,645 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.q_proj.weight
2022-03-31 11:22:52,645 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.v_proj.bias
2022-03-31 11:22:52,645 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.v_proj.weight
2022-03-31 11:22:52,645 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn_layer_norm.bias
2022-03-31 11:22:52,645 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn_layer_norm.weight
2022-03-31 11:22:52,645 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.fc1.bias
2022-03-31 11:22:52,645 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.fc1.weight
2022-03-31 11:22:52,645 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.fc2.bias
2022-03-31 11:22:52,645 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.fc2.weight
2022-03-31 11:22:52,645 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.final_layer_norm.bias
2022-03-31 11:22:52,645 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.final_layer_norm.weight
2022-03-31 11:22:52,645 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.k_proj.bias
2022-03-31 11:22:52,645 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.k_proj.weight
2022-03-31 11:22:52,646 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.out_proj.bias
2022-03-31 11:22:52,646 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.out_proj.weight
2022-03-31 11:22:52,646 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.q_proj.bias
2022-03-31 11:22:52,646 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.q_proj.weight
2022-03-31 11:22:52,646 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.v_proj.bias
2022-03-31 11:22:52,646 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.v_proj.weight
2022-03-31 11:22:52,646 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn_layer_norm.bias
2022-03-31 11:22:52,646 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn_layer_norm.weight
2022-03-31 11:22:52,646 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.k_proj.bias
2022-03-31 11:22:52,646 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.k_proj.weight
2022-03-31 11:22:52,646 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.out_proj.bias
2022-03-31 11:22:52,646 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.out_proj.weight
2022-03-31 11:22:52,646 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.q_proj.bias
2022-03-31 11:22:52,646 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.q_proj.weight
2022-03-31 11:22:52,646 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.v_proj.bias
2022-03-31 11:22:52,646 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.v_proj.weight
2022-03-31 11:22:52,646 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn_layer_norm.bias
2022-03-31 11:22:52,647 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn_layer_norm.weight
2022-03-31 11:22:52,647 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.fc1.bias
2022-03-31 11:22:52,647 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.fc1.weight
2022-03-31 11:22:52,647 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.fc2.bias
2022-03-31 11:22:52,647 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.fc2.weight
2022-03-31 11:22:52,647 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.final_layer_norm.bias
2022-03-31 11:22:52,647 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.final_layer_norm.weight
2022-03-31 11:22:52,647 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.k_proj.bias
2022-03-31 11:22:52,647 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.k_proj.weight
2022-03-31 11:22:52,647 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.out_proj.bias
2022-03-31 11:22:52,647 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.out_proj.weight
2022-03-31 11:22:52,647 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.q_proj.bias
2022-03-31 11:22:52,647 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.q_proj.weight
2022-03-31 11:22:52,647 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.v_proj.bias
2022-03-31 11:22:52,647 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.v_proj.weight
2022-03-31 11:22:52,647 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn_layer_norm.bias
2022-03-31 11:22:52,647 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn_layer_norm.weight
2022-03-31 11:22:52,648 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.k_proj.bias
2022-03-31 11:22:52,648 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.k_proj.weight
2022-03-31 11:22:52,648 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.out_proj.bias
2022-03-31 11:22:52,648 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.out_proj.weight
2022-03-31 11:22:52,648 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.q_proj.bias
2022-03-31 11:22:52,648 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.q_proj.weight
2022-03-31 11:22:52,648 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.v_proj.bias
2022-03-31 11:22:52,648 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.v_proj.weight
2022-03-31 11:22:52,648 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn_layer_norm.bias
2022-03-31 11:22:52,648 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn_layer_norm.weight
2022-03-31 11:22:52,648 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.fc1.bias
2022-03-31 11:22:52,648 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.fc1.weight
2022-03-31 11:22:52,648 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.fc2.bias
2022-03-31 11:22:52,648 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.fc2.weight
2022-03-31 11:22:52,648 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.final_layer_norm.bias
2022-03-31 11:22:52,648 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.final_layer_norm.weight
2022-03-31 11:22:52,649 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.k_proj.bias
2022-03-31 11:22:52,649 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.k_proj.weight
2022-03-31 11:22:52,649 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.out_proj.bias
2022-03-31 11:22:52,649 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.out_proj.weight
2022-03-31 11:22:52,649 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.q_proj.bias
2022-03-31 11:22:52,649 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.q_proj.weight
2022-03-31 11:22:52,649 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.v_proj.bias
2022-03-31 11:22:52,649 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.v_proj.weight
2022-03-31 11:22:52,649 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn_layer_norm.bias
2022-03-31 11:22:52,649 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn_layer_norm.weight
2022-03-31 11:22:52,649 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.k_proj.bias
2022-03-31 11:22:52,649 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.k_proj.weight
2022-03-31 11:22:52,649 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.out_proj.bias
2022-03-31 11:22:52,649 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.out_proj.weight
2022-03-31 11:22:52,649 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.q_proj.bias
2022-03-31 11:22:52,649 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.q_proj.weight
2022-03-31 11:22:52,649 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.v_proj.bias
2022-03-31 11:22:52,650 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.v_proj.weight
2022-03-31 11:22:52,650 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn_layer_norm.bias
2022-03-31 11:22:52,650 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn_layer_norm.weight
2022-03-31 11:22:52,650 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.fc1.bias
2022-03-31 11:22:52,650 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.fc1.weight
2022-03-31 11:22:52,650 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.fc2.bias
2022-03-31 11:22:52,650 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.fc2.weight
2022-03-31 11:22:52,650 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.final_layer_norm.bias
2022-03-31 11:22:52,650 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.final_layer_norm.weight
2022-03-31 11:22:52,650 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.k_proj.bias
2022-03-31 11:22:52,650 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.k_proj.weight
2022-03-31 11:22:52,650 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.out_proj.bias
2022-03-31 11:22:52,650 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.out_proj.weight
2022-03-31 11:22:52,650 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.q_proj.bias
2022-03-31 11:22:52,650 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.q_proj.weight
2022-03-31 11:22:52,650 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.v_proj.bias
2022-03-31 11:22:52,651 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.v_proj.weight
2022-03-31 11:22:52,651 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn_layer_norm.bias
2022-03-31 11:22:52,651 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn_layer_norm.weight
2022-03-31 11:22:52,651 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.k_proj.bias
2022-03-31 11:22:52,651 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.k_proj.weight
2022-03-31 11:22:52,651 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.out_proj.bias
2022-03-31 11:22:52,651 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.out_proj.weight
2022-03-31 11:22:52,651 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.q_proj.bias
2022-03-31 11:22:52,651 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.q_proj.weight
2022-03-31 11:22:52,651 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.v_proj.bias
2022-03-31 11:22:52,651 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.v_proj.weight
2022-03-31 11:22:52,651 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn_layer_norm.bias
2022-03-31 11:22:52,651 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn_layer_norm.weight
2022-03-31 11:22:52,651 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.fc1.bias
2022-03-31 11:22:52,651 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.fc1.weight
2022-03-31 11:22:52,651 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.fc2.bias
2022-03-31 11:22:52,651 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.fc2.weight
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.final_layer_norm.bias
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.final_layer_norm.weight
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.k_proj.bias
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.k_proj.weight
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.out_proj.bias
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.out_proj.weight
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.q_proj.bias
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.q_proj.weight
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.v_proj.bias
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.v_proj.weight
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn_layer_norm.bias
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn_layer_norm.weight
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.k_proj.bias
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.k_proj.weight
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.out_proj.bias
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.out_proj.weight
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.q_proj.bias
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.q_proj.weight
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.v_proj.bias
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.v_proj.weight
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn_layer_norm.bias
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn_layer_norm.weight
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.fc1.bias
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.fc1.weight
2022-03-31 11:22:52,652 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.fc2.bias
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.fc2.weight
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.final_layer_norm.bias
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.final_layer_norm.weight
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.k_proj.bias
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.k_proj.weight
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.out_proj.bias
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.out_proj.weight
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.q_proj.bias
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.q_proj.weight
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.v_proj.bias
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.v_proj.weight
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn_layer_norm.bias
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn_layer_norm.weight
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.k_proj.bias
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.k_proj.weight
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.out_proj.bias
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.out_proj.weight
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.q_proj.bias
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.q_proj.weight
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.v_proj.bias
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.v_proj.weight
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn_layer_norm.bias
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn_layer_norm.weight
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.fc1.bias
2022-03-31 11:22:52,653 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.fc1.weight
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.fc2.bias
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.fc2.weight
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.final_layer_norm.bias
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.final_layer_norm.weight
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.k_proj.bias
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.k_proj.weight
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.out_proj.bias
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.out_proj.weight
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.q_proj.bias
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.q_proj.weight
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.v_proj.bias
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.v_proj.weight
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn_layer_norm.bias
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn_layer_norm.weight
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.k_proj.bias
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.k_proj.weight
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.out_proj.bias
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.out_proj.weight
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.q_proj.bias
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.q_proj.weight
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.v_proj.bias
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.v_proj.weight
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn_layer_norm.bias
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn_layer_norm.weight
2022-03-31 11:22:52,654 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.fc1.bias
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.fc1.weight
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.fc2.bias
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.fc2.weight
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.final_layer_norm.bias
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.final_layer_norm.weight
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.k_proj.bias
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.k_proj.weight
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.out_proj.bias
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.out_proj.weight
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.q_proj.bias
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.q_proj.weight
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.v_proj.bias
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.v_proj.weight
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn_layer_norm.bias
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn_layer_norm.weight
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.k_proj.bias
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.k_proj.weight
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.out_proj.bias
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.out_proj.weight
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.q_proj.bias
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.q_proj.weight
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.v_proj.bias
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.v_proj.weight
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn_layer_norm.bias
2022-03-31 11:22:52,655 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn_layer_norm.weight
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.fc1.bias
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.fc1.weight
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.fc2.bias
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.fc2.weight
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.final_layer_norm.bias
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.final_layer_norm.weight
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.k_proj.bias
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.k_proj.weight
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.out_proj.bias
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.out_proj.weight
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.q_proj.bias
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.q_proj.weight
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.v_proj.bias
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.v_proj.weight
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn_layer_norm.bias
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn_layer_norm.weight
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.k_proj.bias
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.k_proj.weight
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.out_proj.bias
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.out_proj.weight
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.q_proj.bias
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.q_proj.weight
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.v_proj.bias
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.v_proj.weight
2022-03-31 11:22:52,656 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn_layer_norm.bias
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn_layer_norm.weight
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.fc1.bias
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.fc1.weight
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.fc2.bias
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.fc2.weight
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.final_layer_norm.bias
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.final_layer_norm.weight
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.k_proj.bias
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.k_proj.weight
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.out_proj.bias
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.out_proj.weight
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.q_proj.bias
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.q_proj.weight
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.v_proj.bias
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.v_proj.weight
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn_layer_norm.bias
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn_layer_norm.weight
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.k_proj.bias
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.k_proj.weight
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.out_proj.bias
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.out_proj.weight
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.q_proj.bias
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.q_proj.weight
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.v_proj.bias
2022-03-31 11:22:52,657 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.v_proj.weight
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn_layer_norm.bias
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn_layer_norm.weight
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.fc1.bias
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.fc1.weight
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.fc2.bias
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.fc2.weight
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.final_layer_norm.bias
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.final_layer_norm.weight
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.k_proj.bias
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.k_proj.weight
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.out_proj.bias
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.out_proj.weight
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.q_proj.bias
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.q_proj.weight
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.v_proj.bias
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.v_proj.weight
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn_layer_norm.bias
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn_layer_norm.weight
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.embed_positions.weight
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layernorm_embedding.bias
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layernorm_embedding.weight
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.fc1.bias
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.fc1.weight
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.fc2.bias
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.fc2.weight
2022-03-31 11:22:52,658 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.final_layer_norm.bias
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.final_layer_norm.weight
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.k_proj.bias
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.k_proj.weight
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.out_proj.bias
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.out_proj.weight
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.q_proj.bias
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.q_proj.weight
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.v_proj.bias
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.v_proj.weight
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn_layer_norm.bias
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn_layer_norm.weight
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.fc1.bias
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.fc1.weight
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.fc2.bias
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.fc2.weight
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.final_layer_norm.bias
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.final_layer_norm.weight
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.k_proj.bias
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.k_proj.weight
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.out_proj.bias
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.out_proj.weight
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.q_proj.bias
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.q_proj.weight
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.v_proj.bias
2022-03-31 11:22:52,659 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.v_proj.weight
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn_layer_norm.bias
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn_layer_norm.weight
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.fc1.bias
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.fc1.weight
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.fc2.bias
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.fc2.weight
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.final_layer_norm.bias
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.final_layer_norm.weight
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.k_proj.bias
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.k_proj.weight
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.out_proj.bias
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.out_proj.weight
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.q_proj.bias
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.q_proj.weight
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.v_proj.bias
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.v_proj.weight
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn_layer_norm.bias
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn_layer_norm.weight
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.fc1.bias
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.fc1.weight
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.fc2.bias
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.fc2.weight
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.final_layer_norm.bias
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.final_layer_norm.weight
2022-03-31 11:22:52,660 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.k_proj.bias
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.k_proj.weight
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.out_proj.bias
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.out_proj.weight
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.q_proj.bias
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.q_proj.weight
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.v_proj.bias
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.v_proj.weight
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn_layer_norm.bias
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn_layer_norm.weight
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.fc1.bias
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.fc1.weight
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.fc2.bias
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.fc2.weight
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.final_layer_norm.bias
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.final_layer_norm.weight
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.k_proj.bias
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.k_proj.weight
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.out_proj.bias
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.out_proj.weight
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.q_proj.bias
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.q_proj.weight
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.v_proj.bias
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.v_proj.weight
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn_layer_norm.bias
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn_layer_norm.weight
2022-03-31 11:22:52,661 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.fc1.bias
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.fc1.weight
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.fc2.bias
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.fc2.weight
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.final_layer_norm.bias
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.final_layer_norm.weight
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.k_proj.bias
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.k_proj.weight
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.out_proj.bias
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.out_proj.weight
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.q_proj.bias
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.q_proj.weight
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.v_proj.bias
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.v_proj.weight
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn_layer_norm.bias
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn_layer_norm.weight
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.fc1.bias
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.fc1.weight
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.fc2.bias
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.fc2.weight
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.final_layer_norm.bias
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.final_layer_norm.weight
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.k_proj.bias
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.k_proj.weight
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.out_proj.bias
2022-03-31 11:22:52,662 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.out_proj.weight
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.q_proj.bias
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.q_proj.weight
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.v_proj.bias
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.v_proj.weight
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn_layer_norm.bias
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn_layer_norm.weight
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.fc1.bias
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.fc1.weight
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.fc2.bias
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.fc2.weight
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.final_layer_norm.bias
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.final_layer_norm.weight
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.k_proj.bias
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.k_proj.weight
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.out_proj.bias
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.out_proj.weight
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.q_proj.bias
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.q_proj.weight
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.v_proj.bias
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.v_proj.weight
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn_layer_norm.bias
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn_layer_norm.weight
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.fc1.bias
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.fc1.weight
2022-03-31 11:22:52,663 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.fc2.bias
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.fc2.weight
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.final_layer_norm.bias
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.final_layer_norm.weight
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.k_proj.bias
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.k_proj.weight
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.out_proj.bias
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.out_proj.weight
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.q_proj.bias
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.q_proj.weight
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.v_proj.bias
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.v_proj.weight
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn_layer_norm.bias
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn_layer_norm.weight
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.fc1.bias
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.fc1.weight
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.fc2.bias
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.fc2.weight
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.final_layer_norm.bias
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.final_layer_norm.weight
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.k_proj.bias
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.k_proj.weight
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.out_proj.bias
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.out_proj.weight
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.q_proj.bias
2022-03-31 11:22:52,664 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.q_proj.weight
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.v_proj.bias
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.v_proj.weight
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn_layer_norm.bias
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn_layer_norm.weight
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.fc1.bias
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.fc1.weight
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.fc2.bias
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.fc2.weight
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.final_layer_norm.bias
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.final_layer_norm.weight
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.k_proj.bias
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.k_proj.weight
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.out_proj.bias
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.out_proj.weight
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.q_proj.bias
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.q_proj.weight
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.v_proj.bias
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.v_proj.weight
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn_layer_norm.bias
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn_layer_norm.weight
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.fc1.bias
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.fc1.weight
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.fc2.bias
2022-03-31 11:22:52,665 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.fc2.weight
2022-03-31 11:22:52,666 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.final_layer_norm.bias
2022-03-31 11:22:52,666 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.final_layer_norm.weight
2022-03-31 11:22:52,666 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.k_proj.bias
2022-03-31 11:22:52,666 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.k_proj.weight
2022-03-31 11:22:52,666 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.out_proj.bias
2022-03-31 11:22:52,666 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.out_proj.weight
2022-03-31 11:22:52,666 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.q_proj.bias
2022-03-31 11:22:52,666 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.q_proj.weight
2022-03-31 11:22:52,666 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.v_proj.bias
2022-03-31 11:22:52,666 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.v_proj.weight
2022-03-31 11:22:52,666 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn_layer_norm.bias
2022-03-31 11:22:52,666 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn_layer_norm.weight
2022-03-31 11:22:52,666 - INFO - allennlp.nn.initializers -    _seq2seq.model.shared.weight
2022-03-31 11:22:53,083 - WARNING - allennlp.data.vocabulary - vocabulary serialization directory ./output_decomposition/vocabulary is not empty
2022-03-31 11:22:53,083 - INFO - filelock - Lock 139933520414672 acquired on ./output_decomposition/vocabulary/.lock
2022-03-31 11:22:53,083 - INFO - filelock - Lock 139933520414672 released on ./output_decomposition/vocabulary/.lock
2022-03-31 11:22:53,083 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader
2022-03-31 11:22:53,084 - INFO - allennlp.common.params - data_loader.batch_size = 1
2022-03-31 11:22:53,084 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-31 11:22:53,084 - INFO - allennlp.common.params - data_loader.sampler = None
2022-03-31 11:22:53,084 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-31 11:22:53,084 - INFO - allennlp.common.params - data_loader.pin_memory = False
2022-03-31 11:22:53,084 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-31 11:22:53,084 - INFO - allennlp.common.params - data_loader.timeout = 0
2022-03-31 11:22:53,084 - INFO - allennlp.common.params - data_loader.worker_init_fn = None
2022-03-31 11:22:53,084 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None
2022-03-31 11:22:53,084 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-31 11:22:53,084 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-31 11:22:53,085 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 2
2022-03-31 11:22:53,085 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-31 11:22:53,085 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-31 11:22:53,085 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-31 11:22:53,088 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader
2022-03-31 11:22:53,089 - INFO - allennlp.common.params - data_loader.batch_size = 1
2022-03-31 11:22:53,089 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-31 11:22:53,089 - INFO - allennlp.common.params - data_loader.sampler = None
2022-03-31 11:22:53,089 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-31 11:22:53,089 - INFO - allennlp.common.params - data_loader.pin_memory = False
2022-03-31 11:22:53,089 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-31 11:22:53,089 - INFO - allennlp.common.params - data_loader.timeout = 0
2022-03-31 11:22:53,089 - INFO - allennlp.common.params - data_loader.worker_init_fn = None
2022-03-31 11:22:53,089 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None
2022-03-31 11:22:53,089 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-31 11:22:53,089 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-31 11:22:53,090 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 2
2022-03-31 11:22:53,090 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-31 11:22:53,090 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-31 11:22:53,090 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-31 11:22:53,090 - INFO - allennlp.common.params - trainer.type = gradient_descent
2022-03-31 11:22:53,090 - INFO - allennlp.common.params - trainer.patience = None
2022-03-31 11:22:53,090 - INFO - allennlp.common.params - trainer.validation_metric = +SARI
2022-03-31 11:22:53,090 - INFO - allennlp.common.params - trainer.num_epochs = 15
2022-03-31 11:22:53,091 - INFO - allennlp.common.params - trainer.cuda_device = 0
2022-03-31 11:22:53,091 - INFO - allennlp.common.params - trainer.grad_norm = None
2022-03-31 11:22:53,091 - INFO - allennlp.common.params - trainer.grad_clipping = None
2022-03-31 11:22:53,091 - INFO - allennlp.common.params - trainer.distributed = False
2022-03-31 11:22:53,091 - INFO - allennlp.common.params - trainer.world_size = 1
2022-03-31 11:22:53,091 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 16
2022-03-31 11:22:53,091 - INFO - allennlp.common.params - trainer.use_amp = False
2022-03-31 11:22:53,091 - INFO - allennlp.common.params - trainer.no_grad = None
2022-03-31 11:22:53,091 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2022-03-31 11:22:53,091 - INFO - allennlp.common.params - trainer.tensorboard_writer = <allennlp.common.lazy.Lazy object at 0x7f4461803f90>
2022-03-31 11:22:53,091 - INFO - allennlp.common.params - trainer.moving_average = None
2022-03-31 11:22:53,091 - INFO - allennlp.common.params - trainer.batch_callbacks = None
2022-03-31 11:22:53,092 - INFO - allennlp.common.params - trainer.epoch_callbacks = None
2022-03-31 11:22:53,092 - INFO - allennlp.common.params - trainer.end_callbacks = None
2022-03-31 11:22:53,092 - INFO - allennlp.common.params - trainer.trainer_callbacks = None
2022-03-31 11:22:57,443 - INFO - allennlp.common.params - trainer.optimizer.type = huggingface_adamw
2022-03-31 11:22:57,443 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups = None
2022-03-31 11:22:57,443 - INFO - allennlp.common.params - trainer.optimizer.lr = 3e-05
2022-03-31 11:22:57,444 - INFO - allennlp.common.params - trainer.optimizer.betas = [0.9, 0.999]
2022-03-31 11:22:57,444 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08
2022-03-31 11:22:57,444 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.0
2022-03-31 11:22:57,444 - INFO - allennlp.common.params - trainer.optimizer.correct_bias = True
2022-03-31 11:22:57,444 - INFO - allennlp.training.optimizers - Number of trainable parameters: 406291456
2022-03-31 11:22:57,447 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2022-03-31 11:22:57,449 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2022-03-31 11:22:57,450 - INFO - allennlp.common.util - _seq2seq.model.shared.weight
2022-03-31 11:22:57,450 - INFO - allennlp.common.util - _seq2seq.model.encoder.embed_positions.weight
2022-03-31 11:22:57,450 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.k_proj.weight
2022-03-31 11:22:57,450 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.k_proj.bias
2022-03-31 11:22:57,450 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.v_proj.weight
2022-03-31 11:22:57,450 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.v_proj.bias
2022-03-31 11:22:57,450 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.q_proj.weight
2022-03-31 11:22:57,450 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.q_proj.bias
2022-03-31 11:22:57,450 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.out_proj.weight
2022-03-31 11:22:57,450 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.out_proj.bias
2022-03-31 11:22:57,450 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn_layer_norm.weight
2022-03-31 11:22:57,450 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn_layer_norm.bias
2022-03-31 11:22:57,450 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.fc1.weight
2022-03-31 11:22:57,450 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.fc1.bias
2022-03-31 11:22:57,450 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.fc2.weight
2022-03-31 11:22:57,450 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.fc2.bias
2022-03-31 11:22:57,450 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.final_layer_norm.weight
2022-03-31 11:22:57,450 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.final_layer_norm.bias
2022-03-31 11:22:57,450 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.k_proj.weight
2022-03-31 11:22:57,451 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.k_proj.bias
2022-03-31 11:22:57,451 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.v_proj.weight
2022-03-31 11:22:57,451 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.v_proj.bias
2022-03-31 11:22:57,451 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.q_proj.weight
2022-03-31 11:22:57,451 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.q_proj.bias
2022-03-31 11:22:57,451 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.out_proj.weight
2022-03-31 11:22:57,451 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.out_proj.bias
2022-03-31 11:22:57,451 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn_layer_norm.weight
2022-03-31 11:22:57,451 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn_layer_norm.bias
2022-03-31 11:22:57,451 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.fc1.weight
2022-03-31 11:22:57,451 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.fc1.bias
2022-03-31 11:22:57,451 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.fc2.weight
2022-03-31 11:22:57,451 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.fc2.bias
2022-03-31 11:22:57,451 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.final_layer_norm.weight
2022-03-31 11:22:57,451 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.final_layer_norm.bias
2022-03-31 11:22:57,451 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.k_proj.weight
2022-03-31 11:22:57,451 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.k_proj.bias
2022-03-31 11:22:57,451 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.v_proj.weight
2022-03-31 11:22:57,451 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.v_proj.bias
2022-03-31 11:22:57,451 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.q_proj.weight
2022-03-31 11:22:57,452 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.q_proj.bias
2022-03-31 11:22:57,452 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.out_proj.weight
2022-03-31 11:22:57,452 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.out_proj.bias
2022-03-31 11:22:57,452 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn_layer_norm.weight
2022-03-31 11:22:57,452 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn_layer_norm.bias
2022-03-31 11:22:57,452 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.fc1.weight
2022-03-31 11:22:57,452 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.fc1.bias
2022-03-31 11:22:57,452 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.fc2.weight
2022-03-31 11:22:57,452 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.fc2.bias
2022-03-31 11:22:57,452 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.final_layer_norm.weight
2022-03-31 11:22:57,452 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.final_layer_norm.bias
2022-03-31 11:22:57,452 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.k_proj.weight
2022-03-31 11:22:57,452 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.k_proj.bias
2022-03-31 11:22:57,452 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.v_proj.weight
2022-03-31 11:22:57,452 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.v_proj.bias
2022-03-31 11:22:57,452 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.q_proj.weight
2022-03-31 11:22:57,452 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.q_proj.bias
2022-03-31 11:22:57,452 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.out_proj.weight
2022-03-31 11:22:57,452 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.out_proj.bias
2022-03-31 11:22:57,452 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn_layer_norm.weight
2022-03-31 11:22:57,453 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn_layer_norm.bias
2022-03-31 11:22:57,453 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.fc1.weight
2022-03-31 11:22:57,453 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.fc1.bias
2022-03-31 11:22:57,453 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.fc2.weight
2022-03-31 11:22:57,453 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.fc2.bias
2022-03-31 11:22:57,453 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.final_layer_norm.weight
2022-03-31 11:22:57,453 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.final_layer_norm.bias
2022-03-31 11:22:57,453 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.k_proj.weight
2022-03-31 11:22:57,453 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.k_proj.bias
2022-03-31 11:22:57,453 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.v_proj.weight
2022-03-31 11:22:57,453 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.v_proj.bias
2022-03-31 11:22:57,453 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.q_proj.weight
2022-03-31 11:22:57,453 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.q_proj.bias
2022-03-31 11:22:57,453 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.out_proj.weight
2022-03-31 11:22:57,453 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.out_proj.bias
2022-03-31 11:22:57,453 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn_layer_norm.weight
2022-03-31 11:22:57,453 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn_layer_norm.bias
2022-03-31 11:22:57,453 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.fc1.weight
2022-03-31 11:22:57,453 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.fc1.bias
2022-03-31 11:22:57,453 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.fc2.weight
2022-03-31 11:22:57,454 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.fc2.bias
2022-03-31 11:22:57,454 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.final_layer_norm.weight
2022-03-31 11:22:57,454 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.final_layer_norm.bias
2022-03-31 11:22:57,454 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.k_proj.weight
2022-03-31 11:22:57,454 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.k_proj.bias
2022-03-31 11:22:57,454 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.v_proj.weight
2022-03-31 11:22:57,454 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.v_proj.bias
2022-03-31 11:22:57,454 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.q_proj.weight
2022-03-31 11:22:57,454 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.q_proj.bias
2022-03-31 11:22:57,454 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.out_proj.weight
2022-03-31 11:22:57,454 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.out_proj.bias
2022-03-31 11:22:57,454 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn_layer_norm.weight
2022-03-31 11:22:57,454 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn_layer_norm.bias
2022-03-31 11:22:57,454 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.fc1.weight
2022-03-31 11:22:57,454 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.fc1.bias
2022-03-31 11:22:57,454 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.fc2.weight
2022-03-31 11:22:57,454 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.fc2.bias
2022-03-31 11:22:57,454 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.final_layer_norm.weight
2022-03-31 11:22:57,454 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.final_layer_norm.bias
2022-03-31 11:22:57,454 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.k_proj.weight
2022-03-31 11:22:57,455 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.k_proj.bias
2022-03-31 11:22:57,455 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.v_proj.weight
2022-03-31 11:22:57,455 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.v_proj.bias
2022-03-31 11:22:57,455 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.q_proj.weight
2022-03-31 11:22:57,455 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.q_proj.bias
2022-03-31 11:22:57,455 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.out_proj.weight
2022-03-31 11:22:57,455 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.out_proj.bias
2022-03-31 11:22:57,455 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn_layer_norm.weight
2022-03-31 11:22:57,455 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn_layer_norm.bias
2022-03-31 11:22:57,455 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.fc1.weight
2022-03-31 11:22:57,455 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.fc1.bias
2022-03-31 11:22:57,455 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.fc2.weight
2022-03-31 11:22:57,455 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.fc2.bias
2022-03-31 11:22:57,455 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.final_layer_norm.weight
2022-03-31 11:22:57,455 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.final_layer_norm.bias
2022-03-31 11:22:57,455 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.k_proj.weight
2022-03-31 11:22:57,455 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.k_proj.bias
2022-03-31 11:22:57,455 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.v_proj.weight
2022-03-31 11:22:57,455 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.v_proj.bias
2022-03-31 11:22:57,455 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.q_proj.weight
2022-03-31 11:22:57,455 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.q_proj.bias
2022-03-31 11:22:57,456 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.out_proj.weight
2022-03-31 11:22:57,456 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.out_proj.bias
2022-03-31 11:22:57,456 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn_layer_norm.weight
2022-03-31 11:22:57,456 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn_layer_norm.bias
2022-03-31 11:22:57,456 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.fc1.weight
2022-03-31 11:22:57,456 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.fc1.bias
2022-03-31 11:22:57,456 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.fc2.weight
2022-03-31 11:22:57,456 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.fc2.bias
2022-03-31 11:22:57,456 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.final_layer_norm.weight
2022-03-31 11:22:57,456 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.final_layer_norm.bias
2022-03-31 11:22:57,456 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.k_proj.weight
2022-03-31 11:22:57,456 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.k_proj.bias
2022-03-31 11:22:57,456 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.v_proj.weight
2022-03-31 11:22:57,456 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.v_proj.bias
2022-03-31 11:22:57,456 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.q_proj.weight
2022-03-31 11:22:57,456 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.q_proj.bias
2022-03-31 11:22:57,456 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.out_proj.weight
2022-03-31 11:22:57,456 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.out_proj.bias
2022-03-31 11:22:57,456 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn_layer_norm.weight
2022-03-31 11:22:57,456 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn_layer_norm.bias
2022-03-31 11:22:57,456 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.fc1.weight
2022-03-31 11:22:57,457 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.fc1.bias
2022-03-31 11:22:57,457 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.fc2.weight
2022-03-31 11:22:57,457 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.fc2.bias
2022-03-31 11:22:57,457 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.final_layer_norm.weight
2022-03-31 11:22:57,457 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.final_layer_norm.bias
2022-03-31 11:22:57,457 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.k_proj.weight
2022-03-31 11:22:57,457 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.k_proj.bias
2022-03-31 11:22:57,457 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.v_proj.weight
2022-03-31 11:22:57,457 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.v_proj.bias
2022-03-31 11:22:57,457 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.q_proj.weight
2022-03-31 11:22:57,457 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.q_proj.bias
2022-03-31 11:22:57,457 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.out_proj.weight
2022-03-31 11:22:57,457 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.out_proj.bias
2022-03-31 11:22:57,457 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn_layer_norm.weight
2022-03-31 11:22:57,457 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn_layer_norm.bias
2022-03-31 11:22:57,457 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.fc1.weight
2022-03-31 11:22:57,457 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.fc1.bias
2022-03-31 11:22:57,457 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.fc2.weight
2022-03-31 11:22:57,457 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.fc2.bias
2022-03-31 11:22:57,457 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.final_layer_norm.weight
2022-03-31 11:22:57,458 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.final_layer_norm.bias
2022-03-31 11:22:57,458 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.k_proj.weight
2022-03-31 11:22:57,458 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.k_proj.bias
2022-03-31 11:22:57,458 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.v_proj.weight
2022-03-31 11:22:57,458 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.v_proj.bias
2022-03-31 11:22:57,458 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.q_proj.weight
2022-03-31 11:22:57,458 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.q_proj.bias
2022-03-31 11:22:57,458 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.out_proj.weight
2022-03-31 11:22:57,458 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.out_proj.bias
2022-03-31 11:22:57,458 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn_layer_norm.weight
2022-03-31 11:22:57,458 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn_layer_norm.bias
2022-03-31 11:22:57,458 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.fc1.weight
2022-03-31 11:22:57,458 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.fc1.bias
2022-03-31 11:22:57,458 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.fc2.weight
2022-03-31 11:22:57,458 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.fc2.bias
2022-03-31 11:22:57,458 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.final_layer_norm.weight
2022-03-31 11:22:57,458 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.final_layer_norm.bias
2022-03-31 11:22:57,458 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.k_proj.weight
2022-03-31 11:22:57,458 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.k_proj.bias
2022-03-31 11:22:57,458 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.v_proj.weight
2022-03-31 11:22:57,458 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.v_proj.bias
2022-03-31 11:22:57,459 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.q_proj.weight
2022-03-31 11:22:57,459 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.q_proj.bias
2022-03-31 11:22:57,459 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.out_proj.weight
2022-03-31 11:22:57,459 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.out_proj.bias
2022-03-31 11:22:57,459 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn_layer_norm.weight
2022-03-31 11:22:57,459 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn_layer_norm.bias
2022-03-31 11:22:57,459 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.fc1.weight
2022-03-31 11:22:57,459 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.fc1.bias
2022-03-31 11:22:57,459 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.fc2.weight
2022-03-31 11:22:57,459 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.fc2.bias
2022-03-31 11:22:57,459 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.final_layer_norm.weight
2022-03-31 11:22:57,459 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.final_layer_norm.bias
2022-03-31 11:22:57,459 - INFO - allennlp.common.util - _seq2seq.model.encoder.layernorm_embedding.weight
2022-03-31 11:22:57,459 - INFO - allennlp.common.util - _seq2seq.model.encoder.layernorm_embedding.bias
2022-03-31 11:22:57,459 - INFO - allennlp.common.util - _seq2seq.model.decoder.embed_positions.weight
2022-03-31 11:22:57,459 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.k_proj.weight
2022-03-31 11:22:57,459 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.k_proj.bias
2022-03-31 11:22:57,459 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.v_proj.weight
2022-03-31 11:22:57,459 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.v_proj.bias
2022-03-31 11:22:57,460 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.q_proj.weight
2022-03-31 11:22:57,460 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.q_proj.bias
2022-03-31 11:22:57,460 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.out_proj.weight
2022-03-31 11:22:57,460 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.out_proj.bias
2022-03-31 11:22:57,460 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn_layer_norm.weight
2022-03-31 11:22:57,460 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn_layer_norm.bias
2022-03-31 11:22:57,460 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.k_proj.weight
2022-03-31 11:22:57,460 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.k_proj.bias
2022-03-31 11:22:57,460 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.v_proj.weight
2022-03-31 11:22:57,460 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.v_proj.bias
2022-03-31 11:22:57,460 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.q_proj.weight
2022-03-31 11:22:57,460 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.q_proj.bias
2022-03-31 11:22:57,460 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.out_proj.weight
2022-03-31 11:22:57,460 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.out_proj.bias
2022-03-31 11:22:57,460 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn_layer_norm.weight
2022-03-31 11:22:57,460 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn_layer_norm.bias
2022-03-31 11:22:57,460 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.fc1.weight
2022-03-31 11:22:57,460 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.fc1.bias
2022-03-31 11:22:57,460 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.fc2.weight
2022-03-31 11:22:57,460 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.fc2.bias
2022-03-31 11:22:57,461 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.final_layer_norm.weight
2022-03-31 11:22:57,461 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.final_layer_norm.bias
2022-03-31 11:22:57,461 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.k_proj.weight
2022-03-31 11:22:57,461 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.k_proj.bias
2022-03-31 11:22:57,461 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.v_proj.weight
2022-03-31 11:22:57,461 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.v_proj.bias
2022-03-31 11:22:57,461 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.q_proj.weight
2022-03-31 11:22:57,461 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.q_proj.bias
2022-03-31 11:22:57,461 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.out_proj.weight
2022-03-31 11:22:57,461 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.out_proj.bias
2022-03-31 11:22:57,461 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn_layer_norm.weight
2022-03-31 11:22:57,461 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn_layer_norm.bias
2022-03-31 11:22:57,461 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.k_proj.weight
2022-03-31 11:22:57,461 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.k_proj.bias
2022-03-31 11:22:57,461 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.v_proj.weight
2022-03-31 11:22:57,461 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.v_proj.bias
2022-03-31 11:22:57,461 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.q_proj.weight
2022-03-31 11:22:57,461 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.q_proj.bias
2022-03-31 11:22:57,462 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.out_proj.weight
2022-03-31 11:22:57,462 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.out_proj.bias
2022-03-31 11:22:57,462 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn_layer_norm.weight
2022-03-31 11:22:57,462 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn_layer_norm.bias
2022-03-31 11:22:57,462 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.fc1.weight
2022-03-31 11:22:57,462 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.fc1.bias
2022-03-31 11:22:57,462 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.fc2.weight
2022-03-31 11:22:57,462 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.fc2.bias
2022-03-31 11:22:57,462 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.final_layer_norm.weight
2022-03-31 11:22:57,462 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.final_layer_norm.bias
2022-03-31 11:22:57,462 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.k_proj.weight
2022-03-31 11:22:57,462 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.k_proj.bias
2022-03-31 11:22:57,462 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.v_proj.weight
2022-03-31 11:22:57,462 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.v_proj.bias
2022-03-31 11:22:57,462 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.q_proj.weight
2022-03-31 11:22:57,462 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.q_proj.bias
2022-03-31 11:22:57,462 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.out_proj.weight
2022-03-31 11:22:57,462 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.out_proj.bias
2022-03-31 11:22:57,462 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn_layer_norm.weight
2022-03-31 11:22:57,462 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn_layer_norm.bias
2022-03-31 11:22:57,463 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.k_proj.weight
2022-03-31 11:22:57,463 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.k_proj.bias
2022-03-31 11:22:57,463 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.v_proj.weight
2022-03-31 11:22:57,463 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.v_proj.bias
2022-03-31 11:22:57,463 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.q_proj.weight
2022-03-31 11:22:57,463 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.q_proj.bias
2022-03-31 11:22:57,463 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.out_proj.weight
2022-03-31 11:22:57,463 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.out_proj.bias
2022-03-31 11:22:57,463 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn_layer_norm.weight
2022-03-31 11:22:57,463 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn_layer_norm.bias
2022-03-31 11:22:57,463 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.fc1.weight
2022-03-31 11:22:57,463 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.fc1.bias
2022-03-31 11:22:57,463 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.fc2.weight
2022-03-31 11:22:57,463 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.fc2.bias
2022-03-31 11:22:57,463 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.final_layer_norm.weight
2022-03-31 11:22:57,463 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.final_layer_norm.bias
2022-03-31 11:22:57,463 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.k_proj.weight
2022-03-31 11:22:57,464 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.k_proj.bias
2022-03-31 11:22:57,464 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.v_proj.weight
2022-03-31 11:22:57,464 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.v_proj.bias
2022-03-31 11:22:57,464 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.q_proj.weight
2022-03-31 11:22:57,464 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.q_proj.bias
2022-03-31 11:22:57,464 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.out_proj.weight
2022-03-31 11:22:57,464 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.out_proj.bias
2022-03-31 11:22:57,464 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn_layer_norm.weight
2022-03-31 11:22:57,464 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn_layer_norm.bias
2022-03-31 11:22:57,464 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.k_proj.weight
2022-03-31 11:22:57,464 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.k_proj.bias
2022-03-31 11:22:57,464 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.v_proj.weight
2022-03-31 11:22:57,465 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.v_proj.bias
2022-03-31 11:22:57,465 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.q_proj.weight
2022-03-31 11:22:57,465 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.q_proj.bias
2022-03-31 11:22:57,465 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.out_proj.weight
2022-03-31 11:22:57,465 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.out_proj.bias
2022-03-31 11:22:57,465 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn_layer_norm.weight
2022-03-31 11:22:57,465 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn_layer_norm.bias
2022-03-31 11:22:57,465 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.fc1.weight
2022-03-31 11:22:57,465 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.fc1.bias
2022-03-31 11:22:57,465 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.fc2.weight
2022-03-31 11:22:57,465 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.fc2.bias
2022-03-31 11:22:57,465 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.final_layer_norm.weight
2022-03-31 11:22:57,466 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.final_layer_norm.bias
2022-03-31 11:22:57,466 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.k_proj.weight
2022-03-31 11:22:57,466 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.k_proj.bias
2022-03-31 11:22:57,466 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.v_proj.weight
2022-03-31 11:22:57,466 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.v_proj.bias
2022-03-31 11:22:57,466 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.q_proj.weight
2022-03-31 11:22:57,466 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.q_proj.bias
2022-03-31 11:22:57,466 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.out_proj.weight
2022-03-31 11:22:57,466 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.out_proj.bias
2022-03-31 11:22:57,466 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn_layer_norm.weight
2022-03-31 11:22:57,466 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn_layer_norm.bias
2022-03-31 11:22:57,467 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.k_proj.weight
2022-03-31 11:22:57,467 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.k_proj.bias
2022-03-31 11:22:57,467 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.v_proj.weight
2022-03-31 11:22:57,467 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.v_proj.bias
2022-03-31 11:22:57,467 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.q_proj.weight
2022-03-31 11:22:57,467 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.q_proj.bias
2022-03-31 11:22:57,467 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.out_proj.weight
2022-03-31 11:22:57,467 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.out_proj.bias
2022-03-31 11:22:57,467 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn_layer_norm.weight
2022-03-31 11:22:57,467 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn_layer_norm.bias
2022-03-31 11:22:57,467 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.fc1.weight
2022-03-31 11:22:57,467 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.fc1.bias
2022-03-31 11:22:57,468 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.fc2.weight
2022-03-31 11:22:57,468 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.fc2.bias
2022-03-31 11:22:57,468 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.final_layer_norm.weight
2022-03-31 11:22:57,468 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.final_layer_norm.bias
2022-03-31 11:22:57,468 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.k_proj.weight
2022-03-31 11:22:57,468 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.k_proj.bias
2022-03-31 11:22:57,468 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.v_proj.weight
2022-03-31 11:22:57,468 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.v_proj.bias
2022-03-31 11:22:57,468 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.q_proj.weight
2022-03-31 11:22:57,468 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.q_proj.bias
2022-03-31 11:22:57,468 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.out_proj.weight
2022-03-31 11:22:57,469 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.out_proj.bias
2022-03-31 11:22:57,469 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn_layer_norm.weight
2022-03-31 11:22:57,469 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn_layer_norm.bias
2022-03-31 11:22:57,469 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.k_proj.weight
2022-03-31 11:22:57,469 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.k_proj.bias
2022-03-31 11:22:57,469 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.v_proj.weight
2022-03-31 11:22:57,469 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.v_proj.bias
2022-03-31 11:22:57,469 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.q_proj.weight
2022-03-31 11:22:57,469 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.q_proj.bias
2022-03-31 11:22:57,469 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.out_proj.weight
2022-03-31 11:22:57,469 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.out_proj.bias
2022-03-31 11:22:57,469 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn_layer_norm.weight
2022-03-31 11:22:57,470 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn_layer_norm.bias
2022-03-31 11:22:57,470 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.fc1.weight
2022-03-31 11:22:57,470 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.fc1.bias
2022-03-31 11:22:57,470 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.fc2.weight
2022-03-31 11:22:57,470 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.fc2.bias
2022-03-31 11:22:57,470 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.final_layer_norm.weight
2022-03-31 11:22:57,470 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.final_layer_norm.bias
2022-03-31 11:22:57,470 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.k_proj.weight
2022-03-31 11:22:57,470 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.k_proj.bias
2022-03-31 11:22:57,470 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.v_proj.weight
2022-03-31 11:22:57,470 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.v_proj.bias
2022-03-31 11:22:57,471 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.q_proj.weight
2022-03-31 11:22:57,471 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.q_proj.bias
2022-03-31 11:22:57,471 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.out_proj.weight
2022-03-31 11:22:57,471 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.out_proj.bias
2022-03-31 11:22:57,471 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn_layer_norm.weight
2022-03-31 11:22:57,471 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn_layer_norm.bias
2022-03-31 11:22:57,471 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.k_proj.weight
2022-03-31 11:22:57,471 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.k_proj.bias
2022-03-31 11:22:57,471 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.v_proj.weight
2022-03-31 11:22:57,471 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.v_proj.bias
2022-03-31 11:22:57,471 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.q_proj.weight
2022-03-31 11:22:57,472 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.q_proj.bias
2022-03-31 11:22:57,472 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.out_proj.weight
2022-03-31 11:22:57,472 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.out_proj.bias
2022-03-31 11:22:57,472 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn_layer_norm.weight
2022-03-31 11:22:57,472 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn_layer_norm.bias
2022-03-31 11:22:57,472 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.fc1.weight
2022-03-31 11:22:57,472 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.fc1.bias
2022-03-31 11:22:57,472 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.fc2.weight
2022-03-31 11:22:57,472 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.fc2.bias
2022-03-31 11:22:57,472 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.final_layer_norm.weight
2022-03-31 11:22:57,472 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.final_layer_norm.bias
2022-03-31 11:22:57,472 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.k_proj.weight
2022-03-31 11:22:57,473 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.k_proj.bias
2022-03-31 11:22:57,473 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.v_proj.weight
2022-03-31 11:22:57,473 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.v_proj.bias
2022-03-31 11:22:57,473 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.q_proj.weight
2022-03-31 11:22:57,473 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.q_proj.bias
2022-03-31 11:22:57,473 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.out_proj.weight
2022-03-31 11:22:57,473 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.out_proj.bias
2022-03-31 11:22:57,473 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn_layer_norm.weight
2022-03-31 11:22:57,473 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn_layer_norm.bias
2022-03-31 11:22:57,473 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.k_proj.weight
2022-03-31 11:22:57,473 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.k_proj.bias
2022-03-31 11:22:57,474 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.v_proj.weight
2022-03-31 11:22:57,474 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.v_proj.bias
2022-03-31 11:22:57,474 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.q_proj.weight
2022-03-31 11:22:57,474 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.q_proj.bias
2022-03-31 11:22:57,474 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.out_proj.weight
2022-03-31 11:22:57,474 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.out_proj.bias
2022-03-31 11:22:57,474 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn_layer_norm.weight
2022-03-31 11:22:57,474 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn_layer_norm.bias
2022-03-31 11:22:57,474 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.fc1.weight
2022-03-31 11:22:57,474 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.fc1.bias
2022-03-31 11:22:57,474 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.fc2.weight
2022-03-31 11:22:57,474 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.fc2.bias
2022-03-31 11:22:57,474 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.final_layer_norm.weight
2022-03-31 11:22:57,475 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.final_layer_norm.bias
2022-03-31 11:22:57,475 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.k_proj.weight
2022-03-31 11:22:57,475 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.k_proj.bias
2022-03-31 11:22:57,475 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.v_proj.weight
2022-03-31 11:22:57,475 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.v_proj.bias
2022-03-31 11:22:57,475 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.q_proj.weight
2022-03-31 11:22:57,475 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.q_proj.bias
2022-03-31 11:22:57,475 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.out_proj.weight
2022-03-31 11:22:57,475 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.out_proj.bias
2022-03-31 11:22:57,475 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn_layer_norm.weight
2022-03-31 11:22:57,475 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn_layer_norm.bias
2022-03-31 11:22:57,476 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.k_proj.weight
2022-03-31 11:22:57,476 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.k_proj.bias
2022-03-31 11:22:57,476 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.v_proj.weight
2022-03-31 11:22:57,476 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.v_proj.bias
2022-03-31 11:22:57,476 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.q_proj.weight
2022-03-31 11:22:57,476 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.q_proj.bias
2022-03-31 11:22:57,476 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.out_proj.weight
2022-03-31 11:22:57,476 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.out_proj.bias
2022-03-31 11:22:57,476 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn_layer_norm.weight
2022-03-31 11:22:57,476 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn_layer_norm.bias
2022-03-31 11:22:57,476 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.fc1.weight
2022-03-31 11:22:57,477 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.fc1.bias
2022-03-31 11:22:57,477 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.fc2.weight
2022-03-31 11:22:57,477 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.fc2.bias
2022-03-31 11:22:57,477 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.final_layer_norm.weight
2022-03-31 11:22:57,477 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.final_layer_norm.bias
2022-03-31 11:22:57,477 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.k_proj.weight
2022-03-31 11:22:57,477 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.k_proj.bias
2022-03-31 11:22:57,477 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.v_proj.weight
2022-03-31 11:22:57,477 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.v_proj.bias
2022-03-31 11:22:57,477 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.q_proj.weight
2022-03-31 11:22:57,477 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.q_proj.bias
2022-03-31 11:22:57,477 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.out_proj.weight
2022-03-31 11:22:57,477 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.out_proj.bias
2022-03-31 11:22:57,478 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn_layer_norm.weight
2022-03-31 11:22:57,478 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn_layer_norm.bias
2022-03-31 11:22:57,478 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.k_proj.weight
2022-03-31 11:22:57,478 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.k_proj.bias
2022-03-31 11:22:57,478 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.v_proj.weight
2022-03-31 11:22:57,478 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.v_proj.bias
2022-03-31 11:22:57,478 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.q_proj.weight
2022-03-31 11:22:57,478 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.q_proj.bias
2022-03-31 11:22:57,478 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.out_proj.weight
2022-03-31 11:22:57,478 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.out_proj.bias
2022-03-31 11:22:57,478 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn_layer_norm.weight
2022-03-31 11:22:57,478 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn_layer_norm.bias
2022-03-31 11:22:57,479 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.fc1.weight
2022-03-31 11:22:57,479 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.fc1.bias
2022-03-31 11:22:57,479 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.fc2.weight
2022-03-31 11:22:57,479 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.fc2.bias
2022-03-31 11:22:57,479 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.final_layer_norm.weight
2022-03-31 11:22:57,479 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.final_layer_norm.bias
2022-03-31 11:22:57,479 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.k_proj.weight
2022-03-31 11:22:57,479 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.k_proj.bias
2022-03-31 11:22:57,479 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.v_proj.weight
2022-03-31 11:22:57,479 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.v_proj.bias
2022-03-31 11:22:57,479 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.q_proj.weight
2022-03-31 11:22:57,479 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.q_proj.bias
2022-03-31 11:22:57,480 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.out_proj.weight
2022-03-31 11:22:57,480 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.out_proj.bias
2022-03-31 11:22:57,480 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn_layer_norm.weight
2022-03-31 11:22:57,480 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn_layer_norm.bias
2022-03-31 11:22:57,480 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.k_proj.weight
2022-03-31 11:22:57,480 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.k_proj.bias
2022-03-31 11:22:57,480 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.v_proj.weight
2022-03-31 11:22:57,480 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.v_proj.bias
2022-03-31 11:22:57,480 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.q_proj.weight
2022-03-31 11:22:57,480 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.q_proj.bias
2022-03-31 11:22:57,480 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.out_proj.weight
2022-03-31 11:22:57,480 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.out_proj.bias
2022-03-31 11:22:57,481 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn_layer_norm.weight
2022-03-31 11:22:57,481 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn_layer_norm.bias
2022-03-31 11:22:57,481 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.fc1.weight
2022-03-31 11:22:57,481 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.fc1.bias
2022-03-31 11:22:57,481 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.fc2.weight
2022-03-31 11:22:57,481 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.fc2.bias
2022-03-31 11:22:57,481 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.final_layer_norm.weight
2022-03-31 11:22:57,481 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.final_layer_norm.bias
2022-03-31 11:22:57,481 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.k_proj.weight
2022-03-31 11:22:57,481 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.k_proj.bias
2022-03-31 11:22:57,481 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.v_proj.weight
2022-03-31 11:22:57,481 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.v_proj.bias
2022-03-31 11:22:57,482 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.q_proj.weight
2022-03-31 11:22:57,482 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.q_proj.bias
2022-03-31 11:22:57,482 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.out_proj.weight
2022-03-31 11:22:57,482 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.out_proj.bias
2022-03-31 11:22:57,482 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn_layer_norm.weight
2022-03-31 11:22:57,482 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn_layer_norm.bias
2022-03-31 11:22:57,482 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.k_proj.weight
2022-03-31 11:22:57,482 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.k_proj.bias
2022-03-31 11:22:57,482 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.v_proj.weight
2022-03-31 11:22:57,482 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.v_proj.bias
2022-03-31 11:22:57,482 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.q_proj.weight
2022-03-31 11:22:57,482 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.q_proj.bias
2022-03-31 11:22:57,483 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.out_proj.weight
2022-03-31 11:22:57,483 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.out_proj.bias
2022-03-31 11:22:57,483 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn_layer_norm.weight
2022-03-31 11:22:57,483 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn_layer_norm.bias
2022-03-31 11:22:57,483 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.fc1.weight
2022-03-31 11:22:57,483 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.fc1.bias
2022-03-31 11:22:57,483 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.fc2.weight
2022-03-31 11:22:57,483 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.fc2.bias
2022-03-31 11:22:57,483 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.final_layer_norm.weight
2022-03-31 11:22:57,483 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.final_layer_norm.bias
2022-03-31 11:22:57,483 - INFO - allennlp.common.util - _seq2seq.model.decoder.layernorm_embedding.weight
2022-03-31 11:22:57,483 - INFO - allennlp.common.util - _seq2seq.model.decoder.layernorm_embedding.bias
2022-03-31 11:22:57,484 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = polynomial_decay
2022-03-31 11:22:57,484 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.power = 1.0
2022-03-31 11:22:57,484 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.warmup_steps = 0
2022-03-31 11:22:57,484 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.end_learning_rate = 0.0
2022-03-31 11:22:57,484 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.last_epoch = -1
2022-03-31 11:22:57,485 - INFO - allennlp.common.params - trainer.checkpointer.type = default
2022-03-31 11:22:57,485 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None
2022-03-31 11:22:57,485 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = -1
2022-03-31 11:22:57,485 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None
2022-03-31 11:22:57,485 - INFO - allennlp.common.params - summary_interval = 100
2022-03-31 11:22:57,485 - INFO - allennlp.common.params - histogram_interval = None
2022-03-31 11:22:57,485 - INFO - allennlp.common.params - batch_size_interval = None
2022-03-31 11:22:57,486 - INFO - allennlp.common.params - should_log_parameter_statistics = True
2022-03-31 11:22:57,486 - INFO - allennlp.common.params - should_log_learning_rate = False
2022-03-31 11:22:57,486 - INFO - allennlp.common.params - get_batch_num_total = None
2022-03-31 11:22:57,489 - WARNING - allennlp.training.trainer - You provided a validation dataset but patience was set to None, meaning that early stopping is disabled
2022-03-31 11:23:12,636 - INFO - allennlp.training.trainer - Beginning training.
2022-03-31 11:23:12,637 - INFO - allennlp.training.trainer - Epoch 8/14
2022-03-31 11:23:12,637 - INFO - allennlp.training.trainer - Worker 0 memory usage: 12G
2022-03-31 11:23:12,637 - INFO - allennlp.training.trainer - GPU 0 memory usage: 4.5G
2022-03-31 11:23:12,638 - INFO - allennlp.training.trainer - Training
2022-03-31 11:23:12,639 - INFO - tqdm - 0%|          | 0/65 [00:00<?, ?it/s]
2022-03-31 11:23:12,639 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-31 11:23:12,639 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['target_ids'] as the sorting keys
2022-03-31 11:23:22,882 - INFO - tqdm - batch_loss: 0.9797, loss: 1.0296 ||:   9%|9         | 6/65 [00:10<01:40,  1.70s/it]
2022-03-31 11:23:34,526 - INFO - tqdm - batch_loss: 0.9328, loss: 1.0169 ||:  20%|##        | 13/65 [00:21<01:26,  1.66s/it]
2022-03-31 11:23:44,552 - INFO - tqdm - batch_loss: 0.9114, loss: 1.0119 ||:  29%|##9       | 19/65 [00:31<01:16,  1.67s/it]
2022-03-31 11:23:56,164 - INFO - tqdm - batch_loss: 0.9532, loss: 1.0081 ||:  40%|####      | 26/65 [00:43<01:04,  1.66s/it]
2022-03-31 11:24:06,574 - INFO - tqdm - batch_loss: 1.0920, loss: 1.0118 ||:  49%|####9     | 32/65 [00:53<00:57,  1.74s/it]
2022-03-31 11:24:16,590 - INFO - tqdm - batch_loss: 0.9502, loss: 1.0104 ||:  58%|#####8    | 38/65 [01:03<00:45,  1.68s/it]
2022-03-31 11:24:26,760 - INFO - tqdm - batch_loss: 1.0079, loss: 1.0181 ||:  68%|######7   | 44/65 [01:14<00:35,  1.70s/it]
2022-03-31 11:24:36,876 - INFO - tqdm - batch_loss: 0.8680, loss: 1.0099 ||:  77%|#######6  | 50/65 [01:24<00:25,  1.69s/it]
2022-03-31 11:24:47,138 - INFO - tqdm - batch_loss: 1.1425, loss: 1.0163 ||:  86%|########6 | 56/65 [01:34<00:15,  1.70s/it]
2022-03-31 11:24:57,256 - INFO - tqdm - batch_loss: 0.9158, loss: 1.0141 ||:  95%|#########5| 62/65 [01:44<00:05,  1.69s/it]
2022-03-31 11:25:01,511 - INFO - tqdm - batch_loss: 1.1227, loss: 1.0187 ||: 100%|##########| 65/65 [01:48<00:00,  1.44s/it]
2022-03-31 11:25:01,512 - INFO - tqdm - batch_loss: 1.1227, loss: 1.0187 ||: 100%|##########| 65/65 [01:48<00:00,  1.67s/it]
2022-03-31 11:25:02,427 - CRITICAL - root - Uncaught exception
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/torch/serialization.py", line 372, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol)
  File "/opt/conda/lib/python3.7/site-packages/torch/serialization.py", line 493, in _save
    zip_file.write_record(name, buf_value, len(buf_value))
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/allennlp/training/trainer.py", line 966, in train
    return self._try_train()
  File "/opt/conda/lib/python3.7/site-packages/allennlp/training/trainer.py", line 1004, in _try_train
    self._checkpointer.save_checkpoint(epoch, self, save_model_only=True)
  File "/opt/conda/lib/python3.7/site-packages/allennlp/training/checkpointer.py", line 102, in save_checkpoint
    torch.save(model_state, model_path)
  File "/opt/conda/lib/python3.7/site-packages/torch/serialization.py", line 373, in save
    return
  File "/opt/conda/lib/python3.7/site-packages/torch/serialization.py", line 259, in __exit__
    self.file_like.write_end_of_file()
RuntimeError: [enforce fail at inline_container.cc:274] . unexpected pos 499984256 vs 499984144

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "run_scripts/train.py", line 100, in <module>
    main()
  File "run_scripts/train.py", line 96, in main
    return run(args)
  File "run_scripts/train.py", line 69, in run
    run_main()
  File "/home/jupyter/src/strategyqa/run_scripts/run.py", line 53, in main
    run(args)
  File "/home/jupyter/src/strategyqa/run_scripts/run.py", line 45, in run
    allennlp_main()
  File "/opt/conda/lib/python3.7/site-packages/allennlp/commands/__init__.py", line 118, in main
    args.func(args)
  File "/opt/conda/lib/python3.7/site-packages/allennlp/commands/train.py", line 119, in train_model_from_args
    file_friendly_logging=args.file_friendly_logging,
  File "/opt/conda/lib/python3.7/site-packages/allennlp/commands/train.py", line 178, in train_model_from_file
    file_friendly_logging=file_friendly_logging,
  File "/opt/conda/lib/python3.7/site-packages/allennlp/commands/train.py", line 242, in train_model
    file_friendly_logging=file_friendly_logging,
  File "/opt/2022-03-31 11:32:27,831 - INFO - allennlp.common.params - random_seed = 42
2022-03-31 11:32:27,832 - INFO - allennlp.common.params - numpy_seed = 42
2022-03-31 11:32:27,832 - INFO - allennlp.common.params - pytorch_seed = 42
2022-03-31 11:32:28,499 - INFO - allennlp.common.checks - Pytorch version: 1.7.1
2022-03-31 11:32:28,499 - INFO - allennlp.common.params - type = default
2022-03-31 11:32:28,500 - INFO - allennlp.common.params - dataset_reader.type = strategy_decomposition_reader
2022-03-31 11:32:28,500 - INFO - allennlp.common.params - dataset_reader.lazy = False
2022-03-31 11:32:28,500 - INFO - allennlp.common.params - dataset_reader.cache_directory = None
2022-03-31 11:32:28,500 - INFO - allennlp.common.params - dataset_reader.max_instances = None
2022-03-31 11:32:28,500 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False
2022-03-31 11:32:28,500 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False
2022-03-31 11:32:28,501 - INFO - allennlp.common.params - dataset_reader.tokenizer_wrapper.type = default
2022-03-31 11:32:28,501 - INFO - allennlp.common.params - dataset_reader.tokenizer_wrapper.pretrained_model = facebook/bart-large
2022-03-31 11:32:28,501 - INFO - allennlp.common.params - dataset_reader.tokenizer_wrapper.init_kwargs.add_prefix_space = True
2022-03-31 11:32:28,572 - INFO - allennlp.common.params - dataset_reader.save_tokenizer = True
2022-03-31 11:32:28,572 - INFO - allennlp.common.params - dataset_reader.is_training = True
2022-03-31 11:32:28,573 - INFO - allennlp.common.params - dataset_reader.pickle.action = None
2022-03-31 11:32:28,573 - INFO - allennlp.common.params - train_data_path = data/strategyqa/train.json
2022-03-31 11:32:28,573 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7f680942de50>
2022-03-31 11:32:28,573 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2022-03-31 11:32:28,573 - INFO - allennlp.common.params - validation_dataset_reader.type = strategy_decomposition_reader
2022-03-31 11:32:28,574 - INFO - allennlp.common.params - validation_dataset_reader.lazy = False
2022-03-31 11:32:28,574 - INFO - allennlp.common.params - validation_dataset_reader.cache_directory = None
2022-03-31 11:32:28,574 - INFO - allennlp.common.params - validation_dataset_reader.max_instances = None
2022-03-31 11:32:28,574 - INFO - allennlp.common.params - validation_dataset_reader.manual_distributed_sharding = False
2022-03-31 11:32:28,574 - INFO - allennlp.common.params - validation_dataset_reader.manual_multi_process_sharding = False
2022-03-31 11:32:28,574 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer_wrapper.type = default
2022-03-31 11:32:28,574 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer_wrapper.pretrained_model = facebook/bart-large
2022-03-31 11:32:28,574 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer_wrapper.init_kwargs.add_prefix_space = True
2022-03-31 11:32:28,649 - INFO - allennlp.common.params - validation_dataset_reader.save_tokenizer = False
2022-03-31 11:32:28,649 - INFO - allennlp.common.params - validation_dataset_reader.is_training = False
2022-03-31 11:32:28,649 - INFO - allennlp.common.params - validation_dataset_reader.pickle.action = None
2022-03-31 11:32:28,649 - INFO - allennlp.common.params - validation_data_path = data/strategyqa/dev.json
2022-03-31 11:32:28,650 - INFO - allennlp.common.params - validation_data_loader = None
2022-03-31 11:32:28,650 - INFO - allennlp.common.params - test_data_path = None
2022-03-31 11:32:28,650 - INFO - allennlp.common.params - evaluate_on_test = False
2022-03-31 11:32:28,650 - INFO - allennlp.common.params - batch_weight_key = 
2022-03-31 11:32:28,650 - INFO - allennlp.training.util - Reading training data from data/strategyqa/train.json
2022-03-31 11:32:28,650 - INFO - tqdm - reading instances: 0it [00:00, ?it/s]
2022-03-31 11:32:28,650 - INFO - src.data.dataset_readers.base.base_dataset_reader - Reading the dataset from scratch
2022-03-31 11:32:28,650 - INFO - src.data.dataset_readers.strategy_decomposition_reader - Reading the dataset:
2022-03-31 11:32:28,651 - INFO - src.data.dataset_readers.strategy_decomposition_reader - Reading file at data/strategyqa/train.json
2022-03-31 11:32:30,068 - INFO - allennlp.training.util - Reading validation data from data/strategyqa/dev.json
2022-03-31 11:32:30,069 - INFO - tqdm - reading instances: 0it [00:00, ?it/s]
2022-03-31 11:32:30,069 - INFO - src.data.dataset_readers.base.base_dataset_reader - Reading the dataset from scratch
2022-03-31 11:32:30,069 - INFO - src.data.dataset_readers.strategy_decomposition_reader - Reading the dataset:
2022-03-31 11:32:30,069 - INFO - src.data.dataset_readers.strategy_decomposition_reader - Reading file at data/strategyqa/dev.json
2022-03-31 11:32:30,222 - INFO - allennlp.common.params - type = from_instances
2022-03-31 11:32:30,222 - INFO - allennlp.common.params - min_count = None
2022-03-31 11:32:30,222 - INFO - allennlp.common.params - max_vocab_size = None
2022-03-31 11:32:30,222 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2022-03-31 11:32:30,222 - INFO - allennlp.common.params - pretrained_files = None
2022-03-31 11:32:30,222 - INFO - allennlp.common.params - only_include_pretrained_words = False
2022-03-31 11:32:30,222 - INFO - allennlp.common.params - tokens_to_add = None
2022-03-31 11:32:30,223 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2022-03-31 11:32:30,223 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2022-03-31 11:32:30,223 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2022-03-31 11:32:30,223 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2022-03-31 11:32:30,223 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2022-03-31 11:32:30,228 - INFO - allennlp.common.params - model.type = gen
2022-03-31 11:32:30,228 - INFO - allennlp.common.params - model.regularizer = None
2022-03-31 11:32:30,228 - INFO - allennlp.common.params - model.pretrained_model = facebook/bart-large
2022-03-31 11:32:30,228 - INFO - allennlp.common.params - model.tokenizer_wrapper.type = default
2022-03-31 11:32:30,228 - INFO - allennlp.common.params - model.tokenizer_wrapper.pretrained_model = facebook/bart-large
2022-03-31 11:32:30,229 - INFO - allennlp.common.params - model.tokenizer_wrapper.init_kwargs.add_prefix_space = True
2022-03-31 11:32:30,303 - INFO - allennlp.common.params - model.generate_while_training = False
2022-03-31 11:32:30,303 - INFO - allennlp.common.params - model.repetition_penalty = 2.5
2022-03-31 11:32:30,304 - INFO - allennlp.common.params - model.metrics.bleu.type = bleu
2022-03-31 11:32:30,304 - INFO - allennlp.common.params - model.metrics.bleu.ngram_weights = (0.25, 0.25, 0.25, 0.25)
2022-03-31 11:32:30,304 - INFO - allennlp.common.params - model.metrics.bleu.exclude_indices = None
2022-03-31 11:32:30,304 - INFO - allennlp.common.params - model.metrics.rouge.type = rouge
2022-03-31 11:32:30,305 - INFO - allennlp.common.params - model.metrics.rouge.ngram_size = 2
2022-03-31 11:32:30,305 - INFO - allennlp.common.params - model.metrics.rouge.exclude_indices = None
2022-03-31 11:32:30,305 - INFO - allennlp.common.params - model.metrics.sari.type = sari
2022-03-31 11:32:30,305 - INFO - allennlp.common.params - model.metrics.sari.is_main = True
2022-03-31 11:32:30,305 - INFO - allennlp.common.params - model.is_dummy = False
2022-03-31 11:32:30,305 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f67fe7e0d10>
2022-03-31 11:32:39,973 - INFO - allennlp.nn.initializers - Initializing parameters
2022-03-31 11:32:39,976 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-03-31 11:32:39,977 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.embed_positions.weight
2022-03-31 11:32:39,977 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layernorm_embedding.bias
2022-03-31 11:32:39,977 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layernorm_embedding.weight
2022-03-31 11:32:39,977 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.k_proj.bias
2022-03-31 11:32:39,977 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.k_proj.weight
2022-03-31 11:32:39,977 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.out_proj.bias
2022-03-31 11:32:39,977 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.out_proj.weight
2022-03-31 11:32:39,977 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.q_proj.bias
2022-03-31 11:32:39,977 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.q_proj.weight
2022-03-31 11:32:39,977 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.v_proj.bias
2022-03-31 11:32:39,977 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn.v_proj.weight
2022-03-31 11:32:39,977 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn_layer_norm.bias
2022-03-31 11:32:39,977 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.encoder_attn_layer_norm.weight
2022-03-31 11:32:39,977 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.fc1.bias
2022-03-31 11:32:39,978 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.fc1.weight
2022-03-31 11:32:39,978 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.fc2.bias
2022-03-31 11:32:39,978 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.fc2.weight
2022-03-31 11:32:39,978 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.final_layer_norm.bias
2022-03-31 11:32:39,978 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.final_layer_norm.weight
2022-03-31 11:32:39,978 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.k_proj.bias
2022-03-31 11:32:39,978 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.k_proj.weight
2022-03-31 11:32:39,978 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.out_proj.bias
2022-03-31 11:32:39,978 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.out_proj.weight
2022-03-31 11:32:39,978 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.q_proj.bias
2022-03-31 11:32:39,978 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.q_proj.weight
2022-03-31 11:32:39,978 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.v_proj.bias
2022-03-31 11:32:39,978 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn.v_proj.weight
2022-03-31 11:32:39,978 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn_layer_norm.bias
2022-03-31 11:32:39,979 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.0.self_attn_layer_norm.weight
2022-03-31 11:32:39,979 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.k_proj.bias
2022-03-31 11:32:39,979 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.k_proj.weight
2022-03-31 11:32:39,979 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.out_proj.bias
2022-03-31 11:32:39,979 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.out_proj.weight
2022-03-31 11:32:39,979 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.q_proj.bias
2022-03-31 11:32:39,979 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.q_proj.weight
2022-03-31 11:32:39,979 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.v_proj.bias
2022-03-31 11:32:39,979 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn.v_proj.weight
2022-03-31 11:32:39,979 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn_layer_norm.bias
2022-03-31 11:32:39,979 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.encoder_attn_layer_norm.weight
2022-03-31 11:32:39,979 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.fc1.bias
2022-03-31 11:32:39,979 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.fc1.weight
2022-03-31 11:32:39,980 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.fc2.bias
2022-03-31 11:32:39,980 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.fc2.weight
2022-03-31 11:32:39,980 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.final_layer_norm.bias
2022-03-31 11:32:39,980 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.final_layer_norm.weight
2022-03-31 11:32:39,980 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.k_proj.bias
2022-03-31 11:32:39,980 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.k_proj.weight
2022-03-31 11:32:39,980 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.out_proj.bias
2022-03-31 11:32:39,980 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.out_proj.weight
2022-03-31 11:32:39,980 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.q_proj.bias
2022-03-31 11:32:39,980 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.q_proj.weight
2022-03-31 11:32:39,980 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.v_proj.bias
2022-03-31 11:32:39,980 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn.v_proj.weight
2022-03-31 11:32:39,980 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn_layer_norm.bias
2022-03-31 11:32:39,981 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.1.self_attn_layer_norm.weight
2022-03-31 11:32:39,981 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.k_proj.bias
2022-03-31 11:32:39,981 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.k_proj.weight
2022-03-31 11:32:39,981 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.out_proj.bias
2022-03-31 11:32:39,981 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.out_proj.weight
2022-03-31 11:32:39,981 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.q_proj.bias
2022-03-31 11:32:39,981 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.q_proj.weight
2022-03-31 11:32:39,981 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.v_proj.bias
2022-03-31 11:32:39,981 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn.v_proj.weight
2022-03-31 11:32:39,981 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn_layer_norm.bias
2022-03-31 11:32:39,981 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.encoder_attn_layer_norm.weight
2022-03-31 11:32:39,981 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.fc1.bias
2022-03-31 11:32:39,981 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.fc1.weight
2022-03-31 11:32:39,981 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.fc2.bias
2022-03-31 11:32:39,982 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.fc2.weight
2022-03-31 11:32:39,982 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.final_layer_norm.bias
2022-03-31 11:32:39,982 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.final_layer_norm.weight
2022-03-31 11:32:39,982 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.k_proj.bias
2022-03-31 11:32:39,982 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.k_proj.weight
2022-03-31 11:32:39,982 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.out_proj.bias
2022-03-31 11:32:39,982 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.out_proj.weight
2022-03-31 11:32:39,982 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.q_proj.bias
2022-03-31 11:32:39,982 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.q_proj.weight
2022-03-31 11:32:39,982 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.v_proj.bias
2022-03-31 11:32:39,982 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn.v_proj.weight
2022-03-31 11:32:39,982 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn_layer_norm.bias
2022-03-31 11:32:39,982 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.10.self_attn_layer_norm.weight
2022-03-31 11:32:39,982 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.k_proj.bias
2022-03-31 11:32:39,983 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.k_proj.weight
2022-03-31 11:32:39,983 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.out_proj.bias
2022-03-31 11:32:39,983 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.out_proj.weight
2022-03-31 11:32:39,983 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.q_proj.bias
2022-03-31 11:32:39,983 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.q_proj.weight
2022-03-31 11:32:39,983 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.v_proj.bias
2022-03-31 11:32:39,983 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn.v_proj.weight
2022-03-31 11:32:39,983 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn_layer_norm.bias
2022-03-31 11:32:39,983 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.encoder_attn_layer_norm.weight
2022-03-31 11:32:39,983 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.fc1.bias
2022-03-31 11:32:39,983 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.fc1.weight
2022-03-31 11:32:39,983 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.fc2.bias
2022-03-31 11:32:39,983 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.fc2.weight
2022-03-31 11:32:39,983 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.final_layer_norm.bias
2022-03-31 11:32:39,984 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.final_layer_norm.weight
2022-03-31 11:32:39,984 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.k_proj.bias
2022-03-31 11:32:39,984 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.k_proj.weight
2022-03-31 11:32:39,984 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.out_proj.bias
2022-03-31 11:32:39,984 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.out_proj.weight
2022-03-31 11:32:39,984 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.q_proj.bias
2022-03-31 11:32:39,984 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.q_proj.weight
2022-03-31 11:32:39,984 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.v_proj.bias
2022-03-31 11:32:39,984 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn.v_proj.weight
2022-03-31 11:32:39,984 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn_layer_norm.bias
2022-03-31 11:32:39,984 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.11.self_attn_layer_norm.weight
2022-03-31 11:32:39,984 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.k_proj.bias
2022-03-31 11:32:39,984 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.k_proj.weight
2022-03-31 11:32:39,985 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.out_proj.bias
2022-03-31 11:32:39,985 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.out_proj.weight
2022-03-31 11:32:39,985 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.q_proj.bias
2022-03-31 11:32:39,985 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.q_proj.weight
2022-03-31 11:32:39,985 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.v_proj.bias
2022-03-31 11:32:39,985 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn.v_proj.weight
2022-03-31 11:32:39,985 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn_layer_norm.bias
2022-03-31 11:32:39,985 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.encoder_attn_layer_norm.weight
2022-03-31 11:32:39,985 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.fc1.bias
2022-03-31 11:32:39,985 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.fc1.weight
2022-03-31 11:32:39,985 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.fc2.bias
2022-03-31 11:32:39,985 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.fc2.weight
2022-03-31 11:32:39,985 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.final_layer_norm.bias
2022-03-31 11:32:39,986 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.final_layer_norm.weight
2022-03-31 11:32:39,986 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.k_proj.bias
2022-03-31 11:32:39,986 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.k_proj.weight
2022-03-31 11:32:39,986 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.out_proj.bias
2022-03-31 11:32:39,986 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.out_proj.weight
2022-03-31 11:32:39,986 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.q_proj.bias
2022-03-31 11:32:39,986 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.q_proj.weight
2022-03-31 11:32:39,986 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.v_proj.bias
2022-03-31 11:32:39,986 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn.v_proj.weight
2022-03-31 11:32:39,986 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn_layer_norm.bias
2022-03-31 11:32:39,986 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.2.self_attn_layer_norm.weight
2022-03-31 11:32:39,986 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.k_proj.bias
2022-03-31 11:32:39,986 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.k_proj.weight
2022-03-31 11:32:39,986 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.out_proj.bias
2022-03-31 11:32:39,987 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.out_proj.weight
2022-03-31 11:32:39,987 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.q_proj.bias
2022-03-31 11:32:39,987 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.q_proj.weight
2022-03-31 11:32:39,987 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.v_proj.bias
2022-03-31 11:32:39,987 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn.v_proj.weight
2022-03-31 11:32:39,987 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn_layer_norm.bias
2022-03-31 11:32:39,987 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.encoder_attn_layer_norm.weight
2022-03-31 11:32:39,987 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.fc1.bias
2022-03-31 11:32:39,987 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.fc1.weight
2022-03-31 11:32:39,987 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.fc2.bias
2022-03-31 11:32:39,987 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.fc2.weight
2022-03-31 11:32:39,987 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.final_layer_norm.bias
2022-03-31 11:32:39,987 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.final_layer_norm.weight
2022-03-31 11:32:39,988 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.k_proj.bias
2022-03-31 11:32:39,988 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.k_proj.weight
2022-03-31 11:32:39,988 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.out_proj.bias
2022-03-31 11:32:39,988 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.out_proj.weight
2022-03-31 11:32:39,988 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.q_proj.bias
2022-03-31 11:32:39,988 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.q_proj.weight
2022-03-31 11:32:39,988 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.v_proj.bias
2022-03-31 11:32:39,988 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn.v_proj.weight
2022-03-31 11:32:39,988 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn_layer_norm.bias
2022-03-31 11:32:39,988 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.3.self_attn_layer_norm.weight
2022-03-31 11:32:39,988 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.k_proj.bias
2022-03-31 11:32:39,988 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.k_proj.weight
2022-03-31 11:32:39,988 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.out_proj.bias
2022-03-31 11:32:39,989 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.out_proj.weight
2022-03-31 11:32:39,989 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.q_proj.bias
2022-03-31 11:32:39,989 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.q_proj.weight
2022-03-31 11:32:39,989 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.v_proj.bias
2022-03-31 11:32:39,989 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn.v_proj.weight
2022-03-31 11:32:39,989 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn_layer_norm.bias
2022-03-31 11:32:39,989 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.encoder_attn_layer_norm.weight
2022-03-31 11:32:39,989 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.fc1.bias
2022-03-31 11:32:39,989 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.fc1.weight
2022-03-31 11:32:39,989 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.fc2.bias
2022-03-31 11:32:39,989 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.fc2.weight
2022-03-31 11:32:39,989 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.final_layer_norm.bias
2022-03-31 11:32:39,989 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.final_layer_norm.weight
2022-03-31 11:32:39,990 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.k_proj.bias
2022-03-31 11:32:39,990 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.k_proj.weight
2022-03-31 11:32:39,990 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.out_proj.bias
2022-03-31 11:32:39,990 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.out_proj.weight
2022-03-31 11:32:39,990 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.q_proj.bias
2022-03-31 11:32:39,990 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.q_proj.weight
2022-03-31 11:32:39,990 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.v_proj.bias
2022-03-31 11:32:39,990 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn.v_proj.weight
2022-03-31 11:32:39,990 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn_layer_norm.bias
2022-03-31 11:32:39,990 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.4.self_attn_layer_norm.weight
2022-03-31 11:32:39,990 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.k_proj.bias
2022-03-31 11:32:39,990 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.k_proj.weight
2022-03-31 11:32:39,990 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.out_proj.bias
2022-03-31 11:32:39,991 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.out_proj.weight
2022-03-31 11:32:39,991 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.q_proj.bias
2022-03-31 11:32:39,991 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.q_proj.weight
2022-03-31 11:32:39,991 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.v_proj.bias
2022-03-31 11:32:39,991 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn.v_proj.weight
2022-03-31 11:32:39,991 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn_layer_norm.bias
2022-03-31 11:32:39,991 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.encoder_attn_layer_norm.weight
2022-03-31 11:32:39,991 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.fc1.bias
2022-03-31 11:32:39,991 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.fc1.weight
2022-03-31 11:32:39,991 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.fc2.bias
2022-03-31 11:32:39,991 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.fc2.weight
2022-03-31 11:32:39,991 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.final_layer_norm.bias
2022-03-31 11:32:39,991 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.final_layer_norm.weight
2022-03-31 11:32:39,992 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.k_proj.bias
2022-03-31 11:32:39,992 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.k_proj.weight
2022-03-31 11:32:39,992 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.out_proj.bias
2022-03-31 11:32:39,992 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.out_proj.weight
2022-03-31 11:32:39,992 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.q_proj.bias
2022-03-31 11:32:39,992 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.q_proj.weight
2022-03-31 11:32:39,992 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.v_proj.bias
2022-03-31 11:32:39,992 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn.v_proj.weight
2022-03-31 11:32:39,992 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn_layer_norm.bias
2022-03-31 11:32:39,992 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.5.self_attn_layer_norm.weight
2022-03-31 11:32:39,992 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.k_proj.bias
2022-03-31 11:32:39,992 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.k_proj.weight
2022-03-31 11:32:39,992 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.out_proj.bias
2022-03-31 11:32:39,993 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.out_proj.weight
2022-03-31 11:32:39,993 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.q_proj.bias
2022-03-31 11:32:39,993 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.q_proj.weight
2022-03-31 11:32:39,993 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.v_proj.bias
2022-03-31 11:32:39,993 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn.v_proj.weight
2022-03-31 11:32:39,993 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn_layer_norm.bias
2022-03-31 11:32:39,993 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.encoder_attn_layer_norm.weight
2022-03-31 11:32:39,993 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.fc1.bias
2022-03-31 11:32:39,993 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.fc1.weight
2022-03-31 11:32:39,993 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.fc2.bias
2022-03-31 11:32:39,993 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.fc2.weight
2022-03-31 11:32:39,993 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.final_layer_norm.bias
2022-03-31 11:32:39,993 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.final_layer_norm.weight
2022-03-31 11:32:39,993 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.k_proj.bias
2022-03-31 11:32:39,993 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.k_proj.weight
2022-03-31 11:32:39,994 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.out_proj.bias
2022-03-31 11:32:39,994 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.out_proj.weight
2022-03-31 11:32:39,994 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.q_proj.bias
2022-03-31 11:32:39,994 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.q_proj.weight
2022-03-31 11:32:39,994 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.v_proj.bias
2022-03-31 11:32:39,994 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn.v_proj.weight
2022-03-31 11:32:39,994 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn_layer_norm.bias
2022-03-31 11:32:39,994 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.6.self_attn_layer_norm.weight
2022-03-31 11:32:39,994 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.k_proj.bias
2022-03-31 11:32:39,994 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.k_proj.weight
2022-03-31 11:32:39,994 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.out_proj.bias
2022-03-31 11:32:39,994 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.out_proj.weight
2022-03-31 11:32:39,994 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.q_proj.bias
2022-03-31 11:32:39,994 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.q_proj.weight
2022-03-31 11:32:39,994 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.v_proj.bias
2022-03-31 11:32:39,994 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn.v_proj.weight
2022-03-31 11:32:39,994 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn_layer_norm.bias
2022-03-31 11:32:39,994 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.encoder_attn_layer_norm.weight
2022-03-31 11:32:39,994 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.fc1.bias
2022-03-31 11:32:39,995 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.fc1.weight
2022-03-31 11:32:39,995 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.fc2.bias
2022-03-31 11:32:39,995 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.fc2.weight
2022-03-31 11:32:39,995 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.final_layer_norm.bias
2022-03-31 11:32:39,995 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.final_layer_norm.weight
2022-03-31 11:32:39,995 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.k_proj.bias
2022-03-31 11:32:39,995 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.k_proj.weight
2022-03-31 11:32:39,995 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.out_proj.bias
2022-03-31 11:32:39,995 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.out_proj.weight
2022-03-31 11:32:39,995 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.q_proj.bias
2022-03-31 11:32:39,995 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.q_proj.weight
2022-03-31 11:32:39,995 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.v_proj.bias
2022-03-31 11:32:39,995 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn.v_proj.weight
2022-03-31 11:32:39,995 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn_layer_norm.bias
2022-03-31 11:32:39,995 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.7.self_attn_layer_norm.weight
2022-03-31 11:32:39,995 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.k_proj.bias
2022-03-31 11:32:39,995 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.k_proj.weight
2022-03-31 11:32:39,995 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.out_proj.bias
2022-03-31 11:32:39,995 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.out_proj.weight
2022-03-31 11:32:39,996 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.q_proj.bias
2022-03-31 11:32:39,996 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.q_proj.weight
2022-03-31 11:32:39,996 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.v_proj.bias
2022-03-31 11:32:39,996 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn.v_proj.weight
2022-03-31 11:32:39,996 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn_layer_norm.bias
2022-03-31 11:32:39,996 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.encoder_attn_layer_norm.weight
2022-03-31 11:32:39,996 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.fc1.bias
2022-03-31 11:32:39,996 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.fc1.weight
2022-03-31 11:32:39,996 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.fc2.bias
2022-03-31 11:32:39,996 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.fc2.weight
2022-03-31 11:32:39,996 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.final_layer_norm.bias
2022-03-31 11:32:39,996 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.final_layer_norm.weight
2022-03-31 11:32:39,996 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.k_proj.bias
2022-03-31 11:32:39,996 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.k_proj.weight
2022-03-31 11:32:39,996 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.out_proj.bias
2022-03-31 11:32:39,997 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.out_proj.weight
2022-03-31 11:32:39,997 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.q_proj.bias
2022-03-31 11:32:39,997 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.q_proj.weight
2022-03-31 11:32:39,997 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.v_proj.bias
2022-03-31 11:32:39,997 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn.v_proj.weight
2022-03-31 11:32:39,997 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn_layer_norm.bias
2022-03-31 11:32:39,997 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.8.self_attn_layer_norm.weight
2022-03-31 11:32:39,997 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.k_proj.bias
2022-03-31 11:32:39,997 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.k_proj.weight
2022-03-31 11:32:39,997 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.out_proj.bias
2022-03-31 11:32:39,997 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.out_proj.weight
2022-03-31 11:32:39,997 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.q_proj.bias
2022-03-31 11:32:39,997 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.q_proj.weight
2022-03-31 11:32:39,997 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.v_proj.bias
2022-03-31 11:32:39,998 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn.v_proj.weight
2022-03-31 11:32:39,998 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn_layer_norm.bias
2022-03-31 11:32:39,998 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.encoder_attn_layer_norm.weight
2022-03-31 11:32:39,998 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.fc1.bias
2022-03-31 11:32:39,998 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.fc1.weight
2022-03-31 11:32:39,998 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.fc2.bias
2022-03-31 11:32:39,998 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.fc2.weight
2022-03-31 11:32:39,998 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.final_layer_norm.bias
2022-03-31 11:32:39,998 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.final_layer_norm.weight
2022-03-31 11:32:39,998 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.k_proj.bias
2022-03-31 11:32:39,998 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.k_proj.weight
2022-03-31 11:32:39,998 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.out_proj.bias
2022-03-31 11:32:39,998 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.out_proj.weight
2022-03-31 11:32:39,998 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.q_proj.bias
2022-03-31 11:32:39,999 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.q_proj.weight
2022-03-31 11:32:39,999 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.v_proj.bias
2022-03-31 11:32:39,999 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn.v_proj.weight
2022-03-31 11:32:39,999 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn_layer_norm.bias
2022-03-31 11:32:39,999 - INFO - allennlp.nn.initializers -    _seq2seq.model.decoder.layers.9.self_attn_layer_norm.weight
2022-03-31 11:32:39,999 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.embed_positions.weight
2022-03-31 11:32:39,999 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layernorm_embedding.bias
2022-03-31 11:32:39,999 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layernorm_embedding.weight
2022-03-31 11:32:39,999 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.fc1.bias
2022-03-31 11:32:39,999 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.fc1.weight
2022-03-31 11:32:39,999 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.fc2.bias
2022-03-31 11:32:39,999 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.fc2.weight
2022-03-31 11:32:39,999 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.final_layer_norm.bias
2022-03-31 11:32:40,000 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.final_layer_norm.weight
2022-03-31 11:32:40,000 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.k_proj.bias
2022-03-31 11:32:40,000 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.k_proj.weight
2022-03-31 11:32:40,000 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.out_proj.bias
2022-03-31 11:32:40,000 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.out_proj.weight
2022-03-31 11:32:40,000 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.q_proj.bias
2022-03-31 11:32:40,000 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.q_proj.weight
2022-03-31 11:32:40,000 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.v_proj.bias
2022-03-31 11:32:40,000 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn.v_proj.weight
2022-03-31 11:32:40,000 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn_layer_norm.bias
2022-03-31 11:32:40,000 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.0.self_attn_layer_norm.weight
2022-03-31 11:32:40,000 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.fc1.bias
2022-03-31 11:32:40,001 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.fc1.weight
2022-03-31 11:32:40,001 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.fc2.bias
2022-03-31 11:32:40,001 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.fc2.weight
2022-03-31 11:32:40,001 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.final_layer_norm.bias
2022-03-31 11:32:40,001 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.final_layer_norm.weight
2022-03-31 11:32:40,001 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.k_proj.bias
2022-03-31 11:32:40,001 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.k_proj.weight
2022-03-31 11:32:40,001 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.out_proj.bias
2022-03-31 11:32:40,001 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.out_proj.weight
2022-03-31 11:32:40,001 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.q_proj.bias
2022-03-31 11:32:40,001 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.q_proj.weight
2022-03-31 11:32:40,001 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.v_proj.bias
2022-03-31 11:32:40,001 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn.v_proj.weight
2022-03-31 11:32:40,001 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn_layer_norm.bias
2022-03-31 11:32:40,002 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.1.self_attn_layer_norm.weight
2022-03-31 11:32:40,002 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.fc1.bias
2022-03-31 11:32:40,002 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.fc1.weight
2022-03-31 11:32:40,002 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.fc2.bias
2022-03-31 11:32:40,002 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.fc2.weight
2022-03-31 11:32:40,002 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.final_layer_norm.bias
2022-03-31 11:32:40,002 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.final_layer_norm.weight
2022-03-31 11:32:40,002 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.k_proj.bias
2022-03-31 11:32:40,002 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.k_proj.weight
2022-03-31 11:32:40,002 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.out_proj.bias
2022-03-31 11:32:40,003 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.out_proj.weight
2022-03-31 11:32:40,003 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.q_proj.bias
2022-03-31 11:32:40,003 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.q_proj.weight
2022-03-31 11:32:40,003 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.v_proj.bias
2022-03-31 11:32:40,003 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn.v_proj.weight
2022-03-31 11:32:40,003 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn_layer_norm.bias
2022-03-31 11:32:40,003 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.10.self_attn_layer_norm.weight
2022-03-31 11:32:40,003 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.fc1.bias
2022-03-31 11:32:40,003 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.fc1.weight
2022-03-31 11:32:40,003 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.fc2.bias
2022-03-31 11:32:40,003 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.fc2.weight
2022-03-31 11:32:40,004 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.final_layer_norm.bias
2022-03-31 11:32:40,004 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.final_layer_norm.weight
2022-03-31 11:32:40,004 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.k_proj.bias
2022-03-31 11:32:40,004 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.k_proj.weight
2022-03-31 11:32:40,004 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.out_proj.bias
2022-03-31 11:32:40,004 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.out_proj.weight
2022-03-31 11:32:40,004 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.q_proj.bias
2022-03-31 11:32:40,004 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.q_proj.weight
2022-03-31 11:32:40,004 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.v_proj.bias
2022-03-31 11:32:40,004 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn.v_proj.weight
2022-03-31 11:32:40,005 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn_layer_norm.bias
2022-03-31 11:32:40,005 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.11.self_attn_layer_norm.weight
2022-03-31 11:32:40,005 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.fc1.bias
2022-03-31 11:32:40,005 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.fc1.weight
2022-03-31 11:32:40,005 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.fc2.bias
2022-03-31 11:32:40,005 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.fc2.weight
2022-03-31 11:32:40,005 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.final_layer_norm.bias
2022-03-31 11:32:40,005 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.final_layer_norm.weight
2022-03-31 11:32:40,005 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.k_proj.bias
2022-03-31 11:32:40,005 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.k_proj.weight
2022-03-31 11:32:40,005 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.out_proj.bias
2022-03-31 11:32:40,005 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.out_proj.weight
2022-03-31 11:32:40,006 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.q_proj.bias
2022-03-31 11:32:40,006 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.q_proj.weight
2022-03-31 11:32:40,006 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.v_proj.bias
2022-03-31 11:32:40,006 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn.v_proj.weight
2022-03-31 11:32:40,006 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn_layer_norm.bias
2022-03-31 11:32:40,006 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.2.self_attn_layer_norm.weight
2022-03-31 11:32:40,006 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.fc1.bias
2022-03-31 11:32:40,006 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.fc1.weight
2022-03-31 11:32:40,006 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.fc2.bias
2022-03-31 11:32:40,006 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.fc2.weight
2022-03-31 11:32:40,006 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.final_layer_norm.bias
2022-03-31 11:32:40,006 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.final_layer_norm.weight
2022-03-31 11:32:40,006 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.k_proj.bias
2022-03-31 11:32:40,007 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.k_proj.weight
2022-03-31 11:32:40,007 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.out_proj.bias
2022-03-31 11:32:40,007 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.out_proj.weight
2022-03-31 11:32:40,007 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.q_proj.bias
2022-03-31 11:32:40,007 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.q_proj.weight
2022-03-31 11:32:40,007 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.v_proj.bias
2022-03-31 11:32:40,007 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn.v_proj.weight
2022-03-31 11:32:40,007 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn_layer_norm.bias
2022-03-31 11:32:40,007 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.3.self_attn_layer_norm.weight
2022-03-31 11:32:40,007 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.fc1.bias
2022-03-31 11:32:40,007 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.fc1.weight
2022-03-31 11:32:40,007 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.fc2.bias
2022-03-31 11:32:40,007 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.fc2.weight
2022-03-31 11:32:40,007 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.final_layer_norm.bias
2022-03-31 11:32:40,008 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.final_layer_norm.weight
2022-03-31 11:32:40,008 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.k_proj.bias
2022-03-31 11:32:40,008 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.k_proj.weight
2022-03-31 11:32:40,008 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.out_proj.bias
2022-03-31 11:32:40,008 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.out_proj.weight
2022-03-31 11:32:40,008 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.q_proj.bias
2022-03-31 11:32:40,008 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.q_proj.weight
2022-03-31 11:32:40,008 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.v_proj.bias
2022-03-31 11:32:40,008 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn.v_proj.weight
2022-03-31 11:32:40,008 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn_layer_norm.bias
2022-03-31 11:32:40,008 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.4.self_attn_layer_norm.weight
2022-03-31 11:32:40,008 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.fc1.bias
2022-03-31 11:32:40,009 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.fc1.weight
2022-03-31 11:32:40,009 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.fc2.bias
2022-03-31 11:32:40,009 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.fc2.weight
2022-03-31 11:32:40,009 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.final_layer_norm.bias
2022-03-31 11:32:40,009 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.final_layer_norm.weight
2022-03-31 11:32:40,009 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.k_proj.bias
2022-03-31 11:32:40,009 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.k_proj.weight
2022-03-31 11:32:40,009 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.out_proj.bias
2022-03-31 11:32:40,009 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.out_proj.weight
2022-03-31 11:32:40,009 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.q_proj.bias
2022-03-31 11:32:40,009 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.q_proj.weight
2022-03-31 11:32:40,009 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.v_proj.bias
2022-03-31 11:32:40,009 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn.v_proj.weight
2022-03-31 11:32:40,010 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn_layer_norm.bias
2022-03-31 11:32:40,010 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.5.self_attn_layer_norm.weight
2022-03-31 11:32:40,010 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.fc1.bias
2022-03-31 11:32:40,010 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.fc1.weight
2022-03-31 11:32:40,010 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.fc2.bias
2022-03-31 11:32:40,010 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.fc2.weight
2022-03-31 11:32:40,010 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.final_layer_norm.bias
2022-03-31 11:32:40,010 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.final_layer_norm.weight
2022-03-31 11:32:40,010 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.k_proj.bias
2022-03-31 11:32:40,010 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.k_proj.weight
2022-03-31 11:32:40,010 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.out_proj.bias
2022-03-31 11:32:40,010 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.out_proj.weight
2022-03-31 11:32:40,010 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.q_proj.bias
2022-03-31 11:32:40,011 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.q_proj.weight
2022-03-31 11:32:40,011 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.v_proj.bias
2022-03-31 11:32:40,011 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn.v_proj.weight
2022-03-31 11:32:40,011 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn_layer_norm.bias
2022-03-31 11:32:40,011 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.6.self_attn_layer_norm.weight
2022-03-31 11:32:40,011 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.fc1.bias
2022-03-31 11:32:40,011 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.fc1.weight
2022-03-31 11:32:40,011 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.fc2.bias
2022-03-31 11:32:40,011 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.fc2.weight
2022-03-31 11:32:40,011 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.final_layer_norm.bias
2022-03-31 11:32:40,011 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.final_layer_norm.weight
2022-03-31 11:32:40,011 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.k_proj.bias
2022-03-31 11:32:40,011 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.k_proj.weight
2022-03-31 11:32:40,011 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.out_proj.bias
2022-03-31 11:32:40,012 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.out_proj.weight
2022-03-31 11:32:40,012 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.q_proj.bias
2022-03-31 11:32:40,012 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.q_proj.weight
2022-03-31 11:32:40,012 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.v_proj.bias
2022-03-31 11:32:40,012 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn.v_proj.weight
2022-03-31 11:32:40,012 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn_layer_norm.bias
2022-03-31 11:32:40,012 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.7.self_attn_layer_norm.weight
2022-03-31 11:32:40,012 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.fc1.bias
2022-03-31 11:32:40,012 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.fc1.weight
2022-03-31 11:32:40,012 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.fc2.bias
2022-03-31 11:32:40,012 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.fc2.weight
2022-03-31 11:32:40,012 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.final_layer_norm.bias
2022-03-31 11:32:40,013 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.final_layer_norm.weight
2022-03-31 11:32:40,013 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.k_proj.bias
2022-03-31 11:32:40,013 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.k_proj.weight
2022-03-31 11:32:40,013 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.out_proj.bias
2022-03-31 11:32:40,013 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.out_proj.weight
2022-03-31 11:32:40,013 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.q_proj.bias
2022-03-31 11:32:40,013 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.q_proj.weight
2022-03-31 11:32:40,013 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.v_proj.bias
2022-03-31 11:32:40,013 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn.v_proj.weight
2022-03-31 11:32:40,013 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn_layer_norm.bias
2022-03-31 11:32:40,013 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.8.self_attn_layer_norm.weight
2022-03-31 11:32:40,013 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.fc1.bias
2022-03-31 11:32:40,013 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.fc1.weight
2022-03-31 11:32:40,013 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.fc2.bias
2022-03-31 11:32:40,014 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.fc2.weight
2022-03-31 11:32:40,014 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.final_layer_norm.bias
2022-03-31 11:32:40,014 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.final_layer_norm.weight
2022-03-31 11:32:40,014 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.k_proj.bias
2022-03-31 11:32:40,014 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.k_proj.weight
2022-03-31 11:32:40,014 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.out_proj.bias
2022-03-31 11:32:40,014 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.out_proj.weight
2022-03-31 11:32:40,014 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.q_proj.bias
2022-03-31 11:32:40,014 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.q_proj.weight
2022-03-31 11:32:40,014 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.v_proj.bias
2022-03-31 11:32:40,014 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn.v_proj.weight
2022-03-31 11:32:40,014 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn_layer_norm.bias
2022-03-31 11:32:40,014 - INFO - allennlp.nn.initializers -    _seq2seq.model.encoder.layers.9.self_attn_layer_norm.weight
2022-03-31 11:32:40,015 - INFO - allennlp.nn.initializers -    _seq2seq.model.shared.weight
2022-03-31 11:32:40,411 - WARNING - allennlp.data.vocabulary - vocabulary serialization directory ./output_decomposition/vocabulary is not empty
2022-03-31 11:32:40,411 - INFO - filelock - Lock 140084628142672 acquired on ./output_decomposition/vocabulary/.lock
2022-03-31 11:32:40,412 - INFO - filelock - Lock 140084628142672 released on ./output_decomposition/vocabulary/.lock
2022-03-31 11:32:40,412 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader
2022-03-31 11:32:40,412 - INFO - allennlp.common.params - data_loader.batch_size = 1
2022-03-31 11:32:40,412 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-31 11:32:40,412 - INFO - allennlp.common.params - data_loader.sampler = None
2022-03-31 11:32:40,413 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-31 11:32:40,413 - INFO - allennlp.common.params - data_loader.pin_memory = False
2022-03-31 11:32:40,413 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-31 11:32:40,413 - INFO - allennlp.common.params - data_loader.timeout = 0
2022-03-31 11:32:40,413 - INFO - allennlp.common.params - data_loader.worker_init_fn = None
2022-03-31 11:32:40,413 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None
2022-03-31 11:32:40,413 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-31 11:32:40,413 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-31 11:32:40,413 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 2
2022-03-31 11:32:40,413 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-31 11:32:40,413 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-31 11:32:40,413 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-31 11:32:40,414 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader
2022-03-31 11:32:40,414 - INFO - allennlp.common.params - data_loader.batch_size = 1
2022-03-31 11:32:40,414 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-03-31 11:32:40,414 - INFO - allennlp.common.params - data_loader.sampler = None
2022-03-31 11:32:40,414 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-03-31 11:32:40,415 - INFO - allennlp.common.params - data_loader.pin_memory = False
2022-03-31 11:32:40,415 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-03-31 11:32:40,415 - INFO - allennlp.common.params - data_loader.timeout = 0
2022-03-31 11:32:40,415 - INFO - allennlp.common.params - data_loader.worker_init_fn = None
2022-03-31 11:32:40,415 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None
2022-03-31 11:32:40,415 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-03-31 11:32:40,415 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-03-31 11:32:40,415 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 2
2022-03-31 11:32:40,415 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-03-31 11:32:40,415 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-03-31 11:32:40,415 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-03-31 11:32:40,416 - INFO - allennlp.common.params - trainer.type = gradient_descent
2022-03-31 11:32:40,416 - INFO - allennlp.common.params - trainer.patience = None
2022-03-31 11:32:40,416 - INFO - allennlp.common.params - trainer.validation_metric = +SARI
2022-03-31 11:32:40,416 - INFO - allennlp.common.params - trainer.num_epochs = 15
2022-03-31 11:32:40,416 - INFO - allennlp.common.params - trainer.cuda_device = 0
2022-03-31 11:32:40,416 - INFO - allennlp.common.params - trainer.grad_norm = None
2022-03-31 11:32:40,416 - INFO - allennlp.common.params - trainer.grad_clipping = None
2022-03-31 11:32:40,416 - INFO - allennlp.common.params - trainer.distributed = False
2022-03-31 11:32:40,416 - INFO - allennlp.common.params - trainer.world_size = 1
2022-03-31 11:32:40,416 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 16
2022-03-31 11:32:40,416 - INFO - allennlp.common.params - trainer.use_amp = False
2022-03-31 11:32:40,417 - INFO - allennlp.common.params - trainer.no_grad = None
2022-03-31 11:32:40,417 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2022-03-31 11:32:40,417 - INFO - allennlp.common.params - trainer.tensorboard_writer = <allennlp.common.lazy.Lazy object at 0x7f67fefde1d0>
2022-03-31 11:32:40,417 - INFO - allennlp.common.params - trainer.moving_average = None
2022-03-31 11:32:40,417 - INFO - allennlp.common.params - trainer.batch_callbacks = None
2022-03-31 11:32:40,417 - INFO - allennlp.common.params - trainer.epoch_callbacks = None
2022-03-31 11:32:40,417 - INFO - allennlp.common.params - trainer.end_callbacks = None
2022-03-31 11:32:40,417 - INFO - allennlp.common.params - trainer.trainer_callbacks = None
2022-03-31 11:32:43,362 - INFO - allennlp.common.params - trainer.optimizer.type = huggingface_adamw
2022-03-31 11:32:43,362 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups = None
2022-03-31 11:32:43,362 - INFO - allennlp.common.params - trainer.optimizer.lr = 3e-05
2022-03-31 11:32:43,362 - INFO - allennlp.common.params - trainer.optimizer.betas = [0.9, 0.999]
2022-03-31 11:32:43,362 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08
2022-03-31 11:32:43,362 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.0
2022-03-31 11:32:43,363 - INFO - allennlp.common.params - trainer.optimizer.correct_bias = True
2022-03-31 11:32:43,363 - INFO - allennlp.training.optimizers - Number of trainable parameters: 406291456
2022-03-31 11:32:43,365 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2022-03-31 11:32:43,368 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2022-03-31 11:32:43,368 - INFO - allennlp.common.util - _seq2seq.model.shared.weight
2022-03-31 11:32:43,368 - INFO - allennlp.common.util - _seq2seq.model.encoder.embed_positions.weight
2022-03-31 11:32:43,368 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.k_proj.weight
2022-03-31 11:32:43,368 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.k_proj.bias
2022-03-31 11:32:43,368 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.v_proj.weight
2022-03-31 11:32:43,369 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.v_proj.bias
2022-03-31 11:32:43,369 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.q_proj.weight
2022-03-31 11:32:43,369 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.q_proj.bias
2022-03-31 11:32:43,369 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.out_proj.weight
2022-03-31 11:32:43,369 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn.out_proj.bias
2022-03-31 11:32:43,369 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn_layer_norm.weight
2022-03-31 11:32:43,369 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.self_attn_layer_norm.bias
2022-03-31 11:32:43,369 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.fc1.weight
2022-03-31 11:32:43,369 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.fc1.bias
2022-03-31 11:32:43,369 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.fc2.weight
2022-03-31 11:32:43,369 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.fc2.bias
2022-03-31 11:32:43,370 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.final_layer_norm.weight
2022-03-31 11:32:43,370 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.0.final_layer_norm.bias
2022-03-31 11:32:43,370 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.k_proj.weight
2022-03-31 11:32:43,370 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.k_proj.bias
2022-03-31 11:32:43,370 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.v_proj.weight
2022-03-31 11:32:43,370 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.v_proj.bias
2022-03-31 11:32:43,370 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.q_proj.weight
2022-03-31 11:32:43,370 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.q_proj.bias
2022-03-31 11:32:43,370 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.out_proj.weight
2022-03-31 11:32:43,371 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn.out_proj.bias
2022-03-31 11:32:43,371 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn_layer_norm.weight
2022-03-31 11:32:43,371 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.self_attn_layer_norm.bias
2022-03-31 11:32:43,371 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.fc1.weight
2022-03-31 11:32:43,371 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.fc1.bias
2022-03-31 11:32:43,371 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.fc2.weight
2022-03-31 11:32:43,371 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.fc2.bias
2022-03-31 11:32:43,371 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.final_layer_norm.weight
2022-03-31 11:32:43,371 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.1.final_layer_norm.bias
2022-03-31 11:32:43,371 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.k_proj.weight
2022-03-31 11:32:43,371 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.k_proj.bias
2022-03-31 11:32:43,372 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.v_proj.weight
2022-03-31 11:32:43,372 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.v_proj.bias
2022-03-31 11:32:43,372 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.q_proj.weight
2022-03-31 11:32:43,372 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.q_proj.bias
2022-03-31 11:32:43,372 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.out_proj.weight
2022-03-31 11:32:43,372 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn.out_proj.bias
2022-03-31 11:32:43,372 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn_layer_norm.weight
2022-03-31 11:32:43,372 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.self_attn_layer_norm.bias
2022-03-31 11:32:43,372 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.fc1.weight
2022-03-31 11:32:43,372 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.fc1.bias
2022-03-31 11:32:43,373 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.fc2.weight
2022-03-31 11:32:43,373 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.fc2.bias
2022-03-31 11:32:43,373 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.final_layer_norm.weight
2022-03-31 11:32:43,373 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.2.final_layer_norm.bias
2022-03-31 11:32:43,373 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.k_proj.weight
2022-03-31 11:32:43,373 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.k_proj.bias
2022-03-31 11:32:43,373 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.v_proj.weight
2022-03-31 11:32:43,373 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.v_proj.bias
2022-03-31 11:32:43,373 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.q_proj.weight
2022-03-31 11:32:43,373 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.q_proj.bias
2022-03-31 11:32:43,373 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.out_proj.weight
2022-03-31 11:32:43,373 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn.out_proj.bias
2022-03-31 11:32:43,374 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn_layer_norm.weight
2022-03-31 11:32:43,374 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.self_attn_layer_norm.bias
2022-03-31 11:32:43,374 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.fc1.weight
2022-03-31 11:32:43,374 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.fc1.bias
2022-03-31 11:32:43,374 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.fc2.weight
2022-03-31 11:32:43,374 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.fc2.bias
2022-03-31 11:32:43,374 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.final_layer_norm.weight
2022-03-31 11:32:43,374 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.3.final_layer_norm.bias
2022-03-31 11:32:43,374 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.k_proj.weight
2022-03-31 11:32:43,374 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.k_proj.bias
2022-03-31 11:32:43,374 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.v_proj.weight
2022-03-31 11:32:43,375 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.v_proj.bias
2022-03-31 11:32:43,375 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.q_proj.weight
2022-03-31 11:32:43,375 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.q_proj.bias
2022-03-31 11:32:43,375 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.out_proj.weight
2022-03-31 11:32:43,375 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn.out_proj.bias
2022-03-31 11:32:43,375 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn_layer_norm.weight
2022-03-31 11:32:43,375 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.self_attn_layer_norm.bias
2022-03-31 11:32:43,375 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.fc1.weight
2022-03-31 11:32:43,375 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.fc1.bias
2022-03-31 11:32:43,375 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.fc2.weight
2022-03-31 11:32:43,376 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.fc2.bias
2022-03-31 11:32:43,376 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.final_layer_norm.weight
2022-03-31 11:32:43,376 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.4.final_layer_norm.bias
2022-03-31 11:32:43,376 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.k_proj.weight
2022-03-31 11:32:43,376 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.k_proj.bias
2022-03-31 11:32:43,376 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.v_proj.weight
2022-03-31 11:32:43,376 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.v_proj.bias
2022-03-31 11:32:43,376 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.q_proj.weight
2022-03-31 11:32:43,376 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.q_proj.bias
2022-03-31 11:32:43,376 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.out_proj.weight
2022-03-31 11:32:43,376 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn.out_proj.bias
2022-03-31 11:32:43,377 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn_layer_norm.weight
2022-03-31 11:32:43,377 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.self_attn_layer_norm.bias
2022-03-31 11:32:43,377 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.fc1.weight
2022-03-31 11:32:43,377 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.fc1.bias
2022-03-31 11:32:43,377 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.fc2.weight
2022-03-31 11:32:43,377 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.fc2.bias
2022-03-31 11:32:43,377 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.final_layer_norm.weight
2022-03-31 11:32:43,377 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.5.final_layer_norm.bias
2022-03-31 11:32:43,377 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.k_proj.weight
2022-03-31 11:32:43,377 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.k_proj.bias
2022-03-31 11:32:43,378 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.v_proj.weight
2022-03-31 11:32:43,378 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.v_proj.bias
2022-03-31 11:32:43,378 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.q_proj.weight
2022-03-31 11:32:43,378 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.q_proj.bias
2022-03-31 11:32:43,378 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.out_proj.weight
2022-03-31 11:32:43,378 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn.out_proj.bias
2022-03-31 11:32:43,378 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn_layer_norm.weight
2022-03-31 11:32:43,378 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.self_attn_layer_norm.bias
2022-03-31 11:32:43,378 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.fc1.weight
2022-03-31 11:32:43,378 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.fc1.bias
2022-03-31 11:32:43,378 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.fc2.weight
2022-03-31 11:32:43,379 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.fc2.bias
2022-03-31 11:32:43,379 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.final_layer_norm.weight
2022-03-31 11:32:43,379 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.6.final_layer_norm.bias
2022-03-31 11:32:43,379 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.k_proj.weight
2022-03-31 11:32:43,379 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.k_proj.bias
2022-03-31 11:32:43,379 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.v_proj.weight
2022-03-31 11:32:43,379 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.v_proj.bias
2022-03-31 11:32:43,379 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.q_proj.weight
2022-03-31 11:32:43,379 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.q_proj.bias
2022-03-31 11:32:43,379 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.out_proj.weight
2022-03-31 11:32:43,379 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn.out_proj.bias
2022-03-31 11:32:43,380 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn_layer_norm.weight
2022-03-31 11:32:43,380 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.self_attn_layer_norm.bias
2022-03-31 11:32:43,380 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.fc1.weight
2022-03-31 11:32:43,380 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.fc1.bias
2022-03-31 11:32:43,380 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.fc2.weight
2022-03-31 11:32:43,380 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.fc2.bias
2022-03-31 11:32:43,380 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.final_layer_norm.weight
2022-03-31 11:32:43,380 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.7.final_layer_norm.bias
2022-03-31 11:32:43,380 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.k_proj.weight
2022-03-31 11:32:43,380 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.k_proj.bias
2022-03-31 11:32:43,381 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.v_proj.weight
2022-03-31 11:32:43,381 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.v_proj.bias
2022-03-31 11:32:43,381 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.q_proj.weight
2022-03-31 11:32:43,381 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.q_proj.bias
2022-03-31 11:32:43,381 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.out_proj.weight
2022-03-31 11:32:43,381 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn.out_proj.bias
2022-03-31 11:32:43,381 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn_layer_norm.weight
2022-03-31 11:32:43,381 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.self_attn_layer_norm.bias
2022-03-31 11:32:43,381 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.fc1.weight
2022-03-31 11:32:43,381 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.fc1.bias
2022-03-31 11:32:43,381 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.fc2.weight
2022-03-31 11:32:43,382 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.fc2.bias
2022-03-31 11:32:43,382 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.final_layer_norm.weight
2022-03-31 11:32:43,382 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.8.final_layer_norm.bias
2022-03-31 11:32:43,382 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.k_proj.weight
2022-03-31 11:32:43,382 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.k_proj.bias
2022-03-31 11:32:43,382 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.v_proj.weight
2022-03-31 11:32:43,382 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.v_proj.bias
2022-03-31 11:32:43,382 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.q_proj.weight
2022-03-31 11:32:43,382 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.q_proj.bias
2022-03-31 11:32:43,382 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.out_proj.weight
2022-03-31 11:32:43,382 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn.out_proj.bias
2022-03-31 11:32:43,383 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn_layer_norm.weight
2022-03-31 11:32:43,383 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.self_attn_layer_norm.bias
2022-03-31 11:32:43,383 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.fc1.weight
2022-03-31 11:32:43,383 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.fc1.bias
2022-03-31 11:32:43,383 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.fc2.weight
2022-03-31 11:32:43,383 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.fc2.bias
2022-03-31 11:32:43,383 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.final_layer_norm.weight
2022-03-31 11:32:43,383 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.9.final_layer_norm.bias
2022-03-31 11:32:43,383 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.k_proj.weight
2022-03-31 11:32:43,383 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.k_proj.bias
2022-03-31 11:32:43,383 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.v_proj.weight
2022-03-31 11:32:43,384 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.v_proj.bias
2022-03-31 11:32:43,384 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.q_proj.weight
2022-03-31 11:32:43,384 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.q_proj.bias
2022-03-31 11:32:43,384 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.out_proj.weight
2022-03-31 11:32:43,384 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn.out_proj.bias
2022-03-31 11:32:43,384 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn_layer_norm.weight
2022-03-31 11:32:43,384 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.self_attn_layer_norm.bias
2022-03-31 11:32:43,384 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.fc1.weight
2022-03-31 11:32:43,384 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.fc1.bias
2022-03-31 11:32:43,384 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.fc2.weight
2022-03-31 11:32:43,384 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.fc2.bias
2022-03-31 11:32:43,385 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.final_layer_norm.weight
2022-03-31 11:32:43,385 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.10.final_layer_norm.bias
2022-03-31 11:32:43,385 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.k_proj.weight
2022-03-31 11:32:43,385 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.k_proj.bias
2022-03-31 11:32:43,385 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.v_proj.weight
2022-03-31 11:32:43,385 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.v_proj.bias
2022-03-31 11:32:43,385 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.q_proj.weight
2022-03-31 11:32:43,385 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.q_proj.bias
2022-03-31 11:32:43,385 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.out_proj.weight
2022-03-31 11:32:43,385 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn.out_proj.bias
2022-03-31 11:32:43,385 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn_layer_norm.weight
2022-03-31 11:32:43,385 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.self_attn_layer_norm.bias
2022-03-31 11:32:43,386 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.fc1.weight
2022-03-31 11:32:43,386 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.fc1.bias
2022-03-31 11:32:43,386 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.fc2.weight
2022-03-31 11:32:43,386 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.fc2.bias
2022-03-31 11:32:43,386 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.final_layer_norm.weight
2022-03-31 11:32:43,386 - INFO - allennlp.common.util - _seq2seq.model.encoder.layers.11.final_layer_norm.bias
2022-03-31 11:32:43,386 - INFO - allennlp.common.util - _seq2seq.model.encoder.layernorm_embedding.weight
2022-03-31 11:32:43,386 - INFO - allennlp.common.util - _seq2seq.model.encoder.layernorm_embedding.bias
2022-03-31 11:32:43,386 - INFO - allennlp.common.util - _seq2seq.model.decoder.embed_positions.weight
2022-03-31 11:32:43,386 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.k_proj.weight
2022-03-31 11:32:43,386 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.k_proj.bias
2022-03-31 11:32:43,386 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.v_proj.weight
2022-03-31 11:32:43,387 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.v_proj.bias
2022-03-31 11:32:43,387 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.q_proj.weight
2022-03-31 11:32:43,387 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.q_proj.bias
2022-03-31 11:32:43,387 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.out_proj.weight
2022-03-31 11:32:43,387 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn.out_proj.bias
2022-03-31 11:32:43,387 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn_layer_norm.weight
2022-03-31 11:32:43,387 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.self_attn_layer_norm.bias
2022-03-31 11:32:43,387 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.k_proj.weight
2022-03-31 11:32:43,387 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.k_proj.bias
2022-03-31 11:32:43,387 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.v_proj.weight
2022-03-31 11:32:43,387 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.v_proj.bias
2022-03-31 11:32:43,388 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.q_proj.weight
2022-03-31 11:32:43,388 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.q_proj.bias
2022-03-31 11:32:43,388 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.out_proj.weight
2022-03-31 11:32:43,388 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn.out_proj.bias
2022-03-31 11:32:43,388 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn_layer_norm.weight
2022-03-31 11:32:43,388 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.encoder_attn_layer_norm.bias
2022-03-31 11:32:43,388 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.fc1.weight
2022-03-31 11:32:43,388 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.fc1.bias
2022-03-31 11:32:43,388 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.fc2.weight
2022-03-31 11:32:43,388 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.fc2.bias
2022-03-31 11:32:43,389 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.final_layer_norm.weight
2022-03-31 11:32:43,389 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.0.final_layer_norm.bias
2022-03-31 11:32:43,389 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.k_proj.weight
2022-03-31 11:32:43,389 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.k_proj.bias
2022-03-31 11:32:43,389 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.v_proj.weight
2022-03-31 11:32:43,389 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.v_proj.bias
2022-03-31 11:32:43,389 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.q_proj.weight
2022-03-31 11:32:43,389 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.q_proj.bias
2022-03-31 11:32:43,389 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.out_proj.weight
2022-03-31 11:32:43,389 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn.out_proj.bias
2022-03-31 11:32:43,390 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn_layer_norm.weight
2022-03-31 11:32:43,390 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.self_attn_layer_norm.bias
2022-03-31 11:32:43,390 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.k_proj.weight
2022-03-31 11:32:43,390 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.k_proj.bias
2022-03-31 11:32:43,390 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.v_proj.weight
2022-03-31 11:32:43,390 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.v_proj.bias
2022-03-31 11:32:43,390 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.q_proj.weight
2022-03-31 11:32:43,390 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.q_proj.bias
2022-03-31 11:32:43,390 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.out_proj.weight
2022-03-31 11:32:43,390 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn.out_proj.bias
2022-03-31 11:32:43,390 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn_layer_norm.weight
2022-03-31 11:32:43,391 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.encoder_attn_layer_norm.bias
2022-03-31 11:32:43,391 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.fc1.weight
2022-03-31 11:32:43,391 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.fc1.bias
2022-03-31 11:32:43,391 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.fc2.weight
2022-03-31 11:32:43,391 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.fc2.bias
2022-03-31 11:32:43,391 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.final_layer_norm.weight
2022-03-31 11:32:43,391 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.1.final_layer_norm.bias
2022-03-31 11:32:43,391 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.k_proj.weight
2022-03-31 11:32:43,391 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.k_proj.bias
2022-03-31 11:32:43,392 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.v_proj.weight
2022-03-31 11:32:43,392 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.v_proj.bias
2022-03-31 11:32:43,392 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.q_proj.weight
2022-03-31 11:32:43,392 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.q_proj.bias
2022-03-31 11:32:43,392 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.out_proj.weight
2022-03-31 11:32:43,392 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn.out_proj.bias
2022-03-31 11:32:43,392 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn_layer_norm.weight
2022-03-31 11:32:43,392 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.self_attn_layer_norm.bias
2022-03-31 11:32:43,392 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.k_proj.weight
2022-03-31 11:32:43,392 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.k_proj.bias
2022-03-31 11:32:43,392 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.v_proj.weight
2022-03-31 11:32:43,393 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.v_proj.bias
2022-03-31 11:32:43,393 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.q_proj.weight
2022-03-31 11:32:43,393 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.q_proj.bias
2022-03-31 11:32:43,393 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.out_proj.weight
2022-03-31 11:32:43,393 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn.out_proj.bias
2022-03-31 11:32:43,393 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn_layer_norm.weight
2022-03-31 11:32:43,393 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.encoder_attn_layer_norm.bias
2022-03-31 11:32:43,393 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.fc1.weight
2022-03-31 11:32:43,393 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.fc1.bias
2022-03-31 11:32:43,393 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.fc2.weight
2022-03-31 11:32:43,393 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.fc2.bias
2022-03-31 11:32:43,394 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.final_layer_norm.weight
2022-03-31 11:32:43,394 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.2.final_layer_norm.bias
2022-03-31 11:32:43,394 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.k_proj.weight
2022-03-31 11:32:43,394 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.k_proj.bias
2022-03-31 11:32:43,394 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.v_proj.weight
2022-03-31 11:32:43,394 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.v_proj.bias
2022-03-31 11:32:43,394 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.q_proj.weight
2022-03-31 11:32:43,394 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.q_proj.bias
2022-03-31 11:32:43,394 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.out_proj.weight
2022-03-31 11:32:43,394 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn.out_proj.bias
2022-03-31 11:32:43,395 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn_layer_norm.weight
2022-03-31 11:32:43,395 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.self_attn_layer_norm.bias
2022-03-31 11:32:43,395 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.k_proj.weight
2022-03-31 11:32:43,395 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.k_proj.bias
2022-03-31 11:32:43,395 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.v_proj.weight
2022-03-31 11:32:43,395 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.v_proj.bias
2022-03-31 11:32:43,395 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.q_proj.weight
2022-03-31 11:32:43,395 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.q_proj.bias
2022-03-31 11:32:43,395 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.out_proj.weight
2022-03-31 11:32:43,395 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn.out_proj.bias
2022-03-31 11:32:43,395 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn_layer_norm.weight
2022-03-31 11:32:43,395 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.encoder_attn_layer_norm.bias
2022-03-31 11:32:43,396 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.fc1.weight
2022-03-31 11:32:43,396 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.fc1.bias
2022-03-31 11:32:43,396 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.fc2.weight
2022-03-31 11:32:43,396 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.fc2.bias
2022-03-31 11:32:43,396 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.final_layer_norm.weight
2022-03-31 11:32:43,396 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.3.final_layer_norm.bias
2022-03-31 11:32:43,396 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.k_proj.weight
2022-03-31 11:32:43,396 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.k_proj.bias
2022-03-31 11:32:43,396 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.v_proj.weight
2022-03-31 11:32:43,396 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.v_proj.bias
2022-03-31 11:32:43,397 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.q_proj.weight
2022-03-31 11:32:43,397 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.q_proj.bias
2022-03-31 11:32:43,397 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.out_proj.weight
2022-03-31 11:32:43,397 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn.out_proj.bias
2022-03-31 11:32:43,397 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn_layer_norm.weight
2022-03-31 11:32:43,397 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.self_attn_layer_norm.bias
2022-03-31 11:32:43,397 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.k_proj.weight
2022-03-31 11:32:43,397 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.k_proj.bias
2022-03-31 11:32:43,397 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.v_proj.weight
2022-03-31 11:32:43,397 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.v_proj.bias
2022-03-31 11:32:43,397 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.q_proj.weight
2022-03-31 11:32:43,397 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.q_proj.bias
2022-03-31 11:32:43,398 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.out_proj.weight
2022-03-31 11:32:43,398 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn.out_proj.bias
2022-03-31 11:32:43,398 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn_layer_norm.weight
2022-03-31 11:32:43,398 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.encoder_attn_layer_norm.bias
2022-03-31 11:32:43,398 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.fc1.weight
2022-03-31 11:32:43,398 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.fc1.bias
2022-03-31 11:32:43,398 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.fc2.weight
2022-03-31 11:32:43,398 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.fc2.bias
2022-03-31 11:32:43,398 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.final_layer_norm.weight
2022-03-31 11:32:43,398 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.4.final_layer_norm.bias
2022-03-31 11:32:43,399 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.k_proj.weight
2022-03-31 11:32:43,399 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.k_proj.bias
2022-03-31 11:32:43,399 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.v_proj.weight
2022-03-31 11:32:43,399 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.v_proj.bias
2022-03-31 11:32:43,399 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.q_proj.weight
2022-03-31 11:32:43,399 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.q_proj.bias
2022-03-31 11:32:43,399 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.out_proj.weight
2022-03-31 11:32:43,399 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn.out_proj.bias
2022-03-31 11:32:43,399 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn_layer_norm.weight
2022-03-31 11:32:43,399 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.self_attn_layer_norm.bias
2022-03-31 11:32:43,399 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.k_proj.weight
2022-03-31 11:32:43,400 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.k_proj.bias
2022-03-31 11:32:43,400 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.v_proj.weight
2022-03-31 11:32:43,400 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.v_proj.bias
2022-03-31 11:32:43,400 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.q_proj.weight
2022-03-31 11:32:43,400 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.q_proj.bias
2022-03-31 11:32:43,400 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.out_proj.weight
2022-03-31 11:32:43,400 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn.out_proj.bias
2022-03-31 11:32:43,400 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn_layer_norm.weight
2022-03-31 11:32:43,400 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.encoder_attn_layer_norm.bias
2022-03-31 11:32:43,400 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.fc1.weight
2022-03-31 11:32:43,401 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.fc1.bias
2022-03-31 11:32:43,401 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.fc2.weight
2022-03-31 11:32:43,401 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.fc2.bias
2022-03-31 11:32:43,401 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.final_layer_norm.weight
2022-03-31 11:32:43,401 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.5.final_layer_norm.bias
2022-03-31 11:32:43,401 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.k_proj.weight
2022-03-31 11:32:43,401 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.k_proj.bias
2022-03-31 11:32:43,401 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.v_proj.weight
2022-03-31 11:32:43,401 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.v_proj.bias
2022-03-31 11:32:43,401 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.q_proj.weight
2022-03-31 11:32:43,401 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.q_proj.bias
2022-03-31 11:32:43,402 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.out_proj.weight
2022-03-31 11:32:43,402 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn.out_proj.bias
2022-03-31 11:32:43,402 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn_layer_norm.weight
2022-03-31 11:32:43,402 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.self_attn_layer_norm.bias
2022-03-31 11:32:43,402 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.k_proj.weight
2022-03-31 11:32:43,402 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.k_proj.bias
2022-03-31 11:32:43,402 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.v_proj.weight
2022-03-31 11:32:43,402 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.v_proj.bias
2022-03-31 11:32:43,402 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.q_proj.weight
2022-03-31 11:32:43,402 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.q_proj.bias
2022-03-31 11:32:43,402 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.out_proj.weight
2022-03-31 11:32:43,403 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn.out_proj.bias
2022-03-31 11:32:43,403 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn_layer_norm.weight
2022-03-31 11:32:43,403 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.encoder_attn_layer_norm.bias
2022-03-31 11:32:43,403 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.fc1.weight
2022-03-31 11:32:43,403 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.fc1.bias
2022-03-31 11:32:43,403 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.fc2.weight
2022-03-31 11:32:43,403 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.fc2.bias
2022-03-31 11:32:43,403 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.final_layer_norm.weight
2022-03-31 11:32:43,403 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.6.final_layer_norm.bias
2022-03-31 11:32:43,403 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.k_proj.weight
2022-03-31 11:32:43,403 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.k_proj.bias
2022-03-31 11:32:43,404 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.v_proj.weight
2022-03-31 11:32:43,404 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.v_proj.bias
2022-03-31 11:32:43,404 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.q_proj.weight
2022-03-31 11:32:43,404 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.q_proj.bias
2022-03-31 11:32:43,404 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.out_proj.weight
2022-03-31 11:32:43,404 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn.out_proj.bias
2022-03-31 11:32:43,404 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn_layer_norm.weight
2022-03-31 11:32:43,404 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.self_attn_layer_norm.bias
2022-03-31 11:32:43,404 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.k_proj.weight
2022-03-31 11:32:43,404 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.k_proj.bias
2022-03-31 11:32:43,404 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.v_proj.weight
2022-03-31 11:32:43,405 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.v_proj.bias
2022-03-31 11:32:43,405 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.q_proj.weight
2022-03-31 11:32:43,405 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.q_proj.bias
2022-03-31 11:32:43,405 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.out_proj.weight
2022-03-31 11:32:43,405 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn.out_proj.bias
2022-03-31 11:32:43,405 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn_layer_norm.weight
2022-03-31 11:32:43,405 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.encoder_attn_layer_norm.bias
2022-03-31 11:32:43,405 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.fc1.weight
2022-03-31 11:32:43,405 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.fc1.bias
2022-03-31 11:32:43,405 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.fc2.weight
2022-03-31 11:32:43,405 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.fc2.bias
2022-03-31 11:32:43,406 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.final_layer_norm.weight
2022-03-31 11:32:43,406 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.7.final_layer_norm.bias
2022-03-31 11:32:43,406 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.k_proj.weight
2022-03-31 11:32:43,406 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.k_proj.bias
2022-03-31 11:32:43,406 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.v_proj.weight
2022-03-31 11:32:43,406 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.v_proj.bias
2022-03-31 11:32:43,406 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.q_proj.weight
2022-03-31 11:32:43,406 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.q_proj.bias
2022-03-31 11:32:43,406 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.out_proj.weight
2022-03-31 11:32:43,406 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn.out_proj.bias
2022-03-31 11:32:43,407 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn_layer_norm.weight
2022-03-31 11:32:43,407 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.self_attn_layer_norm.bias
2022-03-31 11:32:43,407 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.k_proj.weight
2022-03-31 11:32:43,407 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.k_proj.bias
2022-03-31 11:32:43,407 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.v_proj.weight
2022-03-31 11:32:43,407 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.v_proj.bias
2022-03-31 11:32:43,407 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.q_proj.weight
2022-03-31 11:32:43,407 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.q_proj.bias
2022-03-31 11:32:43,407 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.out_proj.weight
2022-03-31 11:32:43,407 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn.out_proj.bias
2022-03-31 11:32:43,407 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn_layer_norm.weight
2022-03-31 11:32:43,408 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.encoder_attn_layer_norm.bias
2022-03-31 11:32:43,408 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.fc1.weight
2022-03-31 11:32:43,408 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.fc1.bias
2022-03-31 11:32:43,408 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.fc2.weight
2022-03-31 11:32:43,408 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.fc2.bias
2022-03-31 11:32:43,408 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.final_layer_norm.weight
2022-03-31 11:32:43,408 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.8.final_layer_norm.bias
2022-03-31 11:32:43,408 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.k_proj.weight
2022-03-31 11:32:43,408 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.k_proj.bias
2022-03-31 11:32:43,408 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.v_proj.weight
2022-03-31 11:32:43,408 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.v_proj.bias
2022-03-31 11:32:43,409 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.q_proj.weight
2022-03-31 11:32:43,409 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.q_proj.bias
2022-03-31 11:32:43,409 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.out_proj.weight
2022-03-31 11:32:43,409 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn.out_proj.bias
2022-03-31 11:32:43,409 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn_layer_norm.weight
2022-03-31 11:32:43,409 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.self_attn_layer_norm.bias
2022-03-31 11:32:43,409 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.k_proj.weight
2022-03-31 11:32:43,409 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.k_proj.bias
2022-03-31 11:32:43,409 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.v_proj.weight
2022-03-31 11:32:43,409 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.v_proj.bias
2022-03-31 11:32:43,409 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.q_proj.weight
2022-03-31 11:32:43,410 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.q_proj.bias
2022-03-31 11:32:43,410 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.out_proj.weight
2022-03-31 11:32:43,410 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn.out_proj.bias
2022-03-31 11:32:43,410 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn_layer_norm.weight
2022-03-31 11:32:43,410 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.encoder_attn_layer_norm.bias
2022-03-31 11:32:43,410 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.fc1.weight
2022-03-31 11:32:43,410 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.fc1.bias
2022-03-31 11:32:43,410 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.fc2.weight
2022-03-31 11:32:43,410 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.fc2.bias
2022-03-31 11:32:43,410 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.final_layer_norm.weight
2022-03-31 11:32:43,410 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.9.final_layer_norm.bias
2022-03-31 11:32:43,411 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.k_proj.weight
2022-03-31 11:32:43,411 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.k_proj.bias
2022-03-31 11:32:43,411 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.v_proj.weight
2022-03-31 11:32:43,411 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.v_proj.bias
2022-03-31 11:32:43,411 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.q_proj.weight
2022-03-31 11:32:43,411 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.q_proj.bias
2022-03-31 11:32:43,411 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.out_proj.weight
2022-03-31 11:32:43,411 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn.out_proj.bias
2022-03-31 11:32:43,411 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn_layer_norm.weight
2022-03-31 11:32:43,411 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.self_attn_layer_norm.bias
2022-03-31 11:32:43,411 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.k_proj.weight
2022-03-31 11:32:43,412 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.k_proj.bias
2022-03-31 11:32:43,412 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.v_proj.weight
2022-03-31 11:32:43,412 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.v_proj.bias
2022-03-31 11:32:43,412 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.q_proj.weight
2022-03-31 11:32:43,412 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.q_proj.bias
2022-03-31 11:32:43,412 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.out_proj.weight
2022-03-31 11:32:43,412 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn.out_proj.bias
2022-03-31 11:32:43,412 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn_layer_norm.weight
2022-03-31 11:32:43,412 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.encoder_attn_layer_norm.bias
2022-03-31 11:32:43,412 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.fc1.weight
2022-03-31 11:32:43,412 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.fc1.bias
2022-03-31 11:32:43,412 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.fc2.weight
2022-03-31 11:32:43,413 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.fc2.bias
2022-03-31 11:32:43,413 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.final_layer_norm.weight
2022-03-31 11:32:43,413 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.10.final_layer_norm.bias
2022-03-31 11:32:43,413 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.k_proj.weight
2022-03-31 11:32:43,413 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.k_proj.bias
2022-03-31 11:32:43,413 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.v_proj.weight
2022-03-31 11:32:43,413 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.v_proj.bias
2022-03-31 11:32:43,413 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.q_proj.weight
2022-03-31 11:32:43,413 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.q_proj.bias
2022-03-31 11:32:43,413 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.out_proj.weight
2022-03-31 11:32:43,413 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn.out_proj.bias
2022-03-31 11:32:43,414 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn_layer_norm.weight
2022-03-31 11:32:43,414 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.self_attn_layer_norm.bias
2022-03-31 11:32:43,414 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.k_proj.weight
2022-03-31 11:32:43,414 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.k_proj.bias
2022-03-31 11:32:43,414 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.v_proj.weight
2022-03-31 11:32:43,414 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.v_proj.bias
2022-03-31 11:32:43,414 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.q_proj.weight
2022-03-31 11:32:43,414 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.q_proj.bias
2022-03-31 11:32:43,414 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.out_proj.weight
2022-03-31 11:32:43,414 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn.out_proj.bias
2022-03-31 11:32:43,415 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn_layer_norm.weight
2022-03-31 11:32:43,415 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.encoder_attn_layer_norm.bias
2022-03-31 11:32:43,415 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.fc1.weight
2022-03-31 11:32:43,415 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.fc1.bias
2022-03-31 11:32:43,415 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.fc2.weight
2022-03-31 11:32:43,415 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.fc2.bias
2022-03-31 11:32:43,415 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.final_layer_norm.weight
2022-03-31 11:32:43,415 - INFO - allennlp.common.util - _seq2seq.model.decoder.layers.11.final_layer_norm.bias
2022-03-31 11:32:43,415 - INFO - allennlp.common.util - _seq2seq.model.decoder.layernorm_embedding.weight
2022-03-31 11:32:43,415 - INFO - allennlp.common.util - _seq2seq.model.decoder.layernorm_embedding.bias
2022-03-31 11:32:43,416 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = polynomial_decay
2022-03-31 11:32:43,416 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.power = 1.0
2022-03-31 11:32:43,416 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.warmup_steps = 0
2022-03-31 11:32:43,416 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.end_learning_rate = 0.0
2022-03-31 11:32:43,416 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.last_epoch = -1
2022-03-31 11:32:43,416 - INFO - allennlp.common.params - trainer.checkpointer.type = default
2022-03-31 11:32:43,417 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None
2022-03-31 11:32:43,417 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = -1
2022-03-31 11:32:43,417 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None
2022-03-31 11:32:43,417 - INFO - allennlp.common.params - summary_interval = 100
2022-03-31 11:32:43,417 - INFO - allennlp.common.params - histogram_interval = None
2022-03-31 11:32:43,417 - INFO - allennlp.common.params - batch_size_interval = None
2022-03-31 11:32:43,417 - INFO - allennlp.common.params - should_log_parameter_statistics = True
2022-03-31 11:32:43,417 - INFO - allennlp.common.params - should_log_learning_rate = False
2022-03-31 11:32:43,417 - INFO - allennlp.common.params - get_batch_num_total = None
2022-03-31 11:32:43,420 - WARNING - allennlp.training.trainer - You provided a validation dataset but patience was set to None, meaning that early stopping is disabled
2022-03-31 11:32:58,396 - INFO - allennlp.training.trainer - Beginning training.
2022-03-31 11:32:58,396 - INFO - allennlp.training.trainer - Epoch 8/14
2022-03-31 11:32:58,396 - INFO - allennlp.training.trainer - Worker 0 memory usage: 12G
2022-03-31 11:32:58,397 - INFO - allennlp.training.trainer - GPU 0 memory usage: 4.5G
2022-03-31 11:32:58,398 - INFO - allennlp.training.trainer - Training
2022-03-31 11:32:58,399 - INFO - tqdm - 0%|          | 0/65 [00:00<?, ?it/s]
2022-03-31 11:32:58,399 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-31 11:32:58,399 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['target_ids'] as the sorting keys
2022-03-31 11:33:08,501 - INFO - tqdm - batch_loss: 1.1342, loss: 1.1709 ||:   9%|9         | 6/65 [00:10<01:39,  1.68s/it]
2022-03-31 11:33:19,935 - INFO - tqdm - batch_loss: 1.0528, loss: 1.1535 ||:  20%|##        | 13/65 [00:21<01:24,  1.63s/it]
2022-03-31 11:33:31,451 - INFO - tqdm - batch_loss: 1.1348, loss: 1.1475 ||:  31%|###       | 20/65 [00:33<01:13,  1.64s/it]
2022-03-31 11:33:42,955 - INFO - tqdm - batch_loss: 1.0279, loss: 1.1388 ||:  42%|####1     | 27/65 [00:44<01:02,  1.65s/it]
2022-03-31 11:33:54,609 - INFO - tqdm - batch_loss: 1.2521, loss: 1.1495 ||:  52%|#####2    | 34/65 [00:56<00:51,  1.66s/it]
2022-03-31 11:34:06,270 - INFO - tqdm - batch_loss: 1.2235, loss: 1.1495 ||:  63%|######3   | 41/65 [01:07<00:40,  1.68s/it]
2022-03-31 11:34:16,312 - INFO - tqdm - batch_loss: 1.1206, loss: 1.1475 ||:  72%|#######2  | 47/65 [01:17<00:30,  1.67s/it]
2022-03-31 11:34:26,321 - INFO - tqdm - batch_loss: 1.0462, loss: 1.1444 ||:  82%|########1 | 53/65 [01:27<00:20,  1.68s/it]
2022-03-31 11:34:36,376 - INFO - tqdm - batch_loss: 1.1912, loss: 1.1460 ||:  91%|######### | 59/65 [01:37<00:10,  1.67s/it]
2022-03-31 11:34:45,630 - INFO - tqdm - batch_loss: 1.2327, loss: 1.1489 ||: 100%|##########| 65/65 [01:47<00:00,  1.43s/it]
2022-03-31 11:34:45,630 - INFO - tqdm - batch_loss: 1.2327, loss: 1.1489 ||: 100%|##########| 65/65 [01:47<00:00,  1.65s/it]
2022-03-31 11:34:48,192 - INFO - allennlp.training.trainer - Validating
2022-03-31 11:34:48,193 - INFO - tqdm - 0%|          | 0/115 [00:00<?, ?it/s]
2022-03-31 11:34:48,194 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-03-31 11:34:48,194 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['target_ids'] as the sorting keys
2022-03-31 11:34:59,206 - INFO - tqdm - bleu_BLEU: 0.2133, rouge_ROUGE-1_R: 0.4685, rouge_ROUGE-2_R: 0.3125, rouge_ROUGE-1_P: 0.6412, rouge_ROUGE-2_P: 0.4335, rouge_ROUGE-1_F1: 0.5290, rouge_ROUGE-2_F1: 0.3546, rouge_ROUGE-L: 0.4690, SARI: 0.5377, count: 22.0000, batch_loss: 1.2603, loss: 1.4142 ||:  10%|9         | 11/115 [00:11<01:49,  1.06s/it]
2022-03-31 11:35:09,932 - INFO - tqdm - bleu_BLEU: 0.2250, rouge_ROUGE-1_R: 0.5007, rouge_ROUGE-2_R: 0.3296, rouge_ROUGE-1_P: 0.6416, rouge_ROUGE-2_P: 0.4276, rouge_ROUGE-1_F1: 0.5483, rouge_ROUGE-2_F1: 0.3629, rouge_ROUGE-L: 0.4793, SARI: 0.5615, count: 44.0000, batch_loss: 1.2705, loss: 1.3766 ||:  19%|#9        | 22/115 [00:21<01:34,  1.02s/it]
2022-03-31 11:35:19,941 - INFO - tqdm - bleu_BLEU: 0.2294, rouge_ROUGE-1_R: 0.5132, rouge_ROUGE-2_R: 0.3350, rouge_ROUGE-1_P: 0.6366, rouge_ROUGE-2_P: 0.4192, rouge_ROUGE-1_F1: 0.5557, rouge_ROUGE-2_F1: 0.3639, rouge_ROUGE-L: 0.4812, SARI: 0.5575, count: 64.0000, batch_loss: 1.2946, loss: 1.3568 ||:  28%|##7       | 32/115 [00:31<01:25,  1.03s/it]
2022-03-31 11:35:30,948 - INFO - tqdm - bleu_BLEU: 0.2458, rouge_ROUGE-1_R: 0.5275, rouge_ROUGE-2_R: 0.3477, rouge_ROUGE-1_P: 0.6257, rouge_ROUGE-2_P: 0.4154, rouge_ROUGE-1_F1: 0.5588, rouge_ROUGE-2_F1: 0.3693, rouge_ROUGE-L: 0.4836, SARI: 0.5672, count: 84.0000, batch_loss: 1.0162, loss: 1.3894 ||:  37%|###6      | 42/115 [00:42<01:23,  1.14s/it]
2022-03-31 11:35:41,158 - INFO - tqdm - bleu_BLEU: 0.2383, rouge_ROUGE-1_R: 0.5223, rouge_ROUGE-2_R: 0.3443, rouge_ROUGE-1_P: 0.6315, rouge_ROUGE-2_P: 0.4185, rouge_ROUGE-1_F1: 0.5572, rouge_ROUGE-2_F1: 0.3679, rouge_ROUGE-L: 0.4829, SARI: 0.5611, count: 104.0000, batch_loss: 0.6277, loss: 1.3947 ||:  45%|####5     | 52/115 [00:52<01:04,  1.03s/it]
2022-03-31 11:35:51,757 - INFO - tqdm - bleu_BLEU: 0.2363, rouge_ROUGE-1_R: 0.5205, rouge_ROUGE-2_R: 0.3418, rouge_ROUGE-1_P: 0.6322, rouge_ROUGE-2_P: 0.4180, rouge_ROUGE-1_F1: 0.5562, rouge_ROUGE-2_F1: 0.3662, rouge_ROUGE-L: 0.4797, SARI: 0.5595, count: 124.0000, batch_loss: 1.6920, loss: 1.3970 ||:  54%|#####3    | 62/115 [01:03<00:58,  1.10s/it]
2022-03-31 11:36:02,618 - INFO - tqdm - bleu_BLEU: 0.2205, rouge_ROUGE-1_R: 0.5068, rouge_ROUGE-2_R: 0.3283, rouge_ROUGE-1_P: 0.6280, rouge_ROUGE-2_P: 0.4093, rouge_ROUGE-1_F1: 0.5455, rouge_ROUGE-2_F1: 0.3541, rouge_ROUGE-L: 0.4696, SARI: 0.5545, count: 144.0000, batch_loss: 1.2885, loss: 1.4269 ||:  63%|######2   | 72/115 [01:14<00:47,  1.11s/it]
2022-03-31 11:36:13,132 - INFO - tqdm - bleu_BLEU: 0.2267, rouge_ROUGE-1_R: 0.5140, rouge_ROUGE-2_R: 0.3333, rouge_ROUGE-1_P: 0.6259, rouge_ROUGE-2_P: 0.4082, rouge_ROUGE-1_F1: 0.5490, rouge_ROUGE-2_F1: 0.3568, rouge_ROUGE-L: 0.4702, SARI: 0.5556, count: 161.0000, batch_loss: 0.3861, loss: 1.4108 ||:  70%|#######   | 81/115 [01:24<00:39,  1.17s/it]
2022-03-31 11:36:24,108 - INFO - tqdm - bleu_BLEU: 0.2236, rouge_ROUGE-1_R: 0.5109, rouge_ROUGE-2_R: 0.3300, rouge_ROUGE-1_P: 0.6259, rouge_ROUGE-2_P: 0.4072, rouge_ROUGE-1_F1: 0.5480, rouge_ROUGE-2_F1: 0.3548, rouge_ROUGE-L: 0.4687, SARI: 0.5497, count: 183.0000, batch_loss: 1.4167, loss: 1.4251 ||:  80%|########  | 92/115 [01:35<00:23,  1.04s/it]
2022-03-31 11:36:34,961 - INFO - tqdm - bleu_BLEU: 0.2214, rouge_ROUGE-1_R: 0.5038, rouge_ROUGE-2_R: 0.3262, rouge_ROUGE-1_P: 0.6242, rouge_ROUGE-2_P: 0.4079, rouge_ROUGE-1_F1: 0.5433, rouge_ROUGE-2_F1: 0.3531, rouge_ROUGE-L: 0.4655, SARI: 0.5517, count: 203.0000, batch_loss: 0.6767, loss: 1.4237 ||:  89%|########8 | 102/115 [01:46<00:14,  1.10s/it]
2022-03-31 11:36:45,321 - INFO - tqdm - bleu_BLEU: 0.2264, rouge_ROUGE-1_R: 0.5074, rouge_ROUGE-2_R: 0.3299, rouge_ROUGE-1_P: 0.6271, rouge_ROUGE-2_P: 0.4117, rouge_ROUGE-1_F1: 0.5475, rouge_ROUGE-2_F1: 0.3574, rouge_ROUGE-L: 0.4704, SARI: 0.5513, count: 223.0000, batch_loss: 2.4213, loss: 1.4175 ||:  97%|#########7| 112/115 [01:57<00:03,  1.08s/it]
2022-03-31 11:36:48,363 - INFO - tqdm - bleu_BLEU: 0.2297, rouge_ROUGE-1_R: 0.5107, rouge_ROUGE-2_R: 0.3330, rouge_ROUGE-1_P: 0.6283, rouge_ROUGE-2_P: 0.4135, rouge_ROUGE-1_F1: 0.5502, rouge_ROUGE-2_F1: 0.3600, rouge_ROUGE-L: 0.4740, SARI: 0.5534, count: 229.0000, batch_loss: 0.8169, loss: 1.4085 ||: 100%|##########| 115/115 [02:00<00:00,  1.09s/it]
2022-03-31 11:36:48,363 - INFO - tqdm - bleu_BLEU: 0.2297, rouge_ROUGE-1_R: 0.5107, rouge_ROUGE-2_R: 0.3330, rouge_ROUGE-1_P: 0.6283, rouge_ROUGE-2_P: 0.4135, rouge_ROUGE-1_F1: 0.5502, rouge_ROUGE-2_F1: 0.3600, rouge_ROUGE-L: 0.4740, SARI: 0.5534, count: 229.0000, batch_loss: 0.8169, loss: 1.4085 ||: 100%|##########| 115/115 [02:00<00:00,  1.04s/it]
2022-03-31 11:36:48,364 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2022-03-31 11:36:48,365 - INFO - allennlp.training.tensorboard_writer - SARI               |       N/A  |     0.553
2022-03-31 11:36:48,366 - INFO - allennlp.training.tensorboard_writer - bleu_BLEU          |       N/A  |     0.230
2022-03-31 11:36:48,368 - INFO - allennlp.training.tensorboard_writer - count              |       N/A  |   229.000
2022-03-31 11:36:48,368 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |  4649.829  |       N/A
2022-03-31 11:36:48,369 - INFO - allennlp.training.tensorboard_writer - loss               |     1.149  |     1.409
2022-03-31 11:36:48,369 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_F1   |       N/A  |     0.550
2022-03-31 11:36:48,370 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_P    |       N/A  |     0.628
2022-03-31 11:36:48,371 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_R    |       N/A  |     0.511
2022-03-31 11:36:48,371 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_F1   |       N/A  |     0.360
2022-03-31 11:36:48,371 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_P    |       N/A  |     0.413
2022-03-31 11:36:48,372 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_R    |       N/A  |     0.333
2022-03-31 11:36:48,372 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-L      |       N/A  |     0.474
2022-03-31 11:36:48,372 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  12006.336  |       N/A
2022-03-31 11:36:53,425 - INFO - allennlp.training.trainer - Epoch duration: 0:03:55.028348
2022-03-31 11:36:53,425 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:23:30
2022-03-31 11:36:53,425 - INFO - allennlp.training.trainer - Epoch 9/14
2022-03-31 11:36:53,425 - INFO - allennlp.training.trainer - Worker 0 memory usage: 12G
2022-03-31 11:36:53,425 - INFO - allennlp.training.trainer - GPU 0 memory usage: 6.7G
2022-03-31 11:36:53,426 - INFO - allennlp.training.trainer - Training
2022-03-31 11:36:53,427 - INFO - tqdm - 0%|          | 0/65 [00:00<?, ?it/s]
2022-03-31 11:37:03,713 - INFO - tqdm - batch_loss: 0.9703, loss: 1.1213 ||:   9%|9         | 6/65 [00:10<01:41,  1.72s/it]
2022-03-31 11:37:13,842 - INFO - tqdm - batch_loss: 1.2217, loss: 1.1610 ||:  18%|#8        | 12/65 [00:20<01:30,  1.70s/it]
2022-03-31 11:37:24,491 - INFO - tqdm - batch_loss: 1.1276, loss: 1.1500 ||:  28%|##7       | 18/65 [00:31<01:22,  1.75s/it]
2022-03-31 11:37:34,700 - INFO - tqdm - batch_loss: 1.0747, loss: 1.1326 ||:  37%|###6      | 24/65 [00:41<01:09,  1.70s/it]
2022-03-31 11:37:44,939 - INFO - tqdm - batch_loss: 0.9979, loss: 1.1171 ||:  46%|####6     | 30/65 [00:51<00:59,  1.71s/it]
2022-03-31 11:37:55,240 - INFO - tqdm - batch_loss: 1.2349, loss: 1.1301 ||:  55%|#####5    | 36/65 [01:01<00:49,  1.71s/it]
2022-03-31 11:38:05,366 - INFO - tqdm - batch_loss: 1.0651, loss: 1.1313 ||:  65%|######4   | 42/65 [01:11<00:38,  1.68s/it]
2022-03-31 11:38:15,506 - INFO - tqdm - batch_loss: 1.2727, loss: 1.1437 ||:  74%|#######3  | 48/65 [01:22<00:28,  1.69s/it]
2022-03-31 11:38:27,146 - INFO - tqdm - batch_loss: 1.2038, loss: 1.1508 ||:  85%|########4 | 55/65 [01:33<00:16,  1.67s/it]
2022-03-31 11:38:37,166 - INFO - tqdm - batch_loss: 1.0058, loss: 1.1555 ||:  94%|#########3| 61/65 [01:43<00:06,  1.67s/it]
2022-03-31 11:38:42,919 - INFO - tqdm - batch_loss: 1.1288, loss: 1.1493 ||: 100%|##########| 65/65 [01:49<00:00,  1.40s/it]
2022-03-31 11:38:42,920 - INFO - tqdm - batch_loss: 1.1288, loss: 1.1493 ||: 100%|##########| 65/65 [01:49<00:00,  1.68s/it]
2022-03-31 11:38:45,487 - INFO - allennlp.training.trainer - Validating
2022-03-31 11:38:45,489 - INFO - tqdm - 0%|          | 0/115 [00:00<?, ?it/s]
2022-03-31 11:38:56,021 - INFO - tqdm - bleu_BLEU: 0.1645, rouge_ROUGE-1_R: 0.4330, rouge_ROUGE-2_R: 0.2702, rouge_ROUGE-1_P: 0.6489, rouge_ROUGE-2_P: 0.4149, rouge_ROUGE-1_F1: 0.5038, rouge_ROUGE-2_F1: 0.3167, rouge_ROUGE-L: 0.4457, SARI: 0.5248, count: 22.0000, batch_loss: 1.0665, loss: 1.4438 ||:  10%|9         | 11/115 [00:10<01:45,  1.02s/it]
2022-03-31 11:39:06,488 - INFO - tqdm - bleu_BLEU: 0.2053, rouge_ROUGE-1_R: 0.4693, rouge_ROUGE-2_R: 0.3023, rouge_ROUGE-1_P: 0.6496, rouge_ROUGE-2_P: 0.4262, rouge_ROUGE-1_F1: 0.5310, rouge_ROUGE-2_F1: 0.3442, rouge_ROUGE-L: 0.4579, SARI: 0.5157, count: 40.0000, batch_loss: 1.0364, loss: 1.3889 ||:  17%|#7        | 20/115 [00:20<01:42,  1.08s/it]
2022-03-31 11:39:17,184 - INFO - tqdm - bleu_BLEU: 0.2062, rouge_ROUGE-1_R: 0.4827, rouge_ROUGE-2_R: 0.3097, rouge_ROUGE-1_P: 0.6478, rouge_ROUGE-2_P: 0.4200, rouge_ROUGE-1_F1: 0.5405, rouge_ROUGE-2_F1: 0.3478, rouge_ROUGE-L: 0.4663, SARI: 0.5236, count: 60.0000, batch_loss: 1.9886, loss: 1.3878 ||:  26%|##6       | 30/115 [00:31<01:28,  1.04s/it]
2022-03-31 11:39:27,588 - INFO - tqdm - bleu_BLEU: 0.2062, rouge_ROUGE-1_R: 0.4820, rouge_ROUGE-2_R: 0.3050, rouge_ROUGE-1_P: 0.6321, rouge_ROUGE-2_P: 0.4054, rouge_ROUGE-1_F1: 0.5353, rouge_ROUGE-2_F1: 0.3403, rouge_ROUGE-L: 0.4617, SARI: 0.5281, count: 80.0000, batch_loss: 1.3004, loss: 1.4263 ||:  35%|###4      | 40/115 [00:42<01:17,  1.03s/it]
2022-03-31 11:39:37,719 - INFO - tqdm - bleu_BLEU: 0.2246, rouge_ROUGE-1_R: 0.5048, rouge_ROUGE-2_R: 0.3268, rouge_ROUGE-1_P: 0.6355, rouge_ROUGE-2_P: 0.4160, rouge_ROUGE-1_F1: 0.5489, rouge_ROUGE-2_F1: 0.3569, rouge_ROUGE-L: 0.4788, SARI: 0.5444, count: 102.0000, batch_loss: 1.8295, loss: 1.3878 ||:  44%|####4     | 51/115 [00:52<00:58,  1.10it/s]
2022-03-31 11:39:48,869 - INFO - tqdm - bleu_BLEU: 0.2196, rouge_ROUGE-1_R: 0.5022, rouge_ROUGE-2_R: 0.3241, rouge_ROUGE-1_P: 0.6333, rouge_ROUGE-2_P: 0.4128, rouge_ROUGE-1_F1: 0.5466, rouge_ROUGE-2_F1: 0.3542, rouge_ROUGE-L: 0.4773, SARI: 0.5415, count: 124.0000, batch_loss: 0.7310, loss: 1.4280 ||:  54%|#####3    | 62/115 [01:03<00:54,  1.04s/it]
2022-03-31 11:39:59,220 - INFO - tqdm - bleu_BLEU: 0.2187, rouge_ROUGE-1_R: 0.4996, rouge_ROUGE-2_R: 0.3220, rouge_ROUGE-1_P: 0.6343, rouge_ROUGE-2_P: 0.4125, rouge_ROUGE-1_F1: 0.5446, rouge_ROUGE-2_F1: 0.3522, rouge_ROUGE-L: 0.4775, SARI: 0.5421, count: 146.0000, batch_loss: 1.0690, loss: 1.4473 ||:  63%|######3   | 73/115 [01:13<00:35,  1.17it/s]
2022-03-31 11:40:09,257 - INFO - tqdm - bleu_BLEU: 0.2240, rouge_ROUGE-1_R: 0.5041, rouge_ROUGE-2_R: 0.3273, rouge_ROUGE-1_P: 0.6383, rouge_ROUGE-2_P: 0.4178, rouge_ROUGE-1_F1: 0.5489, rouge_ROUGE-2_F1: 0.3575, rouge_ROUGE-L: 0.4796, SARI: 0.5470, count: 164.0000, batch_loss: 0.6216, loss: 1.4076 ||:  71%|#######1  | 82/115 [01:23<00:37,  1.15s/it]
2022-03-31 11:40:19,441 - INFO - tqdm - bleu_BLEU: 0.2233, rouge_ROUGE-1_R: 0.5043, rouge_ROUGE-2_R: 0.3273, rouge_ROUGE-1_P: 0.6408, rouge_ROUGE-2_P: 0.4188, rouge_ROUGE-1_F1: 0.5504, rouge_ROUGE-2_F1: 0.3580, rouge_ROUGE-L: 0.4813, SARI: 0.5471, count: 185.0000, batch_loss: 1.9478, loss: 1.3979 ||:  81%|########  | 93/115 [01:33<00:20,  1.08it/s]
2022-03-31 11:40:29,443 - INFO - tqdm - bleu_BLEU: 0.2277, rouge_ROUGE-1_R: 0.5088, rouge_ROUGE-2_R: 0.3315, rouge_ROUGE-1_P: 0.6455, rouge_ROUGE-2_P: 0.4242, rouge_ROUGE-1_F1: 0.5552, rouge_ROUGE-2_F1: 0.3628, rouge_ROUGE-L: 0.4852, SARI: 0.5522, count: 205.0000, batch_loss: 1.8808, loss: 1.4118 ||:  90%|########9 | 103/115 [01:43<00:11,  1.02it/s]
2022-03-31 11:40:40,506 - INFO - tqdm - bleu_BLEU: 0.2288, rouge_ROUGE-1_R: 0.5084, rouge_ROUGE-2_R: 0.3329, rouge_ROUGE-1_P: 0.6474, rouge_ROUGE-2_P: 0.4276, rouge_ROUGE-1_F1: 0.5556, rouge_ROUGE-2_F1: 0.3648, rouge_ROUGE-L: 0.4849, SARI: 0.5560, count: 229.0000, batch_loss: 1.2689, loss: 1.3949 ||: 100%|##########| 115/115 [01:55<00:00,  1.00s/it]
2022-03-31 11:40:40,506 - INFO - tqdm - bleu_BLEU: 0.2288, rouge_ROUGE-1_R: 0.5084, rouge_ROUGE-2_R: 0.3329, rouge_ROUGE-1_P: 0.6474, rouge_ROUGE-2_P: 0.4276, rouge_ROUGE-1_F1: 0.5556, rouge_ROUGE-2_F1: 0.3648, rouge_ROUGE-L: 0.4849, SARI: 0.5560, count: 229.0000, batch_loss: 1.2689, loss: 1.3949 ||: 100%|##########| 115/115 [01:55<00:00,  1.00s/it]
2022-03-31 11:40:40,507 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2022-03-31 11:40:40,507 - INFO - allennlp.training.tensorboard_writer - SARI               |       N/A  |     0.556
2022-03-31 11:40:40,508 - INFO - allennlp.training.tensorboard_writer - bleu_BLEU          |       N/A  |     0.229
2022-03-31 11:40:40,508 - INFO - allennlp.training.tensorboard_writer - count              |       N/A  |   229.000
2022-03-31 11:40:40,508 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |  6843.886  |       N/A
2022-03-31 11:40:40,509 - INFO - allennlp.training.tensorboard_writer - loss               |     1.149  |     1.395
2022-03-31 11:40:40,510 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_F1   |       N/A  |     0.556
2022-03-31 11:40:40,510 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_P    |       N/A  |     0.647
2022-03-31 11:40:40,510 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_R    |       N/A  |     0.508
2022-03-31 11:40:40,511 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_F1   |       N/A  |     0.365
2022-03-31 11:40:40,511 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_P    |       N/A  |     0.428
2022-03-31 11:40:40,511 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_R    |       N/A  |     0.333
2022-03-31 11:40:40,512 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-L      |       N/A  |     0.485
2022-03-31 11:40:40,512 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  12006.336  |       N/A
2022-03-31 11:40:45,627 - INFO - allennlp.training.trainer - Epoch duration: 0:03:52.201665
2022-03-31 11:40:45,627 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:19:28
2022-03-31 11:40:45,627 - INFO - allennlp.training.trainer - Epoch 10/14
2022-03-31 11:40:45,627 - INFO - allennlp.training.trainer - Worker 0 memory usage: 12G
2022-03-31 11:40:45,628 - INFO - allennlp.training.trainer - GPU 0 memory usage: 6.7G
2022-03-31 11:40:45,629 - INFO - allennlp.training.trainer - Training
2022-03-31 11:40:45,629 - INFO - tqdm - 0%|          | 0/65 [00:00<?, ?it/s]
2022-03-31 11:40:57,244 - INFO - tqdm - batch_loss: 1.1748, loss: 1.1305 ||:  11%|#         | 7/65 [00:11<01:36,  1.67s/it]
2022-03-31 11:41:08,640 - INFO - tqdm - batch_loss: 1.1395, loss: 1.1027 ||:  22%|##1       | 14/65 [00:23<01:22,  1.61s/it]
2022-03-31 11:41:20,144 - INFO - tqdm - batch_loss: 1.1542, loss: 1.1130 ||:  32%|###2      | 21/65 [00:34<01:12,  1.65s/it]
2022-03-31 11:41:31,797 - INFO - tqdm - batch_loss: 1.1597, loss: 1.1097 ||:  43%|####3     | 28/65 [00:46<01:01,  1.67s/it]
2022-03-31 11:41:43,390 - INFO - tqdm - batch_loss: 1.1582, loss: 1.0981 ||:  54%|#####3    | 35/65 [00:57<00:49,  1.66s/it]
2022-03-31 11:41:53,399 - INFO - tqdm - batch_loss: 0.9765, loss: 1.1002 ||:  63%|######3   | 41/65 [01:07<00:39,  1.65s/it]
2022-03-31 11:42:05,037 - INFO - tqdm - batch_loss: 1.1572, loss: 1.0995 ||:  74%|#######3  | 48/65 [01:19<00:28,  1.68s/it]
2022-03-31 11:42:15,544 - INFO - tqdm - batch_loss: 1.1096, loss: 1.1028 ||:  83%|########3 | 54/65 [01:29<00:18,  1.71s/it]
2022-03-31 11:42:27,130 - INFO - tqdm - batch_loss: 1.2108, loss: 1.1022 ||:  94%|#########3| 61/65 [01:41<00:06,  1.67s/it]
2022-03-31 11:42:32,904 - INFO - tqdm - batch_loss: 1.0058, loss: 1.1021 ||: 100%|##########| 65/65 [01:47<00:00,  1.40s/it]
2022-03-31 11:42:32,904 - INFO - tqdm - batch_loss: 1.0058, loss: 1.1021 ||: 100%|##########| 65/65 [01:47<00:00,  1.65s/it]
2022-03-31 11:42:35,497 - INFO - allennlp.training.trainer - Validating
2022-03-31 11:42:35,498 - INFO - tqdm - 0%|          | 0/115 [00:00<?, ?it/s]
2022-03-31 11:42:45,694 - INFO - tqdm - bleu_BLEU: 0.2071, rouge_ROUGE-1_R: 0.5177, rouge_ROUGE-2_R: 0.3115, rouge_ROUGE-1_P: 0.6038, rouge_ROUGE-2_P: 0.3646, rouge_ROUGE-1_F1: 0.5479, rouge_ROUGE-2_F1: 0.3300, rouge_ROUGE-L: 0.4573, SARI: 0.5127, count: 20.0000, batch_loss: 1.0211, loss: 1.4557 ||:   9%|8         | 10/115 [00:10<01:45,  1.01s/it]
2022-03-31 11:42:56,245 - INFO - tqdm - bleu_BLEU: 0.2283, rouge_ROUGE-1_R: 0.5086, rouge_ROUGE-2_R: 0.3242, rouge_ROUGE-1_P: 0.6509, rouge_ROUGE-2_P: 0.4149, rouge_ROUGE-1_F1: 0.5617, rouge_ROUGE-2_F1: 0.3577, rouge_ROUGE-L: 0.4873, SARI: 0.5544, count: 42.0000, batch_loss: 1.4450, loss: 1.3643 ||:  18%|#8        | 21/115 [00:20<01:33,  1.00it/s]
2022-03-31 11:43:06,937 - INFO - tqdm - bleu_BLEU: 0.2400, rouge_ROUGE-1_R: 0.5223, rouge_ROUGE-2_R: 0.3404, rouge_ROUGE-1_P: 0.6294, rouge_ROUGE-2_P: 0.4097, rouge_ROUGE-1_F1: 0.5583, rouge_ROUGE-2_F1: 0.3633, rouge_ROUGE-L: 0.4789, SARI: 0.5568, count: 60.0000, batch_loss: 1.6400, loss: 1.3739 ||:  26%|##6       | 30/115 [00:31<01:31,  1.08s/it]
2022-03-31 11:43:17,730 - INFO - tqdm - bleu_BLEU: 0.2579, rouge_ROUGE-1_R: 0.5404, rouge_ROUGE-2_R: 0.3571, rouge_ROUGE-1_P: 0.6406, rouge_ROUGE-2_P: 0.4255, rouge_ROUGE-1_F1: 0.5743, rouge_ROUGE-2_F1: 0.3802, rouge_ROUGE-L: 0.4893, SARI: 0.5639, count: 82.0000, batch_loss: 0.6788, loss: 1.3111 ||:  36%|###5      | 41/115 [00:42<01:11,  1.04it/s]
2022-03-31 11:43:27,802 - INFO - tqdm - bleu_BLEU: 0.2467, rouge_ROUGE-1_R: 0.5302, rouge_ROUGE-2_R: 0.3467, rouge_ROUGE-1_P: 0.6276, rouge_ROUGE-2_P: 0.4128, rouge_ROUGE-1_F1: 0.5635, rouge_ROUGE-2_F1: 0.3691, rouge_ROUGE-L: 0.4827, SARI: 0.5641, count: 102.0000, batch_loss: 1.6807, loss: 1.3612 ||:  44%|####4     | 51/115 [00:52<01:04,  1.02s/it]
2022-03-31 11:43:38,412 - INFO - tqdm - bleu_BLEU: 0.2481, rouge_ROUGE-1_R: 0.5310, rouge_ROUGE-2_R: 0.3468, rouge_ROUGE-1_P: 0.6326, rouge_ROUGE-2_P: 0.4160, rouge_ROUGE-1_F1: 0.5662, rouge_ROUGE-2_F1: 0.3707, rouge_ROUGE-L: 0.4864, SARI: 0.5708, count: 123.0000, batch_loss: 1.1449, loss: 1.4016 ||:  54%|#####3    | 62/115 [01:02<00:54,  1.03s/it]
2022-03-31 11:43:49,330 - INFO - tqdm - bleu_BLEU: 0.2410, rouge_ROUGE-1_R: 0.5282, rouge_ROUGE-2_R: 0.3429, rouge_ROUGE-1_P: 0.6294, rouge_ROUGE-2_P: 0.4108, rouge_ROUGE-1_F1: 0.5627, rouge_ROUGE-2_F1: 0.3659, rouge_ROUGE-L: 0.4825, SARI: 0.5659, count: 145.0000, batch_loss: 1.8298, loss: 1.3973 ||:  63%|######3   | 73/115 [01:13<00:43,  1.03s/it]
2022-03-31 11:43:59,694 - INFO - tqdm - bleu_BLEU: 0.2414, rouge_ROUGE-1_R: 0.5277, rouge_ROUGE-2_R: 0.3427, rouge_ROUGE-1_P: 0.6242, rouge_ROUGE-2_P: 0.4091, rouge_ROUGE-1_F1: 0.5590, rouge_ROUGE-2_F1: 0.3643, rouge_ROUGE-L: 0.4798, SARI: 0.5630, count: 165.0000, batch_loss: 0.7053, loss: 1.3890 ||:  72%|#######2  | 83/115 [01:24<00:35,  1.09s/it]
2022-03-31 11:44:10,272 - INFO - tqdm - bleu_BLEU: 0.2296, rouge_ROUGE-1_R: 0.5156, rouge_ROUGE-2_R: 0.3320, rouge_ROUGE-1_P: 0.6227, rouge_ROUGE-2_P: 0.4045, rouge_ROUGE-1_F1: 0.5504, rouge_ROUGE-2_F1: 0.3555, rouge_ROUGE-L: 0.4729, SARI: 0.5550, count: 185.0000, batch_loss: 1.5123, loss: 1.4046 ||:  81%|########  | 93/115 [01:34<00:21,  1.01it/s]
2022-03-31 11:44:20,673 - INFO - tqdm - bleu_BLEU: 0.2307, rouge_ROUGE-1_R: 0.5176, rouge_ROUGE-2_R: 0.3342, rouge_ROUGE-1_P: 0.6237, rouge_ROUGE-2_P: 0.4058, rouge_ROUGE-1_F1: 0.5523, rouge_ROUGE-2_F1: 0.3576, rouge_ROUGE-L: 0.4760, SARI: 0.5557, count: 205.0000, batch_loss: 0.6111, loss: 1.3800 ||:  90%|########9 | 103/115 [01:45<00:12,  1.05s/it]
2022-03-31 11:44:31,008 - INFO - tqdm - bleu_BLEU: 0.2275, rouge_ROUGE-1_R: 0.5135, rouge_ROUGE-2_R: 0.3303, rouge_ROUGE-1_P: 0.6230, rouge_ROUGE-2_P: 0.4033, rouge_ROUGE-1_F1: 0.5503, rouge_ROUGE-2_F1: 0.3547, rouge_ROUGE-L: 0.4737, SARI: 0.5533, count: 225.0000, batch_loss: 1.3247, loss: 1.4019 ||:  98%|#########8| 113/115 [01:55<00:01,  1.00it/s]
2022-03-31 11:44:32,884 - INFO - tqdm - bleu_BLEU: 0.2254, rouge_ROUGE-1_R: 0.5110, rouge_ROUGE-2_R: 0.3286, rouge_ROUGE-1_P: 0.6240, rouge_ROUGE-2_P: 0.4039, rouge_ROUGE-1_F1: 0.5490, rouge_ROUGE-2_F1: 0.3538, rouge_ROUGE-L: 0.4725, SARI: 0.5518, count: 229.0000, batch_loss: 1.6730, loss: 1.3992 ||: 100%|##########| 115/115 [01:57<00:00,  1.04it/s]
2022-03-31 11:44:32,884 - INFO - tqdm - bleu_BLEU: 0.2254, rouge_ROUGE-1_R: 0.5110, rouge_ROUGE-2_R: 0.3286, rouge_ROUGE-1_P: 0.6240, rouge_ROUGE-2_P: 0.4039, rouge_ROUGE-1_F1: 0.5490, rouge_ROUGE-2_F1: 0.3538, rouge_ROUGE-L: 0.4725, SARI: 0.5518, count: 229.0000, batch_loss: 1.6730, loss: 1.3992 ||: 100%|##########| 115/115 [01:57<00:00,  1.02s/it]
2022-03-31 11:44:32,884 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2022-03-31 11:44:32,885 - INFO - allennlp.training.tensorboard_writer - SARI               |       N/A  |     0.552
2022-03-31 11:44:32,885 - INFO - allennlp.training.tensorboard_writer - bleu_BLEU          |       N/A  |     0.225
2022-03-31 11:44:32,886 - INFO - allennlp.training.tensorboard_writer - count              |       N/A  |   229.000
2022-03-31 11:44:32,886 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |  6844.262  |       N/A
2022-03-31 11:44:32,886 - INFO - allennlp.training.tensorboard_writer - loss               |     1.102  |     1.399
2022-03-31 11:44:32,887 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_F1   |       N/A  |     0.549
2022-03-31 11:44:32,887 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_P    |       N/A  |     0.624
2022-03-31 11:44:32,887 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_R    |       N/A  |     0.511
2022-03-31 11:44:32,887 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_F1   |       N/A  |     0.354
2022-03-31 11:44:32,888 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_P    |       N/A  |     0.404
2022-03-31 11:44:32,888 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_R    |       N/A  |     0.329
2022-03-31 11:44:32,889 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-L      |       N/A  |     0.473
2022-03-31 11:44:32,889 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  12006.336  |       N/A
2022-03-31 11:44:37,984 - INFO - allennlp.training.trainer - Epoch duration: 0:03:52.356351
2022-03-31 11:44:37,984 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:15:32
2022-03-31 11:44:37,984 - INFO - allennlp.training.trainer - Epoch 11/14
2022-03-31 11:44:37,984 - INFO - allennlp.training.trainer - Worker 0 memory usage: 12G
2022-03-31 11:44:37,984 - INFO - allennlp.training.trainer - GPU 0 memory usage: 6.7G
2022-03-31 11:44:37,985 - INFO - allennlp.training.trainer - Training
2022-03-31 11:44:37,986 - INFO - tqdm - 0%|          | 0/65 [00:00<?, ?it/s]
2022-03-31 11:44:49,572 - INFO - tqdm - batch_loss: 0.9577, loss: 1.0813 ||:  11%|#         | 7/65 [00:11<01:35,  1.65s/it]
2022-03-31 11:44:59,620 - INFO - tqdm - batch_loss: 1.0278, loss: 1.0743 ||:  20%|##        | 13/65 [00:21<01:26,  1.66s/it]
2022-03-31 11:45:09,686 - INFO - tqdm - batch_loss: 1.1741, loss: 1.0807 ||:  29%|##9       | 19/65 [00:31<01:17,  1.68s/it]
2022-03-31 11:45:21,279 - INFO - tqdm - batch_loss: 0.9858, loss: 1.0774 ||:  40%|####      | 26/65 [00:43<01:04,  1.66s/it]
2022-03-31 11:45:32,875 - INFO - tqdm - batch_loss: 1.1611, loss: 1.0638 ||:  51%|#####     | 33/65 [00:54<00:53,  1.67s/it]
2022-03-31 11:45:44,473 - INFO - tqdm - batch_loss: 1.0712, loss: 1.0617 ||:  62%|######1   | 40/65 [01:06<00:41,  1.68s/it]
2022-03-31 11:45:55,934 - INFO - tqdm - batch_loss: 0.9032, loss: 1.0607 ||:  72%|#######2  | 47/65 [01:17<00:29,  1.66s/it]
2022-03-31 11:46:06,031 - INFO - tqdm - batch_loss: 1.0854, loss: 1.0657 ||:  82%|########1 | 53/65 [01:28<00:20,  1.68s/it]
2022-03-31 11:46:16,210 - INFO - tqdm - batch_loss: 1.2352, loss: 1.0710 ||:  91%|######### | 59/65 [01:38<00:10,  1.70s/it]
2022-03-31 11:46:25,418 - INFO - tqdm - batch_loss: 1.0184, loss: 1.0786 ||: 100%|##########| 65/65 [01:47<00:00,  1.42s/it]
2022-03-31 11:46:25,419 - INFO - tqdm - batch_loss: 1.0184, loss: 1.0786 ||: 100%|##########| 65/65 [01:47<00:00,  1.65s/it]
2022-03-31 11:46:28,013 - INFO - allennlp.training.trainer - Validating
2022-03-31 11:46:28,015 - INFO - tqdm - 0%|          | 0/115 [00:00<?, ?it/s]
2022-03-31 11:46:38,386 - INFO - tqdm - bleu_BLEU: 0.2315, rouge_ROUGE-1_R: 0.5208, rouge_ROUGE-2_R: 0.3355, rouge_ROUGE-1_P: 0.6412, rouge_ROUGE-2_P: 0.4082, rouge_ROUGE-1_F1: 0.5645, rouge_ROUGE-2_F1: 0.3617, rouge_ROUGE-L: 0.4706, SARI: 0.5534, count: 20.0000, batch_loss: 1.6888, loss: 1.3710 ||:   9%|8         | 10/115 [00:10<01:55,  1.10s/it]
2022-03-31 11:46:49,570 - INFO - tqdm - bleu_BLEU: 0.2501, rouge_ROUGE-1_R: 0.5507, rouge_ROUGE-2_R: 0.3619, rouge_ROUGE-1_P: 0.6450, rouge_ROUGE-2_P: 0.4234, rouge_ROUGE-1_F1: 0.5863, rouge_ROUGE-2_F1: 0.3851, rouge_ROUGE-L: 0.4968, SARI: 0.5831, count: 40.0000, batch_loss: 1.5174, loss: 1.2072 ||:  17%|#7        | 20/115 [00:21<01:52,  1.19s/it]
2022-03-31 11:46:59,700 - INFO - tqdm - bleu_BLEU: 0.2480, rouge_ROUGE-1_R: 0.5306, rouge_ROUGE-2_R: 0.3440, rouge_ROUGE-1_P: 0.6261, rouge_ROUGE-2_P: 0.4078, rouge_ROUGE-1_F1: 0.5641, rouge_ROUGE-2_F1: 0.3669, rouge_ROUGE-L: 0.4794, SARI: 0.5665, count: 60.0000, batch_loss: 1.0464, loss: 1.2906 ||:  26%|##6       | 30/115 [00:31<01:23,  1.01it/s]
2022-03-31 11:47:09,930 - INFO - tqdm - bleu_BLEU: 0.2619, rouge_ROUGE-1_R: 0.5506, rouge_ROUGE-2_R: 0.3636, rouge_ROUGE-1_P: 0.6327, rouge_ROUGE-2_P: 0.4190, rouge_ROUGE-1_F1: 0.5791, rouge_ROUGE-2_F1: 0.3832, rouge_ROUGE-L: 0.4998, SARI: 0.5722, count: 80.0000, batch_loss: 1.2625, loss: 1.2845 ||:  35%|###4      | 40/115 [00:41<01:22,  1.10s/it]
2022-03-31 11:47:20,531 - INFO - tqdm - bleu_BLEU: 0.2449, rouge_ROUGE-1_R: 0.5276, rouge_ROUGE-2_R: 0.3470, rouge_ROUGE-1_P: 0.6399, rouge_ROUGE-2_P: 0.4223, rouge_ROUGE-1_F1: 0.5671, rouge_ROUGE-2_F1: 0.3737, rouge_ROUGE-L: 0.4894, SARI: 0.5652, count: 102.0000, batch_loss: 2.0374, loss: 1.2712 ||:  44%|####4     | 51/115 [00:52<01:02,  1.02it/s]
2022-03-31 11:47:31,147 - INFO - tqdm - bleu_BLEU: 0.2334, rouge_ROUGE-1_R: 0.5196, rouge_ROUGE-2_R: 0.3380, rouge_ROUGE-1_P: 0.6388, rouge_ROUGE-2_P: 0.4160, rouge_ROUGE-1_F1: 0.5620, rouge_ROUGE-2_F1: 0.3659, rouge_ROUGE-L: 0.4810, SARI: 0.5685, count: 121.0000, batch_loss: 1.3712, loss: 1.3213 ||:  53%|#####3    | 61/115 [01:03<00:56,  1.04s/it]
2022-03-31 11:47:41,216 - INFO - tqdm - bleu_BLEU: 0.2285, rouge_ROUGE-1_R: 0.5133, rouge_ROUGE-2_R: 0.3330, rouge_ROUGE-1_P: 0.6389, rouge_ROUGE-2_P: 0.4155, rouge_ROUGE-1_F1: 0.5581, rouge_ROUGE-2_F1: 0.3625, rouge_ROUGE-L: 0.4783, SARI: 0.5637, count: 141.0000, batch_loss: 2.7680, loss: 1.4093 ||:  62%|######1   | 71/115 [01:13<00:42,  1.04it/s]
2022-03-31 11:47:51,359 - INFO - tqdm - bleu_BLEU: 0.2287, rouge_ROUGE-1_R: 0.5126, rouge_ROUGE-2_R: 0.3313, rouge_ROUGE-1_P: 0.6390, rouge_ROUGE-2_P: 0.4147, rouge_ROUGE-1_F1: 0.5579, rouge_ROUGE-2_F1: 0.3613, rouge_ROUGE-L: 0.4790, SARI: 0.5623, count: 163.0000, batch_loss: 1.6722, loss: 1.4109 ||:  71%|#######1  | 82/115 [01:23<00:28,  1.17it/s]
2022-03-31 11:48:01,734 - INFO - tqdm - bleu_BLEU: 0.2320, rouge_ROUGE-1_R: 0.5183, rouge_ROUGE-2_R: 0.3362, rouge_ROUGE-1_P: 0.6354, rouge_ROUGE-2_P: 0.4134, rouge_ROUGE-1_F1: 0.5599, rouge_ROUGE-2_F1: 0.3636, rouge_ROUGE-L: 0.4795, SARI: 0.5571, count: 183.0000, batch_loss: 1.2809, loss: 1.3876 ||:  80%|########  | 92/115 [01:33<00:24,  1.06s/it]
2022-03-31 11:48:12,549 - INFO - tqdm - bleu_BLEU: 0.2318, rouge_ROUGE-1_R: 0.5197, rouge_ROUGE-2_R: 0.3362, rouge_ROUGE-1_P: 0.6293, rouge_ROUGE-2_P: 0.4088, rouge_ROUGE-1_F1: 0.5575, rouge_ROUGE-2_F1: 0.3613, rouge_ROUGE-L: 0.4774, SARI: 0.5554, count: 203.0000, batch_loss: 1.1880, loss: 1.3860 ||:  89%|########8 | 102/115 [01:44<00:14,  1.09s/it]
2022-03-31 11:48:23,518 - INFO - tqdm - bleu_BLEU: 0.2325, rouge_ROUGE-1_R: 0.5192, rouge_ROUGE-2_R: 0.3375, rouge_ROUGE-1_P: 0.6299, rouge_ROUGE-2_P: 0.4113, rouge_ROUGE-1_F1: 0.5566, rouge_ROUGE-2_F1: 0.3625, rouge_ROUGE-L: 0.4792, SARI: 0.5532, count: 225.0000, batch_loss: 1.5762, loss: 1.3898 ||:  98%|#########8| 113/115 [01:55<00:02,  1.01s/it]
2022-03-31 11:48:26,264 - INFO - tqdm - bleu_BLEU: 0.2331, rouge_ROUGE-1_R: 0.5187, rouge_ROUGE-2_R: 0.3371, rouge_ROUGE-1_P: 0.6301, rouge_ROUGE-2_P: 0.4113, rouge_ROUGE-1_F1: 0.5565, rouge_ROUGE-2_F1: 0.3624, rouge_ROUGE-L: 0.4798, SARI: 0.5529, count: 229.0000, batch_loss: 2.4039, loss: 1.3994 ||: 100%|##########| 115/115 [01:58<00:00,  1.20s/it]
2022-03-31 11:48:26,264 - INFO - tqdm - bleu_BLEU: 0.2331, rouge_ROUGE-1_R: 0.5187, rouge_ROUGE-2_R: 0.3371, rouge_ROUGE-1_P: 0.6301, rouge_ROUGE-2_P: 0.4113, rouge_ROUGE-1_F1: 0.5565, rouge_ROUGE-2_F1: 0.3624, rouge_ROUGE-L: 0.4798, SARI: 0.5529, count: 229.0000, batch_loss: 2.4039, loss: 1.3994 ||: 100%|##########| 115/115 [01:58<00:00,  1.03s/it]
2022-03-31 11:48:26,264 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2022-03-31 11:48:26,265 - INFO - allennlp.training.tensorboard_writer - SARI               |       N/A  |     0.553
2022-03-31 11:48:26,266 - INFO - allennlp.training.tensorboard_writer - bleu_BLEU          |       N/A  |     0.233
2022-03-31 11:48:26,266 - INFO - allennlp.training.tensorboard_writer - count              |       N/A  |   229.000
2022-03-31 11:48:26,266 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |  6844.262  |       N/A
2022-03-31 11:48:26,267 - INFO - allennlp.training.tensorboard_writer - loss               |     1.079  |     1.399
2022-03-31 11:48:26,267 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_F1   |       N/A  |     0.557
2022-03-31 11:48:26,268 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_P    |       N/A  |     0.630
2022-03-31 11:48:26,269 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_R    |       N/A  |     0.519
2022-03-31 11:48:26,269 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_F1   |       N/A  |     0.362
2022-03-31 11:48:26,269 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_P    |       N/A  |     0.411
2022-03-31 11:48:26,269 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_R    |       N/A  |     0.337
2022-03-31 11:48:26,269 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-L      |       N/A  |     0.480
2022-03-31 11:48:26,270 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  12006.336  |       N/A
2022-03-31 11:48:26,274 - INFO - allennlp.training.trainer - Epoch duration: 0:03:48.289844
2022-03-31 11:48:26,274 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:11:35
2022-03-31 11:48:26,274 - INFO - allennlp.training.trainer - Epoch 12/14
2022-03-31 11:48:26,274 - INFO - allennlp.training.trainer - Worker 0 memory usage: 12G
2022-03-31 11:48:26,274 - INFO - allennlp.training.trainer - GPU 0 memory usage: 6.7G
2022-03-31 11:48:26,275 - INFO - allennlp.training.trainer - Training
2022-03-31 11:48:26,276 - INFO - tqdm - 0%|          | 0/65 [00:00<?, ?it/s]
2022-03-31 11:48:36,415 - INFO - tqdm - batch_loss: 1.0623, loss: 1.0080 ||:   9%|9         | 6/65 [00:10<01:39,  1.69s/it]
2022-03-31 11:48:48,004 - INFO - tqdm - batch_loss: 1.0807, loss: 1.0138 ||:  20%|##        | 13/65 [00:21<01:26,  1.66s/it]
2022-03-31 11:49:00,267 - INFO - tqdm - batch_loss: 1.0068, loss: 1.0054 ||:  31%|###       | 20/65 [00:33<01:23,  1.86s/it]
2022-03-31 11:49:10,344 - INFO - tqdm - batch_loss: 1.0462, loss: 1.0212 ||:  40%|####      | 26/65 [00:44<01:06,  1.70s/it]
2022-03-31 11:49:20,389 - INFO - tqdm - batch_loss: 1.0578, loss: 1.0267 ||:  49%|####9     | 32/65 [00:54<00:55,  1.69s/it]
2022-03-31 11:49:30,493 - INFO - tqdm - batch_loss: 1.0322, loss: 1.0317 ||:  58%|#####8    | 38/65 [01:04<00:45,  1.68s/it]
2022-03-31 11:49:42,108 - INFO - tqdm - batch_loss: 1.0275, loss: 1.0361 ||:  69%|######9   | 45/65 [01:15<00:33,  1.66s/it]
2022-03-31 11:49:52,174 - INFO - tqdm - batch_loss: 1.2318, loss: 1.0470 ||:  78%|#######8  | 51/65 [01:25<00:23,  1.69s/it]
2022-03-31 11:50:02,251 - INFO - tqdm - batch_loss: 0.9994, loss: 1.0470 ||:  88%|########7 | 57/65 [01:35<00:13,  1.69s/it]
2022-03-31 11:50:12,354 - INFO - tqdm - batch_loss: 1.2339, loss: 1.0516 ||:  97%|#########6| 63/65 [01:46<00:03,  1.69s/it]
2022-03-31 11:50:14,860 - INFO - tqdm - batch_loss: 0.9063, loss: 1.0503 ||: 100%|##########| 65/65 [01:48<00:00,  1.43s/it]
2022-03-31 11:50:14,861 - INFO - tqdm - batch_loss: 0.9063, loss: 1.0503 ||: 100%|##########| 65/65 [01:48<00:00,  1.67s/it]
2022-03-31 11:50:17,470 - INFO - allennlp.training.trainer - Validating
2022-03-31 11:50:17,471 - INFO - tqdm - 0%|          | 0/115 [00:00<?, ?it/s]
2022-03-31 11:50:28,446 - INFO - tqdm - bleu_BLEU: 0.1913, rouge_ROUGE-1_R: 0.4603, rouge_ROUGE-2_R: 0.3020, rouge_ROUGE-1_P: 0.6481, rouge_ROUGE-2_P: 0.4173, rouge_ROUGE-1_F1: 0.5250, rouge_ROUGE-2_F1: 0.3418, rouge_ROUGE-L: 0.4653, SARI: 0.5690, count: 24.0000, batch_loss: 0.6017, loss: 1.5526 ||:  10%|#         | 12/115 [00:10<01:35,  1.08it/s]
2022-03-31 11:50:38,985 - INFO - tqdm - bleu_BLEU: 0.2261, rouge_ROUGE-1_R: 0.4950, rouge_ROUGE-2_R: 0.3383, rouge_ROUGE-1_P: 0.6447, rouge_ROUGE-2_P: 0.4351, rouge_ROUGE-1_F1: 0.5505, rouge_ROUGE-2_F1: 0.3743, rouge_ROUGE-L: 0.4798, SARI: 0.5628, count: 46.0000, batch_loss: 1.8554, loss: 1.4445 ||:  20%|##        | 23/115 [00:21<01:26,  1.07it/s]
2022-03-31 11:50:49,250 - INFO - tqdm - bleu_BLEU: 0.2236, rouge_ROUGE-1_R: 0.5016, rouge_ROUGE-2_R: 0.3373, rouge_ROUGE-1_P: 0.6551, rouge_ROUGE-2_P: 0.4376, rouge_ROUGE-1_F1: 0.5571, rouge_ROUGE-2_F1: 0.3737, rouge_ROUGE-L: 0.4780, SARI: 0.5666, count: 65.0000, batch_loss: 0.9292, loss: 1.3898 ||:  29%|##8       | 33/115 [00:31<01:23,  1.02s/it]
2022-03-31 11:50:59,272 - INFO - tqdm - bleu_BLEU: 0.2192, rouge_ROUGE-1_R: 0.4936, rouge_ROUGE-2_R: 0.3256, rouge_ROUGE-1_P: 0.6295, rouge_ROUGE-2_P: 0.4160, rouge_ROUGE-1_F1: 0.5398, rouge_ROUGE-2_F1: 0.3565, rouge_ROUGE-L: 0.4644, SARI: 0.5564, count: 85.0000, batch_loss: 1.8799, loss: 1.4177 ||:  37%|###7      | 43/115 [00:41<01:06,  1.08it/s]
2022-03-31 11:51:09,921 - INFO - tqdm - bleu_BLEU: 0.2104, rouge_ROUGE-1_R: 0.4868, rouge_ROUGE-2_R: 0.3194, rouge_ROUGE-1_P: 0.6443, rouge_ROUGE-2_P: 0.4253, rouge_ROUGE-1_F1: 0.5406, rouge_ROUGE-2_F1: 0.3555, rouge_ROUGE-L: 0.4600, SARI: 0.5519, count: 107.0000, batch_loss: 1.6270, loss: 1.4336 ||:  47%|####6     | 54/115 [00:52<00:54,  1.11it/s]
2022-03-31 11:51:21,036 - INFO - tqdm - bleu_BLEU: 0.2116, rouge_ROUGE-1_R: 0.4895, rouge_ROUGE-2_R: 0.3206, rouge_ROUGE-1_P: 0.6476, rouge_ROUGE-2_P: 0.4271, rouge_ROUGE-1_F1: 0.5442, rouge_ROUGE-2_F1: 0.3573, rouge_ROUGE-L: 0.4647, SARI: 0.5572, count: 129.0000, batch_loss: 1.9974, loss: 1.4320 ||:  57%|#####6    | 65/115 [01:03<00:55,  1.11s/it]
2022-03-31 11:51:31,447 - INFO - tqdm - bleu_BLEU: 0.2168, rouge_ROUGE-1_R: 0.4941, rouge_ROUGE-2_R: 0.3237, rouge_ROUGE-1_P: 0.6519, rouge_ROUGE-2_P: 0.4305, rouge_ROUGE-1_F1: 0.5495, rouge_ROUGE-2_F1: 0.3610, rouge_ROUGE-L: 0.4693, SARI: 0.5570, count: 151.0000, batch_loss: 0.6518, loss: 1.4304 ||:  66%|######6   | 76/115 [01:13<00:36,  1.07it/s]
2022-03-31 11:51:41,521 - INFO - tqdm - bleu_BLEU: 0.2188, rouge_ROUGE-1_R: 0.4991, rouge_ROUGE-2_R: 0.3249, rouge_ROUGE-1_P: 0.6419, rouge_ROUGE-2_P: 0.4218, rouge_ROUGE-1_F1: 0.5484, rouge_ROUGE-2_F1: 0.3582, rouge_ROUGE-L: 0.4685, SARI: 0.5558, count: 171.0000, batch_loss: 0.6039, loss: 1.4342 ||:  75%|#######4  | 86/115 [01:24<00:28,  1.02it/s]
2022-03-31 11:51:51,737 - INFO - tqdm - bleu_BLEU: 0.2199, rouge_ROUGE-1_R: 0.5015, rouge_ROUGE-2_R: 0.3258, rouge_ROUGE-1_P: 0.6422, rouge_ROUGE-2_P: 0.4211, rouge_ROUGE-1_F1: 0.5501, rouge_ROUGE-2_F1: 0.3586, rouge_ROUGE-L: 0.4711, SARI: 0.5585, count: 191.0000, batch_loss: 1.5702, loss: 1.4057 ||:  83%|########3 | 96/115 [01:34<00:19,  1.00s/it]
2022-03-31 11:52:02,081 - INFO - tqdm - bleu_BLEU: 0.2250, rouge_ROUGE-1_R: 0.5073, rouge_ROUGE-2_R: 0.3317, rouge_ROUGE-1_P: 0.6457, rouge_ROUGE-2_P: 0.4251, rouge_ROUGE-1_F1: 0.5554, rouge_ROUGE-2_F1: 0.3641, rouge_ROUGE-L: 0.4785, SARI: 0.5587, count: 213.0000, batch_loss: 1.8504, loss: 1.4082 ||:  93%|#########3| 107/115 [01:44<00:07,  1.10it/s]
2022-03-31 11:52:10,271 - INFO - tqdm - bleu_BLEU: 0.2293, rouge_ROUGE-1_R: 0.5111, rouge_ROUGE-2_R: 0.3344, rouge_ROUGE-1_P: 0.6440, rouge_ROUGE-2_P: 0.4242, rouge_ROUGE-1_F1: 0.5574, rouge_ROUGE-2_F1: 0.3656, rouge_ROUGE-L: 0.4800, SARI: 0.5589, count: 229.0000, batch_loss: 1.9558, loss: 1.4047 ||: 100%|##########| 115/115 [01:52<00:00,  1.00it/s]
2022-03-31 11:52:10,271 - INFO - tqdm - bleu_BLEU: 0.2293, rouge_ROUGE-1_R: 0.5111, rouge_ROUGE-2_R: 0.3344, rouge_ROUGE-1_P: 0.6440, rouge_ROUGE-2_P: 0.4242, rouge_ROUGE-1_F1: 0.5574, rouge_ROUGE-2_F1: 0.3656, rouge_ROUGE-L: 0.4800, SARI: 0.5589, count: 229.0000, batch_loss: 1.9558, loss: 1.4047 ||: 100%|##########| 115/115 [01:52<00:00,  1.02it/s]
2022-03-31 11:52:10,272 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2022-03-31 11:52:10,272 - INFO - allennlp.training.tensorboard_writer - SARI               |       N/A  |     0.559
2022-03-31 11:52:10,273 - INFO - allennlp.training.tensorboard_writer - bleu_BLEU          |       N/A  |     0.229
2022-03-31 11:52:10,273 - INFO - allennlp.training.tensorboard_writer - count              |       N/A  |   229.000
2022-03-31 11:52:10,273 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |  6844.262  |       N/A
2022-03-31 11:52:10,274 - INFO - allennlp.training.tensorboard_writer - loss               |     1.050  |     1.405
2022-03-31 11:52:10,274 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_F1   |       N/A  |     0.557
2022-03-31 11:52:10,275 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_P    |       N/A  |     0.644
2022-03-31 11:52:10,275 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_R    |       N/A  |     0.511
2022-03-31 11:52:10,275 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_F1   |       N/A  |     0.366
2022-03-31 11:52:10,276 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_P    |       N/A  |     0.424
2022-03-31 11:52:10,276 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_R    |       N/A  |     0.334
2022-03-31 11:52:10,276 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-L      |       N/A  |     0.480
2022-03-31 11:52:10,276 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  12006.336  |       N/A
2022-03-31 11:52:15,373 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to './output_decomposition/best.th'.
2022-03-31 11:52:27,879 - INFO - allennlp.training.trainer - Epoch duration: 0:04:01.604835
2022-03-31 11:52:27,879 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:07:47
2022-03-31 11:52:27,879 - INFO - allennlp.training.trainer - Epoch 13/14
2022-03-31 11:52:27,879 - INFO - allennlp.training.trainer - Worker 0 memory usage: 12G
2022-03-31 11:52:27,880 - INFO - allennlp.training.trainer - GPU 0 memory usage: 6.7G
2022-03-31 11:52:27,881 - INFO - allennlp.training.trainer - Training
2022-03-31 11:52:27,881 - INFO - tqdm - 0%|          | 0/65 [00:00<?, ?it/s]
2022-03-31 11:52:39,502 - INFO - tqdm - batch_loss: 1.0439, loss: 1.0308 ||:  11%|#         | 7/65 [00:11<01:36,  1.66s/it]
2022-03-31 11:52:51,020 - INFO - tqdm - batch_loss: 1.0134, loss: 1.0106 ||:  22%|##1       | 14/65 [00:23<01:24,  1.65s/it]
2022-03-31 11:53:02,570 - INFO - tqdm - batch_loss: 1.0086, loss: 1.0024 ||:  32%|###2      | 21/65 [00:34<01:13,  1.67s/it]
2022-03-31 11:53:14,173 - INFO - tqdm - batch_loss: 0.8718, loss: 1.0210 ||:  43%|####3     | 28/65 [00:46<01:01,  1.66s/it]
2022-03-31 11:53:24,202 - INFO - tqdm - batch_loss: 1.0649, loss: 1.0270 ||:  52%|#####2    | 34/65 [00:56<00:51,  1.67s/it]
2022-03-31 11:53:34,241 - INFO - tqdm - batch_loss: 1.1245, loss: 1.0291 ||:  62%|######1   | 40/65 [01:06<00:41,  1.68s/it]
2022-03-31 11:53:45,789 - INFO - tqdm - batch_loss: 0.9455, loss: 1.0306 ||:  72%|#######2  | 47/65 [01:17<00:29,  1.64s/it]
2022-03-31 11:53:57,388 - INFO - tqdm - batch_loss: 0.9989, loss: 1.0354 ||:  83%|########3 | 54/65 [01:29<00:18,  1.66s/it]
2022-03-31 11:54:07,997 - INFO - tqdm - batch_loss: 1.0834, loss: 1.0331 ||:  92%|#########2| 60/65 [01:40<00:08,  1.69s/it]
2022-03-31 11:54:15,546 - INFO - tqdm - batch_loss: 1.0709, loss: 1.0375 ||: 100%|##########| 65/65 [01:47<00:00,  1.42s/it]
2022-03-31 11:54:15,547 - INFO - tqdm - batch_loss: 1.0709, loss: 1.0375 ||: 100%|##########| 65/65 [01:47<00:00,  1.66s/it]
2022-03-31 11:54:18,125 - INFO - allennlp.training.trainer - Validating
2022-03-31 11:54:18,126 - INFO - tqdm - 0%|          | 0/115 [00:00<?, ?it/s]
2022-03-31 11:54:28,356 - INFO - tqdm - bleu_BLEU: 0.2379, rouge_ROUGE-1_R: 0.5121, rouge_ROUGE-2_R: 0.3525, rouge_ROUGE-1_P: 0.6955, rouge_ROUGE-2_P: 0.4792, rouge_ROUGE-1_F1: 0.5807, rouge_ROUGE-2_F1: 0.3997, rouge_ROUGE-L: 0.5101, SARI: 0.5521, count: 22.0000, batch_loss: 1.8959, loss: 1.3293 ||:  10%|9         | 11/115 [00:10<01:41,  1.02it/s]
2022-03-31 11:54:38,806 - INFO - tqdm - bleu_BLEU: 0.2153, rouge_ROUGE-1_R: 0.4679, rouge_ROUGE-2_R: 0.3129, rouge_ROUGE-1_P: 0.6594, rouge_ROUGE-2_P: 0.4427, rouge_ROUGE-1_F1: 0.5392, rouge_ROUGE-2_F1: 0.3610, rouge_ROUGE-L: 0.4742, SARI: 0.5438, count: 44.0000, batch_loss: 1.4443, loss: 1.4373 ||:  19%|#9        | 22/115 [00:20<01:30,  1.03it/s]
2022-03-31 11:54:49,450 - INFO - tqdm - bleu_BLEU: 0.2270, rouge_ROUGE-1_R: 0.4897, rouge_ROUGE-2_R: 0.3235, rouge_ROUGE-1_P: 0.6404, rouge_ROUGE-2_P: 0.4274, rouge_ROUGE-1_F1: 0.5438, rouge_ROUGE-2_F1: 0.3608, rouge_ROUGE-L: 0.4672, SARI: 0.5484, count: 64.0000, batch_loss: 0.5031, loss: 1.4580 ||:  28%|##7       | 32/115 [00:31<01:31,  1.10s/it]
2022-03-31 11:54:59,598 - INFO - tqdm - bleu_BLEU: 0.2378, rouge_ROUGE-1_R: 0.4990, rouge_ROUGE-2_R: 0.3331, rouge_ROUGE-1_P: 0.6481, rouge_ROUGE-2_P: 0.4369, rouge_ROUGE-1_F1: 0.5537, rouge_ROUGE-2_F1: 0.3711, rouge_ROUGE-L: 0.4784, SARI: 0.5554, count: 84.0000, batch_loss: 0.9774, loss: 1.4199 ||:  37%|###6      | 42/115 [00:41<01:09,  1.05it/s]
2022-03-31 11:55:10,186 - INFO - tqdm - bleu_BLEU: 0.2372, rouge_ROUGE-1_R: 0.5121, rouge_ROUGE-2_R: 0.3382, rouge_ROUGE-1_P: 0.6422, rouge_ROUGE-2_P: 0.4281, rouge_ROUGE-1_F1: 0.5584, rouge_ROUGE-2_F1: 0.3702, rouge_ROUGE-L: 0.4823, SARI: 0.5518, count: 106.0000, batch_loss: 1.2434, loss: 1.4246 ||:  46%|####6     | 53/115 [00:52<00:57,  1.09it/s]
2022-03-31 11:55:21,377 - INFO - tqdm - bleu_BLEU: 0.2255, rouge_ROUGE-1_R: 0.5022, rouge_ROUGE-2_R: 0.3309, rouge_ROUGE-1_P: 0.6496, rouge_ROUGE-2_P: 0.4328, rouge_ROUGE-1_F1: 0.5537, rouge_ROUGE-2_F1: 0.3664, rouge_ROUGE-L: 0.4773, SARI: 0.5476, count: 128.0000, batch_loss: 2.0330, loss: 1.4582 ||:  56%|#####5    | 64/115 [01:03<00:59,  1.16s/it]
2022-03-31 11:55:31,577 - INFO - tqdm - bleu_BLEU: 0.2299, rouge_ROUGE-1_R: 0.5058, rouge_ROUGE-2_R: 0.3351, rouge_ROUGE-1_P: 0.6553, rouge_ROUGE-2_P: 0.4387, rouge_ROUGE-1_F1: 0.5595, rouge_ROUGE-2_F1: 0.3722, rouge_ROUGE-L: 0.4809, SARI: 0.5538, count: 150.0000, batch_loss: 0.6312, loss: 1.4504 ||:  65%|######5   | 75/115 [01:13<00:35,  1.12it/s]
2022-03-31 11:55:41,767 - INFO - tqdm - bleu_BLEU: 0.2245, rouge_ROUGE-1_R: 0.4969, rouge_ROUGE-2_R: 0.3277, rouge_ROUGE-1_P: 0.6492, rouge_ROUGE-2_P: 0.4326, rouge_ROUGE-1_F1: 0.5515, rouge_ROUGE-2_F1: 0.3652, rouge_ROUGE-L: 0.4753, SARI: 0.5500, count: 169.0000, batch_loss: 1.8988, loss: 1.4697 ||:  74%|#######3  | 85/115 [01:23<00:29,  1.01it/s]
2022-03-31 11:55:51,953 - INFO - tqdm - bleu_BLEU: 0.2314, rouge_ROUGE-1_R: 0.5049, rouge_ROUGE-2_R: 0.3349, rouge_ROUGE-1_P: 0.6522, rouge_ROUGE-2_P: 0.4364, rouge_ROUGE-1_F1: 0.5580, rouge_ROUGE-2_F1: 0.3714, rouge_ROUGE-L: 0.4837, SARI: 0.5587, count: 191.0000, batch_loss: 1.1856, loss: 1.4196 ||:  83%|########3 | 96/115 [01:33<00:17,  1.09it/s]
2022-03-31 11:56:02,612 - INFO - tqdm - bleu_BLEU: 0.2334, rouge_ROUGE-1_R: 0.5090, rouge_ROUGE-2_R: 0.3360, rouge_ROUGE-1_P: 0.6477, rouge_ROUGE-2_P: 0.4312, rouge_ROUGE-1_F1: 0.5591, rouge_ROUGE-2_F1: 0.3703, rouge_ROUGE-L: 0.4837, SARI: 0.5540, count: 213.0000, batch_loss: 0.8621, loss: 1.4071 ||:  93%|#########3| 107/115 [01:44<00:08,  1.03s/it]
2022-03-31 11:56:10,439 - INFO - tqdm - bleu_BLEU: 0.2283, rouge_ROUGE-1_R: 0.5045, rouge_ROUGE-2_R: 0.3317, rouge_ROUGE-1_P: 0.6458, rouge_ROUGE-2_P: 0.4284, rouge_ROUGE-1_F1: 0.5549, rouge_ROUGE-2_F1: 0.3660, rouge_ROUGE-L: 0.4809, SARI: 0.5583, count: 229.0000, batch_loss: 1.3745, loss: 1.4150 ||: 100%|##########| 115/115 [01:52<00:00,  1.09it/s]
2022-03-31 11:56:10,440 - INFO - tqdm - bleu_BLEU: 0.2283, rouge_ROUGE-1_R: 0.5045, rouge_ROUGE-2_R: 0.3317, rouge_ROUGE-1_P: 0.6458, rouge_ROUGE-2_P: 0.4284, rouge_ROUGE-1_F1: 0.5549, rouge_ROUGE-2_F1: 0.3660, rouge_ROUGE-L: 0.4809, SARI: 0.5583, count: 229.0000, batch_loss: 1.3745, loss: 1.4150 ||: 100%|##########| 115/115 [01:52<00:00,  1.02it/s]
2022-03-31 11:56:10,440 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2022-03-31 11:56:10,441 - INFO - allennlp.training.tensorboard_writer - SARI               |       N/A  |     0.558
2022-03-31 11:56:10,441 - INFO - allennlp.training.tensorboard_writer - bleu_BLEU          |       N/A  |     0.228
2022-03-31 11:56:10,442 - INFO - allennlp.training.tensorboard_writer - count              |       N/A  |   229.000
2022-03-31 11:56:10,442 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |  6844.262  |       N/A
2022-03-31 11:56:10,443 - INFO - allennlp.training.tensorboard_writer - loss               |     1.038  |     1.415
2022-03-31 11:56:10,444 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_F1   |       N/A  |     0.555
2022-03-31 11:56:10,444 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_P    |       N/A  |     0.646
2022-03-31 11:56:10,445 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_R    |       N/A  |     0.505
2022-03-31 11:56:10,445 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_F1   |       N/A  |     0.366
2022-03-31 11:56:10,445 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_P    |       N/A  |     0.428
2022-03-31 11:56:10,445 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_R    |       N/A  |     0.332
2022-03-31 11:56:10,445 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-L      |       N/A  |     0.481
2022-03-31 11:56:10,446 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  12006.336  |       N/A
2022-03-31 11:56:15,569 - INFO - allennlp.training.trainer - Epoch duration: 0:03:47.689461
2022-03-31 11:56:15,569 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:03:52
2022-03-31 11:56:15,569 - INFO - allennlp.training.trainer - Epoch 14/14
2022-03-31 11:56:15,569 - INFO - allennlp.training.trainer - Worker 0 memory usage: 12G
2022-03-31 11:56:15,570 - INFO - allennlp.training.trainer - GPU 0 memory usage: 6.7G
2022-03-31 11:56:15,571 - INFO - allennlp.training.trainer - Training
2022-03-31 11:56:15,571 - INFO - tqdm - 0%|          | 0/65 [00:00<?, ?it/s]
2022-03-31 11:56:27,234 - INFO - tqdm - batch_loss: 1.0730, loss: 1.0542 ||:  11%|#         | 7/65 [00:11<01:36,  1.67s/it]
2022-03-31 11:56:37,251 - INFO - tqdm - batch_loss: 1.1230, loss: 1.0595 ||:  20%|##        | 13/65 [00:21<01:27,  1.68s/it]
2022-03-31 11:56:48,914 - INFO - tqdm - batch_loss: 0.9571, loss: 1.0498 ||:  31%|###       | 20/65 [00:33<01:14,  1.67s/it]
2022-03-31 11:56:58,990 - INFO - tqdm - batch_loss: 0.9917, loss: 1.0412 ||:  40%|####      | 26/65 [00:43<01:05,  1.68s/it]
2022-03-31 11:57:09,005 - INFO - tqdm - batch_loss: 0.9119, loss: 1.0346 ||:  49%|####9     | 32/65 [00:53<00:54,  1.66s/it]
2022-03-31 11:57:20,631 - INFO - tqdm - batch_loss: 1.0634, loss: 1.0288 ||:  60%|######    | 39/65 [01:05<00:42,  1.64s/it]
2022-03-31 11:57:32,102 - INFO - tqdm - batch_loss: 0.9526, loss: 1.0276 ||:  71%|#######   | 46/65 [01:16<00:31,  1.65s/it]
2022-03-31 11:57:43,683 - INFO - tqdm - batch_loss: 1.1125, loss: 1.0334 ||:  82%|########1 | 53/65 [01:28<00:19,  1.65s/it]
2022-03-31 11:57:55,203 - INFO - tqdm - batch_loss: 0.9556, loss: 1.0333 ||:  92%|#########2| 60/65 [01:39<00:08,  1.64s/it]
2022-03-31 11:58:02,678 - INFO - tqdm - batch_loss: 1.1850, loss: 1.0334 ||: 100%|##########| 65/65 [01:47<00:00,  1.41s/it]
2022-03-31 11:58:02,678 - INFO - tqdm - batch_loss: 1.1850, loss: 1.0334 ||: 100%|##########| 65/65 [01:47<00:00,  1.65s/it]
2022-03-31 11:58:05,328 - INFO - allennlp.training.trainer - Validating
2022-03-31 11:58:05,329 - INFO - tqdm - 0%|          | 0/115 [00:00<?, ?it/s]
2022-03-31 11:58:15,988 - INFO - tqdm - bleu_BLEU: 0.2417, rouge_ROUGE-1_R: 0.5538, rouge_ROUGE-2_R: 0.3563, rouge_ROUGE-1_P: 0.6423, rouge_ROUGE-2_P: 0.4076, rouge_ROUGE-1_F1: 0.5868, rouge_ROUGE-2_F1: 0.3747, rouge_ROUGE-L: 0.5090, SARI: 0.5446, count: 22.0000, batch_loss: 0.9198, loss: 1.4564 ||:  10%|9         | 11/115 [00:10<01:40,  1.04it/s]
2022-03-31 11:58:26,090 - INFO - tqdm - bleu_BLEU: 0.2338, rouge_ROUGE-1_R: 0.5373, rouge_ROUGE-2_R: 0.3450, rouge_ROUGE-1_P: 0.6214, rouge_ROUGE-2_P: 0.3941, rouge_ROUGE-1_F1: 0.5665, rouge_ROUGE-2_F1: 0.3614, rouge_ROUGE-L: 0.4971, SARI: 0.5671, count: 42.0000, batch_loss: 1.7596, loss: 1.4943 ||:  18%|#8        | 21/115 [00:20<01:44,  1.11s/it]
2022-03-31 11:58:36,263 - INFO - tqdm - bleu_BLEU: 0.2349, rouge_ROUGE-1_R: 0.5222, rouge_ROUGE-2_R: 0.3387, rouge_ROUGE-1_P: 0.6302, rouge_ROUGE-2_P: 0.4077, rouge_ROUGE-1_F1: 0.5618, rouge_ROUGE-2_F1: 0.3635, rouge_ROUGE-L: 0.4931, SARI: 0.5685, count: 62.0000, batch_loss: 1.2602, loss: 1.4610 ||:  27%|##6       | 31/115 [00:30<01:36,  1.14s/it]
2022-03-31 11:58:46,881 - INFO - tqdm - bleu_BLEU: 0.2363, rouge_ROUGE-1_R: 0.5222, rouge_ROUGE-2_R: 0.3417, rouge_ROUGE-1_P: 0.6401, rouge_ROUGE-2_P: 0.4170, rouge_ROUGE-1_F1: 0.5651, rouge_ROUGE-2_F1: 0.3687, rouge_ROUGE-L: 0.4910, SARI: 0.5729, count: 81.0000, batch_loss: 0.8574, loss: 1.4381 ||:  36%|###5      | 41/115 [00:41<01:11,  1.03it/s]
2022-03-31 11:58:57,795 - INFO - tqdm - bleu_BLEU: 0.2351, rouge_ROUGE-1_R: 0.5136, rouge_ROUGE-2_R: 0.3367, rouge_ROUGE-1_P: 0.6454, rouge_ROUGE-2_P: 0.4233, rouge_ROUGE-1_F1: 0.5632, rouge_ROUGE-2_F1: 0.3689, rouge_ROUGE-L: 0.4876, SARI: 0.5731, count: 103.0000, batch_loss: 0.9113, loss: 1.3631 ||:  45%|####5     | 52/115 [00:52<01:02,  1.01it/s]
2022-03-31 11:59:07,815 - INFO - tqdm - bleu_BLEU: 0.2252, rouge_ROUGE-1_R: 0.5027, rouge_ROUGE-2_R: 0.3281, rouge_ROUGE-1_P: 0.6500, rouge_ROUGE-2_P: 0.4242, rouge_ROUGE-1_F1: 0.5580, rouge_ROUGE-2_F1: 0.3638, rouge_ROUGE-L: 0.4796, SARI: 0.5689, count: 123.0000, batch_loss: 1.1060, loss: 1.3925 ||:  54%|#####3    | 62/115 [01:02<00:53,  1.01s/it]
2022-03-31 11:59:17,955 - INFO - tqdm - bleu_BLEU: 0.2239, rouge_ROUGE-1_R: 0.5041, rouge_ROUGE-2_R: 0.3274, rouge_ROUGE-1_P: 0.6473, rouge_ROUGE-2_P: 0.4219, rouge_ROUGE-1_F1: 0.5569, rouge_ROUGE-2_F1: 0.3620, rouge_ROUGE-L: 0.4779, SARI: 0.5607, count: 145.0000, batch_loss: 1.1204, loss: 1.4460 ||:  63%|######3   | 73/115 [01:12<00:37,  1.11it/s]
2022-03-31 11:59:28,028 - INFO - tqdm - bleu_BLEU: 0.2301, rouge_ROUGE-1_R: 0.5041, rouge_ROUGE-2_R: 0.3332, rouge_ROUGE-1_P: 0.6570, rouge_ROUGE-2_P: 0.4367, rouge_ROUGE-1_F1: 0.5601, rouge_ROUGE-2_F1: 0.3707, rouge_ROUGE-L: 0.4816, SARI: 0.5670, count: 165.0000, batch_loss: 0.7266, loss: 1.4223 ||:  72%|#######2  | 83/115 [01:22<00:32,  1.01s/it]
2022-03-31 11:59:38,454 - INFO - tqdm - bleu_BLEU: 0.2317, rouge_ROUGE-1_R: 0.5101, rouge_ROUGE-2_R: 0.3357, rouge_ROUGE-1_P: 0.6520, rouge_ROUGE-2_P: 0.4325, rouge_ROUGE-1_F1: 0.5618, rouge_ROUGE-2_F1: 0.3706, rouge_ROUGE-L: 0.4842, SARI: 0.5637, count: 187.0000, batch_loss: 1.8271, loss: 1.4184 ||:  82%|########1 | 94/115 [01:33<00:21,  1.02s/it]
2022-03-31 11:59:48,541 - INFO - tqdm - bleu_BLEU: 0.2355, rouge_ROUGE-1_R: 0.5113, rouge_ROUGE-2_R: 0.3378, rouge_ROUGE-1_P: 0.6472, rouge_ROUGE-2_P: 0.4307, rouge_ROUGE-1_F1: 0.5599, rouge_ROUGE-2_F1: 0.3707, rouge_ROUGE-L: 0.4845, SARI: 0.5620, count: 207.0000, batch_loss: 1.2564, loss: 1.4157 ||:  90%|######### | 104/115 [01:43<00:10,  1.03it/s]
2022-03-31 11:59:58,977 - INFO - tqdm - bleu_BLEU: 0.2307, rouge_ROUGE-1_R: 0.5076, rouge_ROUGE-2_R: 0.3340, rouge_ROUGE-1_P: 0.6481, rouge_ROUGE-2_P: 0.4302, rouge_ROUGE-1_F1: 0.5578, rouge_ROUGE-2_F1: 0.3680, rouge_ROUGE-L: 0.4836, SARI: 0.5601, count: 229.0000, batch_loss: 2.4191, loss: 1.4160 ||: 100%|##########| 115/115 [01:53<00:00,  1.12it/s]
2022-03-31 11:59:58,977 - INFO - tqdm - bleu_BLEU: 0.2307, rouge_ROUGE-1_R: 0.5076, rouge_ROUGE-2_R: 0.3340, rouge_ROUGE-1_P: 0.6481, rouge_ROUGE-2_P: 0.4302, rouge_ROUGE-1_F1: 0.5578, rouge_ROUGE-2_F1: 0.3680, rouge_ROUGE-L: 0.4836, SARI: 0.5601, count: 229.0000, batch_loss: 2.4191, loss: 1.4160 ||: 100%|##########| 115/115 [01:53<00:00,  1.01it/s]
2022-03-31 11:59:58,978 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2022-03-31 11:59:58,978 - INFO - allennlp.training.tensorboard_writer - SARI               |       N/A  |     0.560
2022-03-31 11:59:58,979 - INFO - allennlp.training.tensorboard_writer - bleu_BLEU          |       N/A  |     0.231
2022-03-31 11:59:58,980 - INFO - allennlp.training.tensorboard_writer - count              |       N/A  |   229.000
2022-03-31 11:59:58,980 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |  6844.262  |       N/A
2022-03-31 11:59:58,981 - INFO - allennlp.training.tensorboard_writer - loss               |     1.033  |     1.416
2022-03-31 11:59:58,981 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_F1   |       N/A  |     0.558
2022-03-31 11:59:58,982 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_P    |       N/A  |     0.648
2022-03-31 11:59:58,982 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-1_R    |       N/A  |     0.508
2022-03-31 11:59:58,983 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_F1   |       N/A  |     0.368
2022-03-31 11:59:58,983 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_P    |       N/A  |     0.430
2022-03-31 11:59:58,983 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-2_R    |       N/A  |     0.334
2022-03-31 11:59:58,984 - INFO - allennlp.training.tensorboard_writer - rouge_ROUGE-L      |       N/A  |     0.484
2022-03-31 11:59:58,984 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  12006.336  |       N/A
2022-03-31 12:00:04,256 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to './output_decomposition/best.th'.
2022-03-31 12:00:28,165 - INFO - allennlp.training.trainer - Epoch duration: 0:04:12.596124
2022-03-31 12:00:28,166 - INFO - allennlp.training.checkpointer - loading best weights
2022-03-31 12:00:29,141 - INFO - allennlp.common.util - Metrics: {
  "best_epoch": 14,
  "best_validation_bleu_BLEU": 0.23067967081344767,
  "best_validation_rouge_ROUGE-1_R": 0.5076332078599389,
  "best_validation_rouge_ROUGE-2_R": 0.3339668676158624,
  "best_validation_rouge_ROUGE-1_P": 0.6481379800943231,
  "best_validation_rouge_ROUGE-2_P": 0.4302082527724172,
  "best_validation_rouge_ROUGE-1_F1": 0.5578461450661512,
  "best_validation_rouge_ROUGE-2_F1": 0.36797590911679146,
  "best_validation_rouge_ROUGE-L": 0.4835590241960094,
  "best_validation_SARI": 0.5600714021380732,
  "best_validation_count": 229,
  "best_validation_loss": 1.4160231110842332,
  "peak_worker_0_memory_MB": 12006.3359375,
  "peak_gpu_0_memory_MB": 6844.26171875,
  "training_duration": "0:27:00.588433",
  "training_start_epoch": 8,
  "training_epochs": 6,
  "epoch": 14,
  "training_loss": 1.03336530568508,
  "training_worker_0_memory_MB": 12006.3359375,
  "training_gpu_0_memory_MB": 6844.26171875,
  "validation_bleu_BLEU": 0.23067967081344767,
  "validation_rouge_ROUGE-1_R": 0.5076332078599389,
  "validation_rouge_ROUGE-2_R": 0.3339668676158624,
  "validation_rouge_ROUGE-1_P": 0.6481379800943231,
  "validation_rouge_ROUGE-2_P": 0.4302082527724172,
  "validation_rouge_ROUGE-1_F1": 0.5578461450661512,
  "validation_rouge_ROUGE-2_F1": 0.36797590911679146,
  "validation_rouge_ROUGE-L": 0.4835590241960094,
  "validation_SARI": 0.5600714021380732,
  "validation_count": 229,
  "validation_loss": 1.4160231110842332
}
2022-03-31 12:00:29,141 - INFO - allennlp.models.archival - archiving weights and vocabulary to ./output_decomposition/model.tar.gz
